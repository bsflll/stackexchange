{
    "title": "How to create an API for a web application without its source code?",
    "link": "https://reverseengineering.stackexchange.com/questions/1568/how-to-create-an-api-for-a-web-application-without-its-source-code",
    "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  There's a post here (\n  <a href=\"http://narenonit.blogspot.in/2011/07/my-youmint-api-to-send-free-sms.html\">\n   http://narenonit.blogspot.in/2011/07/my-youmint-api-to-send-free-sms.html\n  </a>\n  ) in which the author has tried to inform pretty well, as far as I can guess. The exact problem I'm facing is how to study the HTTP connection. Would it be possible for someone to explain the procedure a bit more clearly.\n </p>\n</div>\n</body></html>",
    "votes": "10",
    "answers": 4,
    "views": "1k",
    "tags": [
        "websites"
    ],
    "user": "Mr Programmer",
    "time": "Apr 4, 2013 at 11:54",
    "comments": [],
    "answers_data": [
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  You could use some tools to view what gets sent from your browser to the web app and deduce how to \"emulate\" this behavior. A network sniffer would be the most useful here.\n  <a href=\"http://www.wireshark.org/\">\n   Wireshark\n  </a>\n  (especially it's\n  <a href=\"http://www.wireshark.org/docs/wsug_html_chunked/ChAdvFollowTCPSection.html\">\n   Follow Stream\n  </a>\n  feature)for example. Also , some browser plugins can be useful, for example\n  <a href=\"https://getfirebug.com/\">\n   Firebug\n  </a>\n  ,\n  <a href=\"https://addons.mozilla.org/en-US/firefox/addon/tamper-data/\">\n   TamperData\n  </a>\n  and\n  <a href=\"https://addons.mozilla.org/en-US/firefox/addon/poster/\">\n   Poster\n  </a>\n  .\n </p>\n <p>\n  Appart from that, it's just the matter of replicating what the browser does. \nBasically, http communication consists of either GET or POST requests and replies (there are other requests tho and you should look into\n  <a href=\"http://www.w3.org/Protocols/rfc2616/rfc2616.html\">\n   RFC2616\n  </a>\n  for more details). So, by looking at HTTP streams in Wireshark, you could deduce what kind of request gets sent to the web application, and what kind of reply it gets. Some (or most, even) of this info can be deduced by studying the html source of the webpage since the html form element will have the parameters and action url specified.\n </p>\n</div>\n</body></html>",
            "votes": "10",
            "user": "0xea",
            "time": "Apr 4, 2013 at 12:05",
            "is_accepted": false,
            "comments": [
                {
                    "user": "Remko",
                    "text": "<span class=\"comment-copy\">I can also recommend <a href=\"http://www.fiddler2.com/fiddler2/\" rel=\"nofollow noreferrer\">Fiddler</a> and <a href=\"http://www.ieinspector.com/httpanalyzer/\" rel=\"nofollow noreferrer\">http analyzer</a>(commercial)</span>",
                    "time": null
                },
                {
                    "user": "toasted_flakes",
                    "text": "<span class=\"comment-copy\"><a href=\"http://mitmproxy.org/\" rel=\"nofollow noreferrer\">mitmproxy</a> is pretty good, and it's really easy to modify/replay packets.</span>",
                    "time": null
                }
            ]
        },
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  In addition to the mentioned tools, I'd like to point out\n  <a href=\"https://github.com/jbittel/httpry\">\n   <code>\n    httpry\n   </code>\n  </a>\n  , which is based on\n  <code>\n   libpcap\n  </code>\n  (like\n  <code>\n   tcpdump\n  </code>\n  and\n  <code>\n   WireShark\n  </code>\n  ) but aimed at only listening to and listing HTTP traffic.\n </p>\n <p>\n  <a href=\"http://www.fiddler2.com/fiddler2/\">\n   Fiddler\n  </a>\n  is another tool, albeit not FLOSS, that is up for the job just like the Firefox \"Tamper Data\" add-on. Remko also mentioned it in his comment, but I think it needs to be mentioned more prominently than in a comment. Was missing it from the other answer when reading through it.\n </p>\n</div>\n</body></html>",
            "votes": "6",
            "user": "0xC0000022L",
            "time": "Apr 4, 2013 at 17:27",
            "is_accepted": false,
            "comments": []
        },
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  The way to do it is using web scraping techniques. Using sniffers and proxies is overkill if you can access the web page/resource with a browser. In this case you only need to automate what the user does within the browser and using tools like\n  <a href=\"https://developers.google.com/chrome-developer-tools/\" rel=\"nofollow\">\n   Chrome Developer Tools\n  </a>\n  for inspecting the HTML and AJAX connections.\n </p>\n <p>\n  I've written several articles on this subject if you want to take a look:\n </p>\n <ul>\n  <li>\n   <a href=\"http://blog.databigbang.com/google-search-no-api/\" rel=\"nofollow\">\n    Google Search NoAPI\n   </a>\n   (automating Google searches)\n  </li>\n  <li>\n   <a href=\"http://blog.databigbang.com/automated-browserless-oauth-authentication-for-twitter/\" rel=\"nofollow\">\n    Automated Browserless OAuth Authentication for Twitter\n   </a>\n  </li>\n  <li>\n   <a href=\"http://blog.databigbang.com/web-scraping-ajax-and-javascript-sites/\" rel=\"nofollow\">\n    Web Scraping Ajax and Javascript Sites\n   </a>\n   includes a LOT of resources in the end about offline/headless browsers and browsers emulation like\n   <a href=\"https://developers.google.com/chrome-developer-tools/\" rel=\"nofollow\">\n    HTMLUnit\n   </a>\n  </li>\n </ul>\n <p>\n  For applications that has some anti-scraping techniques you can take a look at\n  <a href=\"http://blog.databigbang.com/running-your-own-anonymous-rotating-proxies/\" rel=\"nofollow\">\n   Running Your Own Anonymous Rotating Proxies\n  </a>\n </p>\n <p>\n  If there is some specific requirement that is not covered there please don't hesitate to leave a comment and I will help you on that.\n </p>\n</div>\n</body></html>",
            "votes": "3",
            "user": "sw.",
            "time": "Apr 6, 2013 at 13:07",
            "is_accepted": false,
            "comments": []
        },
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  <a href=\"http://www.fiddler2.com/fiddler2/version.asp\" rel=\"nofollow\">\n   Fiddler\n  </a>\n  learn to love it..\n </p>\n <p>\n  It provides an easy to use interface for capturing requests/responses to the intended sites.\n </p>\n <p>\n  <strong>\n   Essentially you need to:\n  </strong>\n </p>\n <ul>\n  <li>\n   <p>\n    Make the request you want to automate using your browser.\n   </p>\n  </li>\n  <li>\n   <p>\n    Use Fiddler to capture these requests and investigate them. (Is it a POST or GET? Is there a CSRF token? What variables map to the input I provided etc..)\n   </p>\n  </li>\n  <li>\n   <p>\n    Get the response back from the server.\n   </p>\n  </li>\n  <li>\n   <p>\n    Identify the parts that contain your output.\n   </p>\n  </li>\n </ul>\n <p>\n  Then you need to write a script that takes whatever input you want to problematically send and then makes the request in the same fashion that the browser did. Store the output and pull out the portions that you want.\n </p>\n <p>\n  Once you successfully figure out how to formulate the requests you can then build a class to hide the details of how it all works and make clean looking code.\n </p>\n</div>\n</body></html>",
            "votes": "2",
            "user": "atorrrr",
            "time": "Apr 4, 2013 at 23:46",
            "is_accepted": false,
            "comments": []
        }
    ]
}