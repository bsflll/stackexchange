{
    "title": "Why are these 0-byte jumps used as a delay?",
    "link": "https://reverseengineering.stackexchange.com/questions/18981/why-are-these-0-byte-jumps-used-as-a-delay",
    "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  I'm debugging an old PC BIOS and see a lot of what I assume are delay sequences, using 0-byte jump instructions (\n  <code>\n   EB 00\n  </code>\n  =\n  <code>\n   jmp short $+2\n  </code>\n  ).\n </p>\n <p>\n  <a href=\"https://i.sstatic.net/qaux2.png\" rel=\"nofollow noreferrer\">\n   <img alt='perform some I/O and three \"pointless\" jumps' src=\"https://i.sstatic.net/qaux2.png\"/>\n  </a>\n </p>\n <p>\n  Why this particular instruction? I'm guessing it must have some desirable timing properties.\n </p>\n <p>\n  The CPU in question is a 386SX clocked at 16MHz.\n </p>\n</div>\n</body></html>",
    "votes": "2",
    "answers": 1,
    "views": "168",
    "tags": [
        "disassembly",
        "x86",
        "bios"
    ],
    "user": "pesco",
    "time": "Aug 5, 2018 at 10:59",
    "comments": [],
    "answers_data": [
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  Here's a fragment from the leaked AWARD BIOS source code (file\n  <code>\n   COMMON.MAC\n  </code>\n  ):\n </p>\n <pre><code>SIODELAY    MACRO               ; SHORT IODELAY\n        jmp short $+2\n        ENDM\n\nIODELAY     MACRO               ; NORMAL IODELAY\n        siodelay\n        siodelay\n        ENDM\n\nWAFORIO     MACRO               ; NORMAL IODELAY\n        siodelay\n        siodelay\n        siodelay\n        siodelay\n        siodelay\n        siodelay\n        ENDM\n\nNEWIODELAY      MACRO\n        out 0ebh,al              \n            ENDM  \n</code></pre>\n <p>\n  So apparently this was intended specifically as a delay after I/O operations, presumably to give the potentially slow hardware time to process the request from the CPU.\n </p>\n <p>\n  I also found this in the\n  <a href=\"http://www.edm2.com/index.php/OS/2_Device_Driver_Frequently_Asked_Questions#Is_a_delay_necessary_between_I.2FO_operations\" rel=\"nofollow noreferrer\">\n   OS/2 programming FAQ\n  </a>\n  :\n </p>\n <blockquote>\n  <p>\n   <strong>\n    Question\n   </strong>\n   : I looked at some code in ddk\\src\\dev\\mouse\\bus.asm which diddles with the interrupt controller, and it calls MyIODelay in\n  between IN and OUT instructions. I'm not clear why these are required.\n  It says something about letting the bus catch up - is this brain dead\n  hardware or what?\n  </p>\n  <p>\n   <strong>\n    Answer\n   </strong>\n   : You were right first time - brain dead hardware. \"Some\" (not all) IO devices cannot do:\n  </p>\n  <pre><code>  in al,dx\n  or al,MASK\n  out dx,al\n</code></pre>\n  <p>\n   as the CPU is faster than the IO peripherals, received wisdom is that\n  you should put an arbitrary small delay between IO access to the same\n  IO device. And most people use:\n  </p>\n  <pre><code>  in al,dx\n  or al,MASK\n     jmp next_instruction\nnext_instruction:\n  out dx,al\n</code></pre>\n  <p>\n   The jump op has the additional \"benefit\" of flushing the CPUs\n  instruction pipeline and thereby slowing down processing even more.\n  </p>\n </blockquote>\n <p>\n  It's not quite the pattern in your snippet so could be just an instance of cargo-cult copypasting.\n </p>\n</div>\n</body></html>",
            "votes": "3",
            "user": "Igor Skochinsky",
            "time": "Aug 5, 2018 at 18:55",
            "is_accepted": true,
            "comments": [
                {
                    "user": "pesco",
                    "text": "<span class=\"comment-copy\">Cool, thanks, that helps. The part about flushing the pipeline actually confirms what I suspected. Though I still wonder how the proper reasoning would go, rather than \"everybody does this and it seems to work\".</span>",
                    "time": null
                },
                {
                    "user": "Igor Skochinsky",
                    "text": "<span class=\"comment-copy\">you could try asking on retrocomputing, maybe people there know more about early hardware</span>",
                    "time": null
                },
                {
                    "user": "gilm",
                    "text": "<span class=\"comment-copy\">I remember that I used to nop my way through and that worked fine for me. My only guess is that jmp flushes cache, plus, it takes many more clock ticks per bytes that just a single nop. They probably want to save ROM bytes yet still have lots of cycles spared. It only seems a mystery because you know there are better ways than jmp+$2 :)</span>",
                    "time": null
                }
            ]
        }
    ]
}