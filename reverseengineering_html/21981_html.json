{
    "title": "What compression type has been used here?",
    "link": "https://reverseengineering.stackexchange.com/questions/21981/what-compression-type-has-been-used-here",
    "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  I am still working on the binary image\n  <a href=\"https://reverseengineering.stackexchange.com/q/21974/245\">\n   from the last question\n  </a>\n  , and have already found out that my \"corrupted\" data is actually just compressed. But now I have another issue because I don't know what compression type was used.\n </p>\n <p>\n  What I already know:\n </p>\n <p>\n  The data consists out of at least 9 Bytes. The first byte is always a \"flag\" wich describes in it's 8 bits wehter the next 8 Bytes are compressed or not. A Compressed \"Byte\" is stored as two Bytes.\n </p>\n <p>\n  Example:\n </p>\n <pre><code>ß\\DB\\cóA\\c\nß -> DF -> 11111011 (MSB) -> 6th byte encoded\n</code></pre>\n <p>\n  This means that \"óA\" actually stands for \"ache\" but i have not yet found where \"ache\" is actually stored in memory.\n </p>\n <p>\n  The Image in question is available here:\n  <a href=\"https://we.tl/t-tpG9EjpSbr\" rel=\"nofollow noreferrer\">\n   https://we.tl/t-tpG9EjpSbr\n  </a>\n </p>\n</div>\n</body></html>",
    "votes": "2",
    "answers": 1,
    "views": "375",
    "tags": [
        "decompress"
    ],
    "user": "Lukas S.",
    "time": "Aug 26, 2019 at 17:04",
    "comments": [
        {
            "user": "julian",
            "text": "<html><body><span class=\"comment-copy\">\n It may be necessary to include a much larger sample or perhaps the file itself\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "Lukas S.",
            "text": "<html><body><span class=\"comment-copy\">\n I've added the image just in case someone needs it\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "shxdow",
            "text": "<html><body><span class=\"comment-copy\">\n Right now I can't really spin up a vm to check myself, but\n <a href=\"https://stackoverflow.com/a/19127748/5924796\">\n  here\n </a>\n are good pointers on identifying compression algorithms. You still have to figure out where the binary starts/ends. Something that comes to mind is scanning the memory image looking for known header bytes (that shouldn't take too long)\n</span>\n</body></html>",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  <strong>\n   Basics\n  </strong>\n </p>\n <p>\n  I've had look at your image file and, as the answer to your previous question said, the compression is something like LZSS.\n </p>\n <p>\n  Specifically, the compressed data begins with a flag byte. Each bit of this in turn (from bit 0 to bit 7) indicates that the next decompressed byte(s) are generated by -\n </p>\n <ul>\n  <li>\n   (when the flag bit is 1) copying a single literal byte from the compressed data stream or\n  </li>\n  <li>\n   <p>\n    (when the flag bit is 0) copying between 3 and 18 bytes from earlier in the decompressed data stream.  The length and location of these bytes are encoded in 2 bytes in the compressed data stream.\n   </p>\n   <p>\n    Suppose these 2 bytes are (in hex using dummy characters)\n    <code>\n     0xPQ\n    </code>\n    and\n    <code>\n     0xRS\n    </code>\n   </p>\n   <p>\n    Then\n   </p>\n   <ul>\n    <li>\n     the length of the data to copy is\n     <code>\n      3 + 0xS\n     </code>\n    </li>\n    <li>\n     the offset of the data to copy is\n     <code>\n      18 + 0xRPQ\n     </code>\n     (using unsigned integer arithmetic modulo 0x1000)\n    </li>\n    <li>\n     the offsets appear to be into a 4k circular buffer of the most recently decompressed data\n    </li>\n   </ul>\n  </li>\n </ul>\n <p>\n  <strong>\n   Example\n  </strong>\n </p>\n <p>\n  Let's look at decompressing the data at offset 0x0008D38E in the image to storage at address 0x0006E720 (assuming the earlier data has already been decompressed.)\n </p>\n <pre><code>compressed data                                              decompressed data\n\n0008D68E: 7D (flag byte 0b01111101)\n             45                        literal byte          0x0006E720: 45\n             D2 60                     3 bytes from 0x6E4    0x0006E721: 6D 65 72   (i.e. copied from 0x0006E6E4)\n             67 65 6E 63 79            literal bytes         0x0006E724: 67 65 6E 63 79 \n             DA 50                     3 bytes from 0x5EC    0x0006E729: 20 4C 6F  (i.e. copied from 0x0006E5EC)\n\n0008D699: FF (flag byte 0b11111111)\n             6F 70 20 54 65 73 74 20   literal bytes         0x0006E72C: 6F 70 20 54 65 73 74 20\n\n0008D6A2: 33 (flag byte 0b00110011)\n             4F 4E                     literal bytes         0x0006E734: 4F 4E\n             08 7F                     18 bytes from 0x71A   0x0006E736: 0D 0A 00 00 00 00 45 6D 65 72 67 65 6E 63 79 20 4C 6F \n             1A 76                     9 bytes from 0x72C    0x0006E748: 6F 70 20 54 65 73 74 20 4F (i.e. copied from 0x0006E72C)\n             46 46                     literal bytes         0x0006E751: 46 46\n             65 22                     4 bytes from 0x277    0x0006E753: 0D 0A 00 00 00\n             06 35                     8 bytes from 0x318    0x0006E758: 45 30 34 0D 0A 00 00 00 \n</code></pre>\n <p>\n  Looking at the decompressed data we see -\n </p>\n <pre><code>0x0006E720: \"Emergency Loop Test ON\\r\n\"\n0x0006E73C: \"Emergency Loop Test OFF\\r\n\"\n0x0006E758: \"E04\\r\n\"\n</code></pre>\n <p>\n  <strong>\n   File Structure\n  </strong>\n </p>\n <p>\n  It appears that the whole file is not compressed but contains a couple of compressed regions beginning at offsets\n  <code>\n   0x00010000\n  </code>\n  and\n  <code>\n   0x00040000\n  </code>\n  .\n  \n\n  Each compressed region appears to begin with a 4 byte/32 bit value containing the length of the compressed data.  These lengths are followed by the compressed data as described above.\n </p>\n <p>\n  <strong>\n   Bonus Note\n  </strong>\n </p>\n <p>\n  An image search for the name of the device in question along with the 'main board' produces a result with a clearly visible Renesas R8A77240D500BGY.  This is an MCU in the Renesas SH7724 family containing a SH-4A RISC CPU core.\n </p>\n</div>\n</body></html>",
            "votes": "4",
            "user": "Ian Cook",
            "time": "Sep 27, 2019 at 23:28",
            "is_accepted": true,
            "comments": [
                {
                    "user": "Lukas S.",
                    "text": "<span class=\"comment-copy\">I have tried to implement the algorithm in C# and it seems to work for the most part. The section you showed in your example, is getting decompressed to exactly the same data. However there are still some patches of 0x00's in the decompressed file.  The code I used: <a href=\"https://pastebin.com/89km3kLE\" rel=\"nofollow noreferrer\">pastebin</a> The data I got from 0x00010000: <a href=\"https://mega.nz/#!OxpkHIyY!9v81DcvijhDGdD7sga7wxqoBz43w6jsG6BgRSJH8cOs\" rel=\"nofollow noreferrer\">mega</a> The data I got from 0x00040000: <a href=\"https://mega.nz/#!GpxClIKJ!VbqG8cW-5JUKTpZ49gyM6h-Ut37kOsX_MCHecTvphq8\" rel=\"nofollow noreferrer\">mega</a></span>",
                    "time": null
                },
                {
                    "user": "Ian Cook",
                    "text": "<span class=\"comment-copy\">The first difference in our decodes is at offset 0x00010262 (compressed) or 0x00000876 (decompressed).  It appears I wasn't using signed arithmetic, but unsigned modulo 0x1000.  I've corrected the answer.</span>",
                    "time": null
                }
            ]
        }
    ]
}