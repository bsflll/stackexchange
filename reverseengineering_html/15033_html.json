{
    "title": "How does glibc malloc work?",
    "link": "https://reverseengineering.stackexchange.com/questions/15033/how-does-glibc-malloc-work",
    "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  Wishing to dig in the internals of dynamic memory allocation on Linux, the best I could find is an article titled\n  <a href=\"https://sploitfun.wordpress.com/2015/02/10/understanding-glibc-malloc/\" rel=\"noreferrer\">\n   Understanding glibc malloc\n  </a>\n  . The explanation, though detailed, is not quite understandable (to me). Especially, I couldn't understand all the data structure involved due to fragmented style of writing which provides information on a piece-wise manner. Can anyone provide one or more references detailing the same topic?\n </p>\n</div>\n</body></html>",
    "votes": "12",
    "answers": 2,
    "views": "12k",
    "tags": [
        "linux",
        "memory",
        "libc"
    ],
    "user": "sherlock",
    "time": "Mar 28, 2017 at 7:26",
    "comments": [],
    "answers_data": [
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  For understanding how dynamic memory allocation (the malloc, free, calloc, realloc library functions) really works there is no substitute for reading the\n  <a href=\"https://sourceware.org/git/?p=glibc.git;a=blob;f=malloc/malloc.c;h=994a23248e258501979138f3b07785045a60e69f;hb=HEAD\" rel=\"noreferrer\">\n   source code\n  </a>\n  of\n  <code>\n   malloc()\n  </code>\n  . It is well commented:\n </p>\n <p>\n  comments on chunks:\n </p>\n <pre><code>/*\n1056    malloc_chunk details:\n1057 \n1058     (The following includes lightly edited explanations by Colin Plumb.)\n1059 \n1060     Chunks of memory are maintained using a `boundary tag' method as\n1061     described in e.g., Knuth or Standish.  (See the paper by Paul\n1062     Wilson ftp://ftp.cs.utexas.edu/pub/garbage/allocsrv.ps for a\n1063     survey of such techniques.)  Sizes of free chunks are stored both\n1064     in the front of each chunk and at the end.  This makes\n1065     consolidating fragmented chunks into bigger chunks very fast.  The\n1066     size fields also hold bits representing whether chunks are free or\n1067     in use.\n1068 \n1069     An allocated chunk looks like this:\n1070 \n1071 \n1072     chunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1073             |             Size of previous chunk, if unallocated (P clear)  |\n1074             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1075             |             Size of chunk, in bytes                     |A|M|P|\n1076       mem-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1077             |             User data starts here...                          .\n1078             .                                                               .\n1079             .             (malloc_usable_size() bytes)                      .\n1080             .                                                               |\n1081 nextchunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1082             |             (size of chunk, but used for application data)    |\n1083             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1084             |             Size of next chunk, in bytes                |A|0|1|\n1085             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1086 \n1087     Where \"chunk\" is the front of the chunk for the purpose of most of\n1088     the malloc code, but \"mem\" is the pointer that is returned to the\n1089     user.  \"Nextchunk\" is the beginning of the next contiguous chunk.\n1090 \n1091     Chunks always begin on even word boundaries, so the mem portion\n1092     (which is returned to the user) is also on an even word boundary, and\n1093     thus at least double-word aligned.\n1094 \n1095     Free chunks are stored in circular doubly-linked lists, and look like this:\n1096 \n1097     chunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1098             |             Size of previous chunk, if unallocated (P clear)  |\n1099             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1100     `head:' |             Size of chunk, in bytes                     |A|0|P|\n1101       mem-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1102             |             Forward pointer to next chunk in list             |\n1103             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1104             |             Back pointer to previous chunk in list            |\n1105             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1106             |             Unused space (may be 0 bytes long)                .\n1107             .                                                               .\n1108             .                                                               |\n1109 nextchunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1110     `foot:' |             Size of chunk, in bytes                           |\n1111             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1112             |             Size of next chunk, in bytes                |A|0|0|\n1113             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n1114 \n1115     The P (PREV_INUSE) bit, stored in the unused low-order bit of the\n1116     chunk size (which is always a multiple of two words), is an in-use\n1117     bit for the *previous* chunk.  If that bit is *clear*, then the\n1118     word before the current chunk size contains the previous chunk\n1119     size, and can be used to find the front of the previous chunk.\n1120     The very first chunk allocated always has this bit set,\n1121     preventing access to non-existent (or non-owned) memory. If\n1122     prev_inuse is set for any given chunk, then you CANNOT determine\n1123     the size of the previous chunk, and might even get a memory\n1124     addressing fault when trying to do so.\n1125 \n1126     The A (NON_MAIN_ARENA) bit is cleared for chunks on the initial,\n1127     main arena, described by the main_arena variable.  When additional\n1128     threads are spawned, each thread receives its own arena (up to a\n1129     configurable limit, after which arenas are reused for multiple\n1130     threads), and the chunks in these arenas have the A bit set.  To\n1131     find the arena for a chunk on such a non-main arena, heap_for_ptr\n1132     performs a bit mask operation and indirection through the ar_ptr\n1133     member of the per-heap header heap_info (see arena.c).\n1134 \n1135     Note that the `foot' of the current chunk is actually represented\n1136     as the prev_size of the NEXT chunk. This makes it easier to\n1137     deal with alignments etc but can be very confusing when trying\n1138     to extend or adapt this code.\n1139 \n1140     The three exceptions to all this are:\n1141 \n1142      1. The special chunk `top' doesn't bother using the\n1143         trailing size field since there is no next contiguous chunk\n1144         that would have to index off it. After initialization, `top'\n1145         is forced to always exist.  If it would become less than\n1146         MINSIZE bytes long, it is replenished.\n1147 \n1148      2. Chunks allocated via mmap, which have the second-lowest-order\n1149         bit M (IS_MMAPPED) set in their size fields.  Because they are\n1150         allocated one-by-one, each must contain its own trailing size\n1151         field.  If the M bit is set, the other bits are ignored\n1152         (because mmapped chunks are neither in an arena, nor adjacent\n1153         to a freed chunk).  The M bit is also used for chunks which\n1154         originally came from a dumped heap via malloc_set_state in\n1155         hooks.c.\n1156 \n1157      3. Chunks in fastbins are treated as allocated chunks from the\n1158         point of view of the chunk allocator.  They are consolidated\n1159         with their neighbors only in bulk, in malloc_consolidate.\n1160 */\n</code></pre>\n <p>\n  comments on internal data structures:\n </p>\n <pre><code>/*\n1313    -------------------- Internal data structures --------------------\n1314 \n1315    All internal state is held in an instance of malloc_state defined\n1316    below. There are no other static variables, except in two optional\n1317    cases:\n1318  * If USE_MALLOC_LOCK is defined, the mALLOC_MUTEx declared above.\n1319  * If mmap doesn't support MAP_ANONYMOUS, a dummy file descriptor\n1320      for mmap.\n1321 \n1322    Beware of lots of tricks that minimize the total bookkeeping space\n1323    requirements. The result is a little over 1K bytes (for 4byte\n1324    pointers and size_t.)\n1325  */\n1326 \n1327 /*\n1328    Bins\n1329 \n1330     An array of bin headers for free chunks. Each bin is doubly\n1331     linked.  The bins are approximately proportionally (log) spaced.\n1332     There are a lot of these bins (128). This may look excessive, but\n1333     works very well in practice.  Most bins hold sizes that are\n1334     unusual as malloc request sizes, but are more usual for fragments\n1335     and consolidated sets of chunks, which is what these bins hold, so\n1336     they can be found quickly.  All procedures maintain the invariant\n1337     that no consolidated chunk physically borders another one, so each\n1338     chunk in a list is known to be preceeded and followed by either\n1339     inuse chunks or the ends of memory.\n1340 \n1341     Chunks in bins are kept in size order, with ties going to the\n1342     approximately least recently used chunk. Ordering isn't needed\n1343     for the small bins, which all contain the same-sized chunks, but\n1344     facilitates best-fit allocation for larger chunks. These lists\n1345     are just sequential. Keeping them in order almost never requires\n1346     enough traversal to warrant using fancier ordered data\n1347     structures.\n1348 \n1349     Chunks of the same size are linked with the most\n1350     recently freed at the front, and allocations are taken from the\n1351     back.  This results in LRU (FIFO) allocation order, which tends\n1352     to give each chunk an equal opportunity to be consolidated with\n1353     adjacent freed chunks, resulting in larger free chunks and less\n1354     fragmentation.\n1355 \n1356     To simplify use in double-linked lists, each bin header acts\n1357     as a malloc_chunk. This avoids special-casing for headers.\n1358     But to conserve space and improve locality, we allocate\n1359     only the fd/bk pointers of bins, and then use repositioning tricks\n1360     to treat these as the fields of a malloc_chunk*.\n1361  */\n</code></pre>\n <p>\n  One of the authors of\n  <code>\n   malloc()\n  </code>\n  , Doug Lea, has written an article called \"\n  <a href=\"http://gee.cs.oswego.edu/dl/html/malloc.html\" rel=\"noreferrer\">\n   A Memory Allocator\n  </a>\n  \" which describes how malloc works (note that the article is from 2000, so there will be some out of date info).\n </p>\n <p>\n  From the article:\n </p>\n <p>\n  Chunks:\n </p>\n <p>\n  <a href=\"https://i.sstatic.net/lBBmu.gif\" rel=\"noreferrer\">\n   <img alt=\"malloc chucks\" src=\"https://i.sstatic.net/lBBmu.gif\"/>\n  </a>\n </p>\n <p>\n  Bins:\n </p>\n <p>\n  <a href=\"https://i.sstatic.net/1ecfs.gif\" rel=\"noreferrer\">\n   <img alt=\"binning\" src=\"https://i.sstatic.net/1ecfs.gif\"/>\n  </a>\n </p>\n <p>\n  An additional resource is chapter 7: \"Memory Allocation\" of\n  <a href=\"https://www.nostarch.com/tlpi\" rel=\"noreferrer\">\n   \"The Linux Programming Interface\"\n  </a>\n  by Michael Kerrisk. TLPI is the best reference of any type I have ever encountered and cannot recommend it highly enough.\n </p>\n <p>\n  Here is a diagram of the implementation of\n  <code>\n   malloc()\n  </code>\n  and\n  <code>\n   free()\n  </code>\n  from TLPI:\n </p>\n <p>\n  <a href=\"https://i.sstatic.net/gphFE.png\" rel=\"noreferrer\">\n   <img alt=\"TLPI malloc and free\" src=\"https://i.sstatic.net/gphFE.png\"/>\n  </a>\n </p>\n <p>\n  On a final note,\n  <code>\n   malloc()\n  </code>\n  is a wrapper around the\n  <a href=\"http://man7.org/linux/man-pages/man2/brk.2.html\" rel=\"noreferrer\">\n   <code>\n    brk()\n   </code>\n   and\n   <code>\n    sbrk()\n   </code>\n  </a>\n  system calls, which resize the heap by changing the location of the\n  <a href=\"https://stackoverflow.com/questions/6988487/what-does-brk-system-call-do/6990428#6990428\">\n   program break\n  </a>\n  .\n </p>\n <p>\n  From comments in the source:\n </p>\n <pre><code> 901   In the new situation, brk() and mmap space is shared and there are no\n 902   artificial limits on brk size imposed by the kernel. What is more,\n 903   applications have started using transient allocations larger than the\n 904   128Kb as was imagined in 2001.\n 905 \n 906   The price for mmap is also high now; each time glibc mmaps from the\n 907   kernel, the kernel is forced to zero out the memory it gives to the\n 908   application. Zeroing memory is expensive and eats a lot of cache and\n 909   memory bandwidth. This has nothing to do with the efficiency of the\n 910   virtual memory system, by doing mmap the kernel just has no choice but\n 911   to zero.\n 912 \n 913   In 2001, the kernel had a maximum size for brk() which was about 800\n 914   megabytes on 32 bit x86, at that point brk() would hit the first\n 915   mmaped shared libaries and couldn't expand anymore. With current 2.6\n 916   kernels, the VA space layout is different and brk() and mmap\n 917   both can span the entire heap at will.\n 918 \n 919   Rather than using a static threshold for the brk/mmap tradeoff,\n 920   we are now using a simple dynamic one. The goal is still to avoid\n 921   fragmentation. The old goals we kept are\n 922   1) try to get the long lived large allocations to use mmap()\n 923   2) really large allocations should always use mmap()\n 924   and we're adding now:\n 925   3) transient allocations should use brk() to avoid forcing the kernel\n 926      having to zero memory over and over again\n 927 \n 928   The implementation works with a sliding threshold, which is by default\n 929   limited to go between 128Kb and 32Mb (64Mb for 64 bitmachines) and starts\n 930   out at 128Kb as per the 2001 default.\n 931 \n 932   This allows us to satisfy requirement 1) under the assumption that long\n 933   lived allocations are made early in the process' lifespan, before it has\n 934   started doing dynamic allocations of the same size (which will\n 935   increase the threshold).\n 936 \n 937   The upperbound on the threshold satisfies requirement 2)\n 938 \n 939   The threshold goes up in value when the application frees memory that was\n 940   allocated with the mmap allocator. The idea is that once the application\n 941   starts freeing memory of a certain size, it's highly probable that this is\n 942   a size the application uses for transient allocations. This estimator\n 943   is there to satisfy the new third requirement.\n 944 \n 945 */\n</code></pre>\n</div>\n</body></html>",
            "votes": "16",
            "user": "julian",
            "time": "Mar 4, 2020 at 1:43",
            "is_accepted": false,
            "comments": []
        },
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  There are several quite good references about the exploitation of the heap in software security, one of my favorite is probably the '\n  <a href=\"http://liveoverflow.com/binary_hacking/\" rel=\"nofollow noreferrer\">\n   binary hacking course\n  </a>\n  ' from\n  <a href=\"https://www.youtube.com/channel/UClcE-kVhqyiHCcjYwcpfj9w\" rel=\"nofollow noreferrer\">\n   LiveOverflow\n  </a>\n  .\n </p>\n <p>\n  You can look at the following lectures for a simplified approach of the heap management (using the\n  <a href=\"https://exploit-exercises.lains.space/protostar/\" rel=\"nofollow noreferrer\">\n   Protostar\n  </a>\n  exercise set from\n  <a href=\"https://exploit-exercises.lains.space/\" rel=\"nofollow noreferrer\">\n   Exploit-Exercises\n  </a>\n  ):\n </p>\n <ul>\n  <li>\n   0x14 - The Heap: what does\n   <code>\n    malloc()\n   </code>\n   do?\n  </li>\n  <li>\n   0x15 - The Heap: How to exploit a Heap Overflow\n  </li>\n  <li>\n   0x16 - The Heap: How do use-after-free exploits work?\n  </li>\n  <li>\n   0x17 - The Heap: Once upon a\n   <code>\n    free()\n   </code>\n  </li>\n  <li>\n   0x18 - The Heap: dlmalloc\n   <code>\n    unlink()\n   </code>\n   exploit\n  </li>\n </ul>\n <p>\n  And, also:\n </p>\n <ul>\n  <li>\n   0x1F - [Live] Remote oldschool dlmalloc Heap exploit\n  </li>\n </ul>\n <p>\n  Then, you can try to read the write-ups on all the Heap exercises on\n  <a href=\"https://exploit-exercises.lains.space/protostar/\" rel=\"nofollow noreferrer\">\n   Protostar\n  </a>\n  .\n </p>\n <p>\n  But, the blog posts from\n  <a href=\"https://sploitfun.wordpress.com/2015/06/26/linux-x86-exploit-development-tutorial-series/\" rel=\"nofollow noreferrer\">\n   sploitfun\n  </a>\n  are one of the most accurate articles I ever seen on the web about this specific topic. I would advise to you to get back to the articles of sploitfun once you get enough understanding of the basic principles.\n </p>\n</div>\n</body></html>",
            "votes": "10",
            "user": "perror",
            "time": "Mar 4, 2020 at 8:34",
            "is_accepted": false,
            "comments": []
        }
    ]
}