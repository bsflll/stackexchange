{
    "title": "What kind of compression/obfuscation algorithm is this?",
    "link": "https://reverseengineering.stackexchange.com/questions/9296/what-kind-of-compression-obfuscation-algorithm-is-this",
    "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  I have a couple of streams that look pretty odd within a\n  <code>\n   DICOM\n  </code>\n  file. In a few words,\n  <a href=\"http://medical.nema.org/medical/dicom/current/output/chtml/part05/chapter_7.html#sect_7.1.2\" rel=\"nofollow noreferrer\">\n   DICOM\n  </a>\n  is very close to what\n  <em>\n   binary XML\n  </em>\n  would look like. Almost all of the information from those DICOM files are straighforward and can be read and interpreted nicely with\n  <a href=\"http://dcmtk.org/\" rel=\"nofollow noreferrer\">\n   DCMTK\n  </a>\n  and/or\n  <a href=\"http://sourceforge.net/projects/gdcm/\" rel=\"nofollow noreferrer\">\n   GDCM\n  </a>\n  .\n </p>\n <p>\n  However there are two binary fields stored within the end of the file that looks like\n  <em>\n   private\n  </em>\n  encoded information. Since DICOM is mostly for\n  <em>\n   interoperability\n  </em>\n  in between system, vendors are actually storing there own internal file format within one of the field of the DICOM file (declared as private field, much like what would people in the TIFF world would do). In my past experience, the encoding was trivial (plain\n  <code>\n   struct\n  </code>\n  stored as binary), see\n  <a href=\"https://github.com/malaterre/GDCM/blob/master/Applications/Cxx/gdcmdump.cxx#L67\" rel=\"nofollow noreferrer\">\n   here\n  </a>\n  or\n  <a href=\"https://github.com/malaterre/GDCM/blob/master/Source/DataStructureAndEncodingDefinition/gdcmCSAHeader.cxx#L986\" rel=\"nofollow noreferrer\">\n   here\n  </a>\n  for example.\n </p>\n <p>\n  Now if I extract the binary blobs from the DICOM file (debian/jessie amd64), here is what I see :\n </p>\n <pre><code>$ gdcmraw -t 7101,1000 input.dcm file1000.gz\n$ gdcmraw -t 7101,1002 input.dcm file1002.gz\n$ file file1000.gz file1000.gz: gzip compressed data, max compression, from FAT filesystem (MS-DOS, OS/2, NT)\n\n$ gunzip file1000.gz\n\ngzip: file1000.gz: invalid compressed data--format violated\n</code></pre>\n <p>\n  However\n  <code>\n   gunzip\n  </code>\n  is not capable of decompressing them. Could someone with more gzip knowledge please check if those files are actually gzip compressed ? It looks like it's possible to decompress them because in the medical industry we tend to re-use code whenever possible. For example a well known MRI vendor is also using\n  <code>\n   gzip\n  </code>\n  compressed stream to store its private file format, see\n  <a href=\"https://github.com/malaterre/GDCM/blob/master/Source/DataStructureAndEncodingDefinition/gdcmPDBHeader.cxx#L25\" rel=\"nofollow noreferrer\">\n   here\n  </a>\n  for example (full thread\n  <a href=\"https://groups.google.com/d/msg/comp.protocols.dicom/mxnCkv8A-i4/sHcN_oFeNekJ\" rel=\"nofollow noreferrer\">\n   here\n  </a>\n  ).\n </p>\n <p>\n  The obfuscation should be pretty trivial too because it needs to pass medical industry clearance. From past experience, I've only seen byte reversing being used or simple incremental XOR.\n </p>\n <p>\n  I've uploaded come of the files here:\n </p>\n <ul>\n  <li>\n   <a href=\"https://github.com/malaterre/MRPicker\" rel=\"nofollow noreferrer\">\n    https://github.com/malaterre/MRPicker\n   </a>\n  </li>\n </ul>\n <p>\n  The image can be extracted nicely, so I suspect only a few extra private vendor information (metadata only) is stored within this field (MRI serial number...).\n </p>\n <p>\n  To be more specific, the fake\n  <code>\n   gzip\n  </code>\n  stream comes in pair eg (\n  <code>\n   file1000.gz\n  </code>\n  &\n  <code>\n   file1002.gz\n  </code>\n  were taken from the same DICOM file). From another DICOM file I found that the second fake gzip stream was (bitwise) identical to\n  <code>\n   file1002.gz\n  </code>\n  , so I only uploaded\n  <code>\n   file1000_other1.gz\n  </code>\n  (same goes for\n  <code>\n   file1000_other2.gz\n  </code>\n  ,\n  <code>\n   file1000_other3.gz\n  </code>\n  and\n  <code>\n   file1000_other4.gz\n  </code>\n  ). So maybe\n  <code>\n   file1002.gz\n  </code>\n  is a bit special here. Since I do not have physical access to the MRI workstation that produces those images, I can only do brute-force approach here.\n </p>\n <hr/>\n <p>\n  Update: I did check that the files are not simply a deflate codestream with broken header using\n  <a href=\"https://github.com/malaterre/MRPicker/blob/master/unz.py\" rel=\"nofollow noreferrer\">\n   unz.py\n  </a>\n  and\n  <a href=\"https://github.com/malaterre/MRPicker/blob/master/runme.sh\" rel=\"nofollow noreferrer\">\n   runme\n  </a>\n  (\n  <code>\n   binwalk -X\n  </code>\n  did not reveal anything either). So they are not direct simple\n  <code>\n   gzip\n  </code>\n  files.\n </p>\n <p>\n  Update2: I did try to read the stream backwards using this\n  <a href=\"https://github.com/malaterre/MRPicker/blob/master/reverse.cxx\" rel=\"nofollow noreferrer\">\n   code\n  </a>\n  but again this still does not look like a deflate stream.\n </p>\n <p>\n  Update3: So far, all streams I found have proper gzip header, and they all finish with 4 zeros (0) bytes, just like any valid gzip. I should be able to recover the file using the\n  <a href=\"https://stackoverflow.com/a/11557033/136285\">\n   last 4 bytes\n  </a>\n  since they are used to store a crc32 (as per gzip RFC).\n </p>\n <p>\n  Update4: Thanks to help here, I discover those private tags are actually slightly\n  <a href=\"http://incenter.medical.philips.com/doclib/enc/fetch/2000/4504/577242/577256/588723/5144873/5144488/5144984/DICOM_Conformance_Statement_ViStar%2C_Twinstar_and_Montage_Workstations.pdf%3Fnodeid%3D5148306%26vernum%3D1\" rel=\"nofollow noreferrer\">\n   documented\n  </a>\n  :\n </p>\n <pre><code>Table A.2.1.2.1.3-3 Private Elements for MR Scanner or MR Workstation Images\nWhen exporting Marconi MR Scanner or MR Workstation images the following\nprivate elements may be included.\n\nTag Name Value Representation\n7101,0010 Private MR Creator Data element LO\n7101,1000 MR Processing Field 1 OB\n7101,1001 MR Processing Field 1 Length SL\n7101,1002 MR Processing Field 2 OB\n7101,1003 MR Processing Field 2 Length SL\n7101,1004 Scan Duration SH\n7101,1005 MR Processing Field 3 SH\n7101,1006 MR Processing Field 4 SH\n</code></pre>\n <p>\n  I did check that the length of the extracted fake-gzip actually match the value stored in the associated attribute (so length for attribute 7101,1000 match value stored in attribute 7101,1001, and length for attribute 7101,1002 matches value stored in attribute 7101,1003). For instance:\n </p>\n <pre><code>$ gdcmdump input3.dcm\n[...]\n(07a1,0010) ?? (LO) [ELSCINT1]                                    # 8,1 Private Creator\n(07a1,1013) ?? (UL) 62940                                         # 4,1 ?\n(7101,0000) ?? (UL) 24242                                         # 4,1 Generic Group Length\n(7101,0010) ?? (LO) [Picker MR Private Group ]                    # 24,1 Private Creator\n(7101,1000) ?? (OB) 1f\\8b\\08\\00\\00\\00\\00\\00\\02\\00\\14\\5d\\4b\\8d\\db\\48\\6e\\3e\\ec\\53\\4f\\7b\\28\\c3\\1e\\ef\\8c\\d8\\2d\\86\\e8\\86\\57\\01\\c9\\d9\\96\\4a\\bd\\76\\45\\35\\92\\99\\dc\\33\\e5\\1b\\08\\78\\04\\25\\94\\93\\04\\f3\\80\\7a\\03\\fa\\cd\\34\\02\\40         # 10784,1 ?\n(7101,1001) ?? (SL) 10784                                         # 4,1 ?\n(7101,1002) ?? (OB) 1f\\8b\\08\\00\\00\\00\\00\\00\\02\\00\\14\\3c\\6d\\8d\\da\\48\\6d\\9f\\93\\a1\\31\\e5\\9c\\2f\\f6\\6b\\c1\\48\\44\\d8\\9e\\26\\67\\ab\\78\\8d\\1d\\8a\\6d\\a0\\80\\6c\\36\\31\\dd\\95\\b6\\96\\84\\2f\\13\\90\\a8\\49\\d8\\0f\\fe\\fa\\15\\97\\19\\97\\24\\c0         # 13328,1 ?\n(7101,1003) ?? (SL) 13328                                         # 4,1 ?\n(7101,1004) ?? (SH) [00:48 ]                                      # 6,1 ?\n(7101,1005) ?? (SH) [ECHO\\CARDIAC]                                # 12,2 ?\n(7101,1006) ?? (SH) [115204\\4187\\0\\0 ]                            # 16,4 ?\n</code></pre>\n <p>\n  Update5: DICOM can only stores even-bytes length as attribute. One fake-gzipped stream was actually padded to the next even length, but the actual length reported in 7101,1001 was odd (10765). I've updated\n  <code>\n   file1000_other4.gz\n  </code>\n  to have the proper length (the trailing bytes are not anymore\n  <code>\n   03 00 00 00\n  </code>\n  , but\n  <code>\n   0B 03 00 00\n  </code>\n  )\n </p>\n</div>\n</body></html>",
    "votes": "2",
    "answers": 1,
    "views": "1k",
    "tags": [
        "deobfuscation",
        "decompress",
        "binary-format",
        "xor"
    ],
    "user": "tibar",
    "time": "May 23, 2017 at 12:37",
    "comments": [
        {
            "user": "Jongware",
            "text": "<html><body><span class=\"comment-copy\">\n Various other tools all say the file is \"damaged\" or \"broken\". So: are you sure these files are complete? (Be aware that if the answer is \"no\" or \"I don't know\", then that is most likely the problem: your files are truncated.)\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "tibar",
            "text": "<html><body><span class=\"comment-copy\">\n @Jongware no the files are not truncated, simply obfuscated.\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "yaspr",
            "text": "<html><body><span class=\"comment-copy\">\n May I ask how did you get the gz files and on which OS ?!\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "Igor Skochinsky",
            "text": "<html><body><span class=\"comment-copy\">\n you should upload complete files; there's a remote possibility something went wrong when extracting the streams. Also, do you have the sotware which produced them?\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "Guntram Blohm",
            "text": "<html><body><span class=\"comment-copy\">\n Where do your filenames come from? Dicom Tag, or something else? There seems to be a specification (well, kind of)\n <a href=\"http://incenter.medical.philips.com/doclib/enc/fetch/2000/4504/577242/577256/588723/5144873/5144488/5144984/DICOM_Conformance_Statement_ViStar%2c_Twinstar_and_Montage_Workstations.pdf%3fnodeid%3d5148306%26vernum%3d1\" rel=\"nofollow noreferrer\">\n  here\n </a>\n on page 20, but 1004 and 1006 shouldn't be byte blobs, and 1008/1010 shouldn't exist.\n</span>\n</body></html>",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  The gzip headers are valid, but the deflate compressed data format is violated almost immediately, within less than ten bytes in for all of the files.\n </p>\n <p>\n  For all of the example files provided, the first deflate block is a dynamic block which has an oversubscribed code lengths code.  That means that a Huffman code required to decode the code lengths for that block is itself invalid.  This immediately halts the decompression, since no further progress can be made.\n </p>\n <p>\n  The last four bytes may not be what you think they are.  The last four bytes of a valid gzip file is the length of the uncompressed data, modulo 2\n  <sup>\n   32\n  </sup>\n  , in little-endian order.  Those lengths do not seem correlated to the file sizes.  For example\n  <code>\n   file1010.gz\n  </code>\n  's last four bytes are\n  <code>\n   0b 03 00 00\n  </code>\n  .  It's length is 10766.  So 10766 bytes decompresses to 779 bytes?  I don't think so.  So the second-to-last four bytes are likely also not what you would expect there for a gzip stream, i.e. likely not a CRC.\n </p>\n <p>\n  The data after the header appears to be random in all cases (pretty flat histogram over 0..255), and is itself mostly incompressible, which is consistent with it being compressed data.\n </p>\n <p>\n  I tried decompressing from all bit offsets starting after the gzip header to the end, but no joy.  This rules out some sort of header followed by valid deflate data.\n </p>\n</div>\n</body></html>",
            "votes": "6",
            "user": "Mark Adler",
            "time": "Jul 21, 2015 at 6:29",
            "is_accepted": true,
            "comments": [
                {
                    "user": "tibar",
                    "text": "<span class=\"comment-copy\">I know the files are not directly handled by gzip (see orig post). I was hoping someone would do a finer analysis (probability distribution, entropy analysis...) about how <i>close</i> those files are from gzip compressed ones (esp. coming from one of the author of gzip).</span>",
                    "time": null
                },
                {
                    "user": "Mark Adler",
                    "text": "<span class=\"comment-copy\">The data after the header appears to be random in all cases (pretty flat histogram over 0..255), which is consistent with it being compressed.  Beyond that, there is no other useful analysis I can think of.</span>",
                    "time": null
                },
                {
                    "user": "Guntram Blohm",
                    "text": "<span class=\"comment-copy\">I checked what happens if you compress those .gz files again, with gzip. For 4 of them, the size gets increased slightly, just as you would expect (no more compression possible and headers added). For the other 2, the size decreases. This <i>might</i> mean it's not just gzip + obfuscation, but a different algorithm, which is slightly better than gzip in some and slightly worse in other cases.</span>",
                    "time": null
                },
                {
                    "user": "Guntram Blohm",
                    "text": "<span class=\"comment-copy\">@MarkAdler: Maybe I'm misinterpreting the specification (<a href=\"https://www.ietf.org/rfc/rfc1951.txt\" rel=\"nofollow noreferrer\">ietf.org/rfc/rfc1951.txt</a>), but as far as i can tell, byte 10 in each file is the first byte of the first compressed data block - 0x14 in all 6 files. Starting with the least significant bit (as specified in 3.1.1), this is a bit pattern of 00101000. I'd translate this to (3.2.3) <code>BFINAL=0</code>, <code>BTYPE=01</code> (compressed with fixed huffman code). How do you conclude \"the first deflate block is a dynamic block\" ?</span>",
                    "time": null
                },
                {
                    "user": "Mark Adler",
                    "text": "<span class=\"comment-copy\">Yes, you're misinterpreting the specification.  You leave the byte as is, <code>00010100</code>, but start at the bottom.  So the lowest bit is <code>0</code>, indicating that this is not the last block.  Then the next two bits are <code>10</code> indicating a dynamic block.</span>",
                    "time": null
                }
            ]
        }
    ]
}