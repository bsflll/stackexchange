{
    "title": "Automated tools for file format reverse engineering?",
    "link": "https://reverseengineering.stackexchange.com/questions/1331/automated-tools-for-file-format-reverse-engineering",
    "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  Are there any tools available to help automate the process of reverse engineering file formats? In particular, I'm interested in tools that use dynamic analysis of an application to parse the format, and less interested in visualization or hex editor-type tools (e.g. 010 Editor).\n </p>\n <p>\n  There is some academic literature on the topic:\n </p>\n <ul>\n  <li>\n   <a href=\"http://research.microsoft.com/pubs/101326/tupni-ccs08.pdf\">\n    Tupni: Automatic Reverse Engineering of Input Formats\n   </a>\n  </li>\n  <li>\n   <a href=\"http://research.microsoft.com/pubs/153180/reformat-esorics09.pdf\">\n    ReFormat: Automatic Reverse Engineering of Encrypted Messages\n   </a>\n  </li>\n  <li>\n   <a href=\"http://www.utdallas.edu/~zhiqiang.lin/file/FSE08.pdf\">\n    Deriving Input Syntactic Structure From Execution\n   </a>\n  </li>\n </ul>\n <p>\n  Has any of this made it into practice?\n </p>\n</div>\n</body></html>",
    "votes": "18",
    "answers": 3,
    "views": "4k",
    "tags": [
        "tools",
        "dynamic-analysis",
        "file-format"
    ],
    "user": "Brendan Dolan-Gavitt",
    "time": "Mar 28, 2013 at 4:48",
    "comments": [],
    "answers_data": [
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  You don't state the purpose. If you want to fully understand the format and not just automate certain initial aspects of the analysis, it will be very hard to come up with a generic enough tool. This is what domain-specific languages and extensible tools (010 Editor, scripting languages) exist for. I'm not aware of any tools that would \"do it all\" at the moment.\n </p>\n <p>\n  Tools such as 010 Editor in fact provide additional useful information such as a histogram (giving clues about the entropy, compression/encryption) and give you the binary templates to refine your knowledge about the file format more and more. The most annoying aspect is how limited the scripting is and that you can't, for example, write plugins (imagine being able to decompress bzip2 or deflate streams and such, something commonly found but not at all supported by 010 Editor). One of the major sore points with me and 010 Editor has been that I hit some syntactic limitations of binary templates to express something vital and had to work around that in weird ways (parametrized\n  <code>\n   struct\n  </code>\n  s being a major pain), although this is exactly the problem it tries to address with its own\n  <a href=\"https://en.wikipedia.org/wiki/Domain-specific_language\">\n   DSL\n  </a>\n  . I think we're in dire need of a FLOSS solution (and I was in fact looking into\n  <a href=\"http://www.lua.org/\">\n   Lua\n  </a>\n  izing\n  <a href=\"http://frhed.sourceforge.net/en/\">\n   frhed\n  </a>\n  at some point).\n </p>\n <p>\n  A file format could be under a layer of encryption or compression and that could be separate per section of the file, not per file. There could be several layers. While I don't want to go as far as to state that it's outright impossible to come up with anything like that, there is a reason why IDA is\n  <em>\n   interactive\n  </em>\n  , for example. In most RCE tasks even the best heuristics can't replace the skills and experience of a seasoned reverse engineer. From experience I would apply the same to reverse engineering of file formats.\n </p>\n <p>\n  I, too, reversed some file formats and usually use a combination of writing a parser in a scripting languages on one hand and writing a binary template for 010 Editor on the other hand. The latter provides a nice fallback, because even if the parsing fails, I can go there, investigate what's going on, adjust and re-run. Lather, rinse, repeat ... you get the idea.\n </p>\n <p>\n  The biggest challenge by far was finding out the more arcane aspects such as integers encoded in 24 bit, sometimes LSB and sometimes MSB first, dates, trees based on\n  <code>\n   xor\n  </code>\n  ing two indexes from elsewhere, a few bits being used from one byte and a few from another having particular meaning... that stuff. And I really cannot imagine how you would fill those gaps without reverse engineering the\n  <em>\n   code\n  </em>\n  reading/writing the format originally. Lacking any documentation/standard, it's the best reference you got.\n </p>\n <p>\n  Also, don't underestimate the power of visualization. Of course a single angle, such as a histogram, only provides little information. But there are plenty of interesting algorithms to apply to unknown data and see structures.\n </p>\n</div>\n</body></html>",
            "votes": "10",
            "user": "0xC0000022L",
            "time": "Mar 27, 2013 at 18:58",
            "is_accepted": false,
            "comments": [
                {
                    "user": "Brendan Dolan-Gavitt",
                    "text": "<span class=\"comment-copy\">I should clarify: I'm not looking for something that automates <i>everything</i> -- as you say, a tool like IDA would be best. But there's a whole lot of room for improvement between fully manual and fully automated. Even a tool that just annotated a file with the code that parsed each range of bytes would be hugely valuable.</span>",
                    "time": null
                },
                {
                    "user": "0xC0000022L",
                    "text": "<span class=\"comment-copy\">@BrendanDolan-Gavitt: I totally agree. Alas, I'm not aware of any. It would be dependent on the architecture and moreover the platform to be meaningful. I could, however, imagine that something like that exists to parse the output of <code>strace</code>, for example.</span>",
                    "time": null
                },
                {
                    "user": "Brendan Dolan-Gavitt",
                    "text": "<span class=\"comment-copy\">Also want to add that I definitely don't discount visualization; I've done a little bit of work toward that <a href=\"http://amnesia.gtisc.gatech.edu/~brendan/hal_mixed_annotated.pdf\" rel=\"nofollow noreferrer\">here</a> and <a href=\"http://amnesia.gtisc.gatech.edu/~brendan/hal_dbi.pdf\" rel=\"nofollow noreferrer\">here</a>. Those are both portions of the PDB file format, and it is very helpful to visually see the access patterns to get an idea of where structure boundaries are.</span>",
                    "time": null
                }
            ]
        },
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  The academy is very far from industry, which is always many-many years ahead. I think there is nothing 'magical' to reverse engineer file formats. Indeed, I reversed various file formats and the very 1st time I did this I tried to find if there was such a tool. But, there was nothing at that time and I don't think there is anything at all today.\n </p>\n <p>\n  It's possible to write a tool that 'automagically' detects some patterns and creates an initial structure to start working on without the need to start from zero but I don't think anything else exists.\n </p>\n</div>\n</body></html>",
            "votes": "3",
            "user": "joxeankoret",
            "time": "Mar 27, 2013 at 17:52",
            "is_accepted": false,
            "comments": [
                {
                    "user": "Brendan Dolan-Gavitt",
                    "text": "<span class=\"comment-copy\">It's a shame if no tools exist -- I can think of lots of automation that would be quite useful, particularly if we bring in some data flow analysis! Perhaps another thing to add to my todo list...</span>",
                    "time": null
                }
            ]
        },
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  Not a direct answer to your question, but I guess it could help.\n </p>\n <p>\n  There have been more attempts at analyzing unknown network protocols and I guess some ideas \nand techniques could be applied to analyzing unknown file formats. \nSome of the papers are:\n </p>\n <ul>\n  <li>\n   <a href=\"http://research.microsoft.com/pubs/69364/sysml_114_cameraready.pdf\" rel=\"nofollow\">\n    Automatically Extracting Fields from Unknown Network Protocols\n   </a>\n  </li>\n  <li>\n   <a href=\"http://research.microsoft.com/en-us/um/people/helenw/papers/discoverer.pdf\" rel=\"nofollow\">\n    Automatic Protocol Reverse Engineering from Network Traces\n   </a>\n  </li>\n  <li>\n   <a href=\"http://research.microsoft.com/en-us/um/people/chguo/ndss07.pdf\" rel=\"nofollow\">\n    A Generic Application-Level Protocol Analyzer and its Language\n   </a>\n  </li>\n </ul>\n <p>\n  There is also\n  <a href=\"http://www.netzob.org/\" rel=\"nofollow\">\n   Netzob\n  </a>\n  tool:\n </p>\n <blockquote>\n  <p>\n   Netzob is an open source tool for reverse engineering, traffic generation and fuzzing of communication protocols. It allows to infer the message format and the state machine of a protocol through passive and active processes. The model can afterward be used to simulate realistic and controllable trafic.\n  </p>\n </blockquote>\n</div>\n</body></html>",
            "votes": "3",
            "user": "0xea",
            "time": "Mar 27, 2013 at 21:28",
            "is_accepted": false,
            "comments": []
        }
    ]
}