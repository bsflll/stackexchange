{
    "title": "reverse engineering file containing time series data",
    "link": "https://reverseengineering.stackexchange.com/questions/13538/reverse-engineering-file-containing-time-series-data",
    "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  I have to decode a proprietary file format which mainly contains time series data. The only thing I was told was that the content is 'zipped', although I am not sure whether it is really zipped or some in-house compression method is used.\nHere is a snippet of the data:\n </p>\n <pre><code>789cecdd55d895d5bb057c26489774a7ac798f713feffbd2dd255d4a2b29\n082220a1d24887020648194883747788a4840828024a4a238d347c13beef\n60afb5f777fcac83e7372efedb8d27e3bae635e386d7b592c5cb9f375ebc\n93f1e2c543bc4b09dac5eb302c7f3c5303a910835d32c2f6b579a41bc633\nab66d2945a4c47e95d36e52db44246647789178832c6b03792a0a574b2bb\nb493d194a3f81b9fb3bf1ed734de70adcacdf2a5ac922228122c5f9431ed\n</code></pre>\n <p>\n  I did a [byte] frequency analysis and it shows a uniform distribution. If the bytes are plot (with A.X.E.), a very homogeneous image is shown:\n </p>\n <p>\n  <a href=\"https://i.sstatic.net/sPdXx.png\" rel=\"nofollow noreferrer\">\n   <img alt=\"enter image description here\" src=\"https://i.sstatic.net/sPdXx.png\"/>\n  </a>\n </p>\n <p>\n  I've checked for the header of common compression algorithms but found none of them.\n </p>\n <p>\n  Any help is highly appreciated.\n </p>\n <p>\n  <strong>\n   EDIT\n  </strong>\n </p>\n <p>\n  Some of these file can be accessed on the following links:\n  <a href=\"http://www.pastefile.com/EgRnl4\" rel=\"nofollow noreferrer\">\n   First file\n  </a>\n  ,\n  <a href=\"http://www.pastefile.com/acdor1\" rel=\"nofollow noreferrer\">\n   Second file\n  </a>\n  ,\n  <a href=\"http://www.pastefile.com/FzgDwj\" rel=\"nofollow noreferrer\">\n   Third file\n  </a>\n  ,\n  <a href=\"http://www.pastefile.com/VljT7K\" rel=\"nofollow noreferrer\">\n   Forth file\n  </a>\n </p>\n <p>\n  The executable which produced/validated these files is not available.\n </p>\n <p>\n  <strong>\n   EDIT 2\n  </strong>\n </p>\n <p>\n  Using\n  <code>\n   binwalk -Me <filename>\n  </code>\n  (github.com/devttys0/binwalk) it is possible to extract two zlib-ed files from each of the previous files.\n </p>\n <p>\n  Here's the header of one of the files:\n </p>\n <pre><code>0a002f220000180100002800e80364001f783c0001a0349c3574367136db\n3582348932bb30dd30a12f2b2f542ff02e432f432ff62edd2f772f6a2f2e\n2fbc2edb2d382dcc2cfe2c272d492d342d1d2d352d352d00000000000000\n000000000000000000000000000000000000000000000000000000000000\n000000000000000000000000000000000000000000000000000000000000\n000000000000000000000000000000000000000000000000000000000000\n000000000000000000000000000000000000000000000000000000000000\n</code></pre>\n</div>\n</body></html>",
    "votes": "3",
    "answers": 1,
    "views": "267",
    "tags": [
        "file-format",
        "binary-diagnosis"
    ],
    "user": "izibe",
    "time": "Sep 21, 2016 at 12:40",
    "comments": [
        {
            "user": "NirIzr",
            "text": "<html><body><span class=\"comment-copy\">\n Is the code generating or processing the file available to you? how many file samples can you collect? are you able to trigger any validation over modified files? can you share the entire file? more info would help here\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "grepNstepN",
            "text": "<html><body><span class=\"comment-copy\">\n sharing the entire file would help immensely. also,what is there once you decompress the zlib'd blobs?\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "Denis Laskov",
            "text": "<html><body><span class=\"comment-copy\">\n Best way to analyse proprietary file format - is to analyze software that should receive and process this file format.  I think you should start with RE of binary that able to create file with this file format, read it or convert from\\to it. You have access to those?\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "NirIzr",
            "text": "<html><body><span class=\"comment-copy\">\n @DenisLaskov OP already mentioned he does not. \"The executable which produced/validated these files is not available.\" izibe it would be nice of you to upload the uncompressed files, now that you've figured out the first layer.\n</span>\n</body></html>",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  It would help if I knew what the data represented, but I have determined the format of the files once unzipped.  Each unzipped file has this structure:\n </p>\n <pre><code>short unk1;           // 10\nshort num_records;    // 8751  (8760 hours per year)\nshort unk2;           // 0\nshort num_samples;    // varies per file from 8 to 179\nshort unk3;           // 0\nshort unk4;           // 40\nshort unk5;           // 1000\nshort unk6;           // 100\nint data_bytecount;   // varies per file (remaining byte count of the file)\nRecord records[num_records];\n</code></pre>\n <p>\n  Where each Record is defined as: (defined as an 010Editor template)\n </p>\n <pre><code>typedef struct {\n    byte flag;                // 0 = no data; 1 = sample data follows\n    if(flag == 1)\n        short data[num_samples];\n} Record;\n</code></pre>\n <p>\n  For example, in the first file unzipped from \"295\", there are 8751 records with 179 samples each.  Most records only have ~30 non-zero values.  The samples for records[0] look like:\n </p>\n <pre><code>15185, 15185, 15060, 14968, 14719, 14583, ...\n</code></pre>\n <p>\n  <a href=\"https://i.sstatic.net/FWdqv.png\" rel=\"nofollow noreferrer\">\n   <img alt='File#1 from \"295\", Record 0' src=\"https://i.sstatic.net/FWdqv.png\"/>\n  </a>\n </p>\n <p>\n  I suspect the data values are normalized floats, perhaps dividing them by 1000.0 or using 16384 as a zero reference for positive/negative numbers.  I also suspect each file contains 1 year's worth of records with 1 per hour.\n </p>\n <p>\n  I'd be interested in knowing what the values represent ... just to have a complete picture.\n </p>\n</div>\n</body></html>",
            "votes": "2",
            "user": "David",
            "time": "Sep 24, 2016 at 0:27",
            "is_accepted": false,
            "comments": []
        }
    ]
}