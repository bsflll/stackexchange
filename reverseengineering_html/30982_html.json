{
    "title": "Understanding gRPC message",
    "link": "https://reverseengineering.stackexchange.com/questions/30982/understanding-grpc-message",
    "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <h2>\n  Problem\n </h2>\n <p>\n  I intercepted a gRPC network request from an application, and I intend to modify the contents and resend the message programmatically. As no tools (except for MitmProxy, see below) were able to decode the protobuf data I wanted to know why that is.\n </p>\n <p>\n  The gRPC payload sent from the client:\n </p>\n <pre><code>gRPC header       | Protobuf data\n[00] [00 00 00 22] [12 12 09 c3 8d 09 16 c3 93 2a c2 a5 4d 40 11 14 39 c3 ab 6b c2 a2 c3 b3 31 40 1a 05 65 6e 2d 53 45 1a 05 73 76 2d 53 45]\n ^^       ^^ Payload length\nCompressed flag\n</code></pre>\n <h2>\n  What I've tried\n </h2>\n <h3>\n  Failure\n </h3>\n <ul>\n  <li>\n   <code>\n    protoc --decode_raw\n   </code>\n   on the protobuf data, but I get\n   <code>\n    Failed to parse input.\n   </code>\n  </li>\n  <li>\n   CyberChef with protobuf decode, gives\n   <code>\n    Error: Exhausted Buffer\n   </code>\n  </li>\n  <li>\n   The\n   <code>\n    blackboxprotobuf\n   </code>\n   python module, raising\n   <code>\n    google.protobuf.message.DecodeError: Invalid Message Length\n   </code>\n  </li>\n </ul>\n <h3>\n  Success\n </h3>\n <p>\n  MitmProxy was able to decode the data to the following:\n </p>\n <pre><code>gRPC message 0 (compressed False)\n[message]    2\n[fixed64]    2.1   4633543028839346763\n[fixed64]    2.2   4625748902140211098\n[message]    3\n[fixed32]    3.12  1163079022\n[string]     3     sv-SE\n</code></pre>\n <h3>\n  Manually decoding\n </h3>\n <pre><code>[message]\n00010 010 00010010\n  2   LEN    18\n\n[fixed64]\n00001 001 [11000011 10001101 00001001 00010110 11000011 10010011 00101010 11000010]\n  1   I64                            13991157658477498000\n\n[fixed32]\n10100 101 [01001101 01000000 00010001 00010100]\n  20  I32              336674893\n\n[fixed64]\n00111 001 [11000011 10101011 01101011 11000010 10100010 11000011 10110011 00110001]\n  7   I64                            3581421232503631000\n\n[unknown]\n01000 000 [00011010 00000101]\n  8  VARINT       ???\n\n[message]\n00011 010 00000101 \n  3   LEN    5\n\n[fixed32]\n01100 101 [01101110 00101101 01010011 01000101]\n 12   I32              1163079022\n\n[string]\n00011 010 00000101 [01110011 01110110 00101101 01010011 01000101]\n  3   LEN    7         s         v       -        S         E\n</code></pre>\n <p>\n  I decoded it using the google documentation as reference:\n  <a href=\"https://developers.google.com/protocol-buffers/docs/encoding\" rel=\"nofollow noreferrer\">\n   https://developers.google.com/protocol-buffers/docs/encoding\n  </a>\n  . However, I am not familiar with gRPC or protobuf so I have likely have gaps in my knowledge.\n </p>\n <p>\n  Worth noting:\n </p>\n <ul>\n  <li>\n   I was able to successfully decode all server responses without problems.\n  </li>\n  <li>\n   The payload length as indicated by the gRPC header (0x22) differs from its actual length (0x28).\n  </li>\n  <li>\n   MitmProxy has access to both the gRPC headers and the protobuf data, while the other tools I tried (that all failed) only support protobuf data as input.\n  </li>\n  <li>\n   I do not know for a fact that MitmProxy decoded the data correctly, only that it ran without exceptions\n  </li>\n  <li>\n   According to the user agent, the client uses\n   <code>\n    grpc-swift-nio/1.9.0\n   </code>\n  </li>\n </ul>\n</div>\n</body></html>",
    "votes": "2",
    "answers": 0,
    "views": "676",
    "tags": [
        "protocol",
        "networking"
    ],
    "user": "WanderingCoder",
    "time": "Oct 12, 2022 at 14:08",
    "comments": [
        {
            "user": "Mega Tonnage",
            "text": "<html><body><span class=\"comment-copy\">\n Because the data is serialised the tools need the .proto file to define the structure. You could try\n <a href=\"https://github.com/schdub/protodec\" rel=\"nofollow noreferrer\">\n  github.com/schdub/protodec\n </a>\n which tries to obtain the .proto from the binary, or generate it from multiple messages (v2 only).\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "Robert",
            "text": "<html><body><span class=\"comment-copy\">\n Best tool I know for protobuf decoding is\n <a href=\"https://www.charlesproxy.com\" rel=\"nofollow noreferrer\">\n  Charles Proxy\n </a>\n .\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "WanderingCoder",
            "text": "<html><body><span class=\"comment-copy\">\n @Robert Thank you, but my question is how to deserialize the data programmatically. Also, I did try charles before but saw no option to deserialize the protobuf data.\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "WanderingCoder",
            "text": "<html><body><span class=\"comment-copy\">\n @MegaTonnage\n <code>\n  protoc --decode_raw\n </code>\n (and the other tools I mentioned) will not require a defenition of the structure as each wire type is included in the protobuf blob. It will try to guess the data type, often incorrectly, but even then the data will be deserializable.\n</span>\n</body></html>",
            "time": null
        },
        {
            "user": "Robert",
            "text": "<html><body><span class=\"comment-copy\">\n @WanderingCoder The option is a bit hidden: you can activate it manually in the content menu, \"View Response As\" -> \"Protocol Buffers\". And you can add custom mappings to URLs where requests or responses are decoded.\n</span>\n</body></html>",
            "time": null
        }
    ],
    "answers_data": []
}