{
    "title": "Identifying rating algorithm",
    "link": "https://reverseengineering.stackexchange.com/questions/30220/identifying-rating-algorithm",
    "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  I'm trying to identify the rating algorithm used to calculate the\n  <strong>\n   displayed average\n  </strong>\n  of a 1 star to 5 stars rating system. To analyze the data I collated the first and last 1000 ranks and added the\n  <em>\n   real average\n  </em>\n  .\n </p>\n <p>\n  Please see my\n  <a href=\"https://ethercalc.net/cx3tlrd2xeqe\" rel=\"nofollow noreferrer\">\n   EtherCalc table\n  </a>\n  .\n </p>\n <p>\n  Here is what I know about the underlying algorithm:\n </p>\n <ul>\n  <li>\n   It is symmetrical.\n  </li>\n  <li>\n   It gives more power to the majority of votes.\n  </li>\n  <li>\n   It is pretty simple and not (intentionally) based on any known (complicated) mathematical method.\n  </li>\n  <li>\n   No information other than the respective number of votes is used for the calculation.\n  </li>\n  <li>\n   It tries to give supposedly dishonest votes (those allegedly submitted just to force the rating up (5 stars) or down (1 star)) less weight, so not every vote is worth the same. For example: If the vast majority of votes concentrate around 1 star and 2 stars votes with a smooth decline and a sudden jump at 5 stars votes, those 5 stars votes will count less (not necessarily 3.00 or 4.00, it could also be something like 4.88).\n  </li>\n  <li>\n   To detect outliers (suspected dishonest votes) a relative smooth rating curve is expected.\n  </li>\n  <li>\n   Items with overwhelmingly favorable ratings get bonus points what gets them over 5 stars.\n  </li>\n </ul>\n <p>\n  I guess the easiest way to determine the algorithm is to analyze the items with the fewest numbers of total ratings. For example:\n </p>\n <div class=\"s-table-container\">\n  <table class=\"s-table\">\n   <thead>\n    <tr>\n     <th>\n      rank\n     </th>\n     <th>\n      5 stars\n     </th>\n     <th>\n      4 stars\n     </th>\n     <th>\n      3 stars\n     </th>\n     <th>\n      2 stars\n     </th>\n     <th>\n      1 star\n     </th>\n     <th>\n      total\n     </th>\n     <th>\n      displayed average\n     </th>\n     <th>\n      real average\n     </th>\n    </tr>\n   </thead>\n   <tbody>\n    <tr>\n     <td>\n      535.\n     </td>\n     <td>\n      15\n     </td>\n     <td>\n      1\n     </td>\n     <td>\n      3\n     </td>\n     <td>\n      0\n     </td>\n     <td>\n      1\n     </td>\n     <td>\n      20\n     </td>\n     <td>\n      5.42\n     </td>\n     <td>\n      4.45\n     </td>\n    </tr>\n    <tr>\n     <td>\n      9802.\n     </td>\n     <td>\n      2\n     </td>\n     <td>\n      3\n     </td>\n     <td>\n      10\n     </td>\n     <td>\n      0\n     </td>\n     <td>\n      0\n     </td>\n     <td>\n      15\n     </td>\n     <td>\n      3.11\n     </td>\n     <td>\n      3.47\n     </td>\n    </tr>\n    <tr>\n     <td>\n      9908.\n     </td>\n     <td>\n      2\n     </td>\n     <td>\n      1\n     </td>\n     <td>\n      3\n     </td>\n     <td>\n      2\n     </td>\n     <td>\n      2\n     </td>\n     <td>\n      10\n     </td>\n     <td>\n      2.86\n     </td>\n     <td>\n      2.90\n     </td>\n    </tr>\n    <tr>\n     <td>\n      9944.\n     </td>\n     <td>\n      0\n     </td>\n     <td>\n      0\n     </td>\n     <td>\n      3\n     </td>\n     <td>\n      0\n     </td>\n     <td>\n      1\n     </td>\n     <td>\n      4\n     </td>\n     <td>\n      2.71\n     </td>\n     <td>\n      2.50\n     </td>\n    </tr>\n    <tr>\n     <td>\n      9978.\n     </td>\n     <td>\n      0\n     </td>\n     <td>\n      0\n     </td>\n     <td>\n      3\n     </td>\n     <td>\n      0\n     </td>\n     <td>\n      2\n     </td>\n     <td>\n      5\n     </td>\n     <td>\n      2.26\n     </td>\n     <td>\n      2.20\n     </td>\n    </tr>\n   </tbody>\n  </table>\n </div>\n <p>\n  Since I've been thinking about this for too long and can't come up with the solution, I kindly ask for your valuable help.\n </p>\n</div>\n</body></html>",
    "votes": "1",
    "answers": 2,
    "views": "211",
    "tags": [
        "static-analysis",
        "math"
    ],
    "user": "madlen",
    "time": "Apr 8, 2022 at 13:04",
    "comments": [],
    "answers_data": [
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  First, this is a comment at the moment, but I cannot add comments still not having a minimum of 50 reputations.\n </p>\n <p>\n  You have not given some information on which your knowledge is founded. That might help to confirm those - or not.\n </p>\n <p>\n  Am I correct that you cannot create a response from the site by creating specific input for your own defined combinations?\n </p>\n <p>\n  Then I would try to attack the algorithm by\n </p>\n <ul>\n  <li>\n   selecting most simple combinations, and when displayed, and the real average is not the same. Like here:\n  </li>\n </ul>\n <p>\n  <a href=\"https://i.sstatic.net/jpIYD.png\" rel=\"nofollow noreferrer\">\n   <img alt=\"enter image description here\" src=\"https://i.sstatic.net/jpIYD.png\"/>\n  </a>\n </p>\n <ul>\n  <li>\n   Or selecting combinations where only a single star rating is incrementing and the others keep the same\n  </li>\n </ul>\n <p>\n  <strong>\n   Edit 10.04.22\n  </strong>\n </p>\n <p>\n  Meanwhile, I did a second approach: guessing an almost linear formula with a fixed factor for each star, so that the average is calculated by (number of 5 stars)*a+(number of 4 stars)*b+etc/total.\nThen I selected the ones with Zero 1 star, and Zero 2 stars and optimized the factors, resulting in\n </p>\n <ul>\n  <li>\n   5 stars: factor 5.705\n  </li>\n  <li>\n   4 stars: factor 4.19\n  </li>\n  <li>\n   3 stars: factor 2.335\n  </li>\n </ul>\n <p>\n  Total difference of deltas of that model (\n  <code>\n   abs(result - displayed average)\n  </code>\n  versus average model is reduced, but not Zero => guessed formula is not good enough. This is expected from the information you gave for the algorithm. However the biggest deltas are found for good scored results => a new model is to be guessed to represent that non-linear impact.\n </p>\n <p>\n  I think in that way you can come closer to a model that is good enough and get a final low delta, but it will never be the original algorithm.\nAlternatively, an \"automated formula guesser\" is needed, that combines the 5 variables to a result that comes close to the displayed average. However, this will also most probably not be the original algorithm.\n </p>\n</div>\n</body></html>",
            "votes": "1",
            "user": "Rohit Gupta",
            "time": "Feb 5, 2023 at 8:20",
            "is_accepted": false,
            "comments": [
                {
                    "user": "madlen",
                    "text": "<span class=\"comment-copy\">Thanks for your comment. - My knowledge is based on a survey of the author. Unfortunately, he didn't want to reveal more information. - Yes, you are correct. - That's an interesting approach. Have you come to any approximation with this?</span>",
                    "time": null
                },
                {
                    "user": "dieter reichl",
                    "text": "<span class=\"comment-copy\">Edited above answer with new input</span>",
                    "time": null
                },
                {
                    "user": "madlen",
                    "text": "<span class=\"comment-copy\">Thank you very much for your considerations. - Another approach might be to put the respective number of the 1 star to 5 stars ratings in relation to the number of all ratings, somehow \"smooth\" these five ratio values and then calculate the number of the 1 star to 5 stars ratings from them to finally get the desired result. What do you think?</span>",
                    "time": null
                },
                {
                    "user": "dieter reichl",
                    "text": "<span class=\"comment-copy\">Yes, but I would not call that reverse engineering anymore because not exactly the same but only similar results are received. Methods I know for that are multivariate analysis or artificial neural networks.</span>",
                    "time": null
                },
                {
                    "user": "madlen",
                    "text": "<span class=\"comment-copy\">I think, you got me wrong. My approach should serve as a possible way to discover the actual algorithm. But I don't really know how to do the \"smoothing\".</span>",
                    "time": null
                }
            ]
        },
        {
            "content": "<html><body><div class=\"s-prose js-post-body\" itemprop=\"text\">\n <p>\n  I think what you are looking for is a statistical method for computing the formula. If you fit a least squares model to the five data values you've provided, you can get a prediction formula for this data that looks like:\n </p>\n <p>\n  <code>\n   displayed_average = 3.6746154 + 0.162307923 * five_stars + 0.275384615 * four_stars -0.171548462*three_stars - 0.45 * one_star\n  </code>\n </p>\n <p>\n  which predicts the displayed average as\n </p>\n <p>\n  <a href=\"https://i.sstatic.net/3FHHe.png\" rel=\"nofollow noreferrer\">\n   <img alt=\"Predicted values\" src=\"https://i.sstatic.net/3FHHe.png\"/>\n  </a>\n </p>\n <p>\n  Obviously, this is only based upon the five data values you provided. If you had 10000 values, you could come a lot closer to the actual formula by using those additional data points. For more information on fitting least squares linear regression models in R, see\n  <a href=\"https://kenanfellows.org/kfp-cp-sites/cp19/cp19/lesson-1-least-squares-linear-regression-r/index.html\" rel=\"nofollow noreferrer\">\n   this tutorial.\n  </a>\n </p>\n</div>\n</body></html>",
            "votes": "0",
            "user": "dingo_kinznerhook",
            "time": "Sep 7, 2022 at 15:17",
            "is_accepted": false,
            "comments": [
                {
                    "user": "Ian Cook",
                    "text": "<span class=\"comment-copy\">If you fit a  linear regression model to the 2000 points provided (after normalizing the scores to a total of 1 for each observation) and look at residual plots you will see huge heteroskedasticity (especially for higher displayed averages.) The patterns of residuals are very good indication of the existence of non-linear features which the question indicates.   In your example regression it's not surprising that you get a perfect fit as you've fitted a 5 parameter model to just 5 data points.  Other than in degenerate cases this will almost always be the result.</span>",
                    "time": null
                },
                {
                    "user": "dingo_kinznerhook",
                    "text": "<span class=\"comment-copy\">I goofed and didn't realize the EtherCalc  table contains the whole dataset. I might delete this answer.</span>",
                    "time": null
                }
            ]
        }
    ]
}