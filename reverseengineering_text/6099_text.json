{
    "title": "Unknown compression algorithm",
    "link": "https://reverseengineering.stackexchange.com/questions/6099/unknown-compression-algorithm",
    "content": "I got data which is compressed but I fail to find the compression algorithm.\nThe data is part of a larger file from which I know the layout, So I managed to find out few things. What I know:\n\nI don't have the binary executable that load the data, I only have the updated version which no longer support the old copression algo. I tortured it in many way and it just doesn't contain the corresponding code\nit is compressed (100% sure of it)\nit can be home made as it was replaced later (see below)\nno magic numbers so far\nit is not plain:\n     \ndeflate (wrong header)\nlzma (wrong header)\ngzip (wrong header)\nQuantum (wrong header)\nMicrosoft CAB (wrong header)\nBzip2 (wrong header)\nZip (wrong header)\n\n\nthe uncompressed size is given in the file containing the data, this file layout is fully reversed and does not contain any clue\nit might be encrypted but is unlikely because of speed requirements\nif it is encrypted, it gives the same output given the same data input at the beginning of the sequence (by guess on some uncompressed data located nearby)\nit is from 2001 and has been replaced by deflate since\nSome of those data only output ASCII and nothing else (I know it from the layout of the container file) and have a compression ratio of about 0.30  (compressedSize/uncompressedSize) everytime\nI don't have any before/after data sadly\n\nEDIT: There are the 32 first bytes in hex:\nb9daed36cb64bedb61b9dd2cb72afd8ee565b0dd2ea00f0afda2c36eb25b0016\nI made histograms of several of those data and they all match a specific pattern. Something is going on with the powers of 2 obviously but I fail to see what.\n\nAnyone has a idea what it could be? What can I do to gather further information? Does it look Lempel-Ziv based? If yes how could I reverse it?\n",
    "votes": "5",
    "answers": 1,
    "views": "4k",
    "tags": [
        "file-format"
    ],
    "user": "search4everNever",
    "time": "Aug 19, 2014 at 14:28",
    "comments": [
        {
            "user": "Igor Skochinsky",
            "text": "If you don't have the executable how did you get this file? Also, show a dump of the 16-32 bytes of the header.\n",
            "time": null
        },
        {
            "user": "search4everNever",
            "text": "Updated to answer + hex dump of the header\n",
            "time": null
        },
        {
            "user": "perror",
            "text": "You may find this question and answers interesting to look at: > Are there any tools or scripts for identifying compression algorithms in executables?\n",
            "time": null
        },
        {
            "user": "Jongware",
            "text": "\"The output is ASCII and nothing else\" - that, coupled with a ratio of \"about 0.30\" actually suggests a simple compression scheme, rather than a complicated: a dedicated text-only compression scheme. Can we see this file?\n",
            "time": null
        },
        {
            "user": "Jason Geffner",
            "text": "Have you tried contacting the company that made the software?\n",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "First of all, you forgot lzo. AFAIR it was invented in 1996.\nSecond of all, it is possible that the compressed data has no corresponding standard header (which makes all \"incorrect header\" mistakes not necessarily true).\nThird of all, the histogram doesn't look like histogram of data compressed as one piece, it is possible that it has some internal structure (may be blobs with sizes before them ?).\n\nI'd suggest to write script that runs different decompression algorithms on parts of the data and to observe results.\n",
            "votes": "3",
            "user": "w s",
            "time": "Aug 20, 2014 at 7:09",
            "is_accepted": false,
            "comments": []
        }
    ]
}