{
    "title": "How to differentiate from different hex files of different families of microcontrollers?",
    "link": "https://reverseengineering.stackexchange.com/questions/239/how-to-differentiate-from-different-hex-files-of-different-families-of-microcont",
    "content": "Is there any way to differentiate different microcontroller's hex files? I have a hex file and now I have forgotten of which micro-controller it belongs. Is there any available tool to tell this? or any tip or trick to know? \nEdit:\nThere is a similar question here, But this question specifically belongs to PIC family while I what if we have to differentiate from different families like AVR, 8051, PIC etc.\n",
    "votes": "10",
    "answers": 4,
    "views": "614",
    "tags": [
        "decompilation",
        "c",
        "hex"
    ],
    "user": "Abdul Rehman",
    "time": "Apr 13, 2017 at 12:49",
    "comments": [
        {
            "user": "user187",
            "text": "Related: reverseengineering.stackexchange.com/q/233/187\n",
            "time": null
        },
        {
            "user": "user187",
            "text": "Perhaps you could specify the microcontroller brand already? ARM, PIC, ..?\n",
            "time": null
        },
        {
            "user": "Abdul Rehman",
            "text": "I have edited my question, making it more clarifying\n",
            "time": null
        },
        {
            "user": "Peter Andersson",
            "text": "Maybe someone could contribute common byte patterns you're likely to see for different architectures? Is that the question you're asking?\n",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "My first idea would be to perform a frequency analysis on aligned bytes. For most of the assembly languages, the most relevant bytes are aligned on the most significant bits. \nSo it might be quite easy to create a distinguer that can recognize the type of asm. But, suprisingly, after a few googling, I didn't find any tool or paper about this... \nMaybe there is something to do here.\n",
            "votes": "6",
            "user": "perror",
            "time": "Mar 24, 2013 at 17:39",
            "is_accepted": false,
            "comments": []
        },
        {
            "content": "I don't know of tools designed for this. In practise, loading it into IDA (or any other disassembler) with different architectures until it looks right is probably the easiest way to do it. You might be able to write a script to automate this.\nIf you want to build your own tool, I suggest you look at Christopher Domas's talk \"The future of RE Dynamic Binary Visualization\". It discusses a number of techniques that can be used to analyse unknown data. The general idea graph the frequency of every group of two or three bytes in each file. The graphs are distinctly different between different architectures, and could be used to automatically identify data types. The actual tool, and the dataset you would need, is not publicly available, but this is the way I would go if I wanted to do automatic architecture detection.\nA simpler approach would be to search for function prologue patterns in different architectures. Although the implementation is simpler, it would take more human-time to prepare the dataset (because identifying function prologues cannot be automated). Some processors may not be powerful enough to run C code, and if the code is not compiled it's possible to not have predictable function prologues. You may be able to find other common operations that you could search for.\n",
            "votes": "5",
            "user": "Dougall",
            "time": "Mar 25, 2013 at 2:25",
            "is_accepted": false,
            "comments": [
                {
                    "user": "nopnopgoose",
                    "text": "<span class=\"comment-copy\">My first thought was Domas's Cantor Dust tool as well, but I can't seem to find the demo version online anywhere. Absent that, a simple histogram of 2 or 3 bytes sequences in the file can give a quick picture of what kind of data is in it and lead to some common instructions.  Some hex editors have histogram functionality built in if you don't want to write up your own tool.</span>",
                    "time": null
                },
                {
                    "user": "ixje",
                    "text": "<span class=\"comment-copy\">@nopnopgoose a 'demo/alpha' version of Cantor Dust can be downloaded from the <a href=\"https://media.blackhat.com/bh-us-12/Arsenal/Domas/_cantor.dust_.7z.zip\" rel=\"nofollow noreferrer\">black hat media archives</a>. If you rename your binary to \"visual_re.example\" under /resources/ you can play around with it a bit.</span>",
                    "time": null
                }
            ]
        },
        {
            "content": "Intel HEX format can be seen as a way to represent the contents of a memory at different addresses. This means that the HEX file has info about existing addresses in your target architecture and the contents of those...\nI would recommend you try some tools that allow you to convert the HEX files to binary files. There are many depending on your preferences.\nHaving a look at the populated address ranges would be helpful as different architectures have different memory maps. This may help discard many architectures...\nLooking at the contents of the binary itself you may also obtain a lot of information:\n\nIs the binary split in code and data sections or is it all mixed? Some architectures may mix those, some would put all the strings at the end...\nThere are some tools that may be able to provide information about the architecture of a certain binary. See https://github.com/airbus-seclab/cpu_rec or https://github.com/OSPG/binwalk (Binwalk is only able to do this if capstone is also installed).\nYou may infer if the target binary architecture width and endianness by looking at the frequency of variance of the bytes given their position. Lower endian bytes tend to vary more depending on the architecture constraints.\nOther statistical measurements may also provide signatures: byte distribution, variance, entropy...\n",
            "votes": "0",
            "user": "Antonio VÃ¡zquez Blanco",
            "time": "Apr 12 at 16:35",
            "is_accepted": false,
            "comments": []
        },
        {
            "content": "Try to get an idea of what kinds of CPUs it could target. You can probably also guess the bit length of the CPU by looking at this file (file_size % 32 == 0? Probably 32 bit). Once you have a simple list, run the binary through some disassemblers and see if the code makes sense. Try running it in some emulated CPUs and see if it does anything.\nAlso, keep in mind that invalid instructions might not mean you've got the wrong CPU, it could just be data or something. It's actually probably worth checking out the file to see if you can't find any strings or anything, just to get a better sense of where things are.\n",
            "votes": "-2",
            "user": "Drew DeVault",
            "time": "Mar 24, 2013 at 19:34",
            "is_accepted": false,
            "comments": [
                {
                    "user": "user187",
                    "text": "<span class=\"comment-copy\">We're talking about microcontrollers here, there are 8-bit and 16-bit MCUs as well. This is <i>not</i> about a computer.</span>",
                    "time": null
                },
                {
                    "user": "Drew DeVault",
                    "text": "<span class=\"comment-copy\">Oh, whoops, misread the question. Apologies.</span>",
                    "time": null
                }
            ]
        }
    ]
}