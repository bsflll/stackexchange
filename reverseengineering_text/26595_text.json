{
    "title": "Shannon Entropy of Individual PE sections",
    "link": "https://reverseengineering.stackexchange.com/questions/26595/shannon-entropy-of-individual-pe-sections",
    "content": "Why is Shannon Entropy of individual sections always between 0-8. Also why we need to create a 256 freq array while calculating the Shannon Entropy?\n",
    "votes": "2",
    "answers": 1,
    "views": "85",
    "tags": [
        "malware"
    ],
    "user": "Rishabh Jain",
    "time": "Dec 20, 2020 at 20:12",
    "comments": [
        {
            "user": "David",
            "text": "The mathematical answer is here: stats.stackexchange.com/questions/95261/…\n",
            "time": null
        },
        {
            "user": "David",
            "text": "An intuitive answer is here, which also answers your question about the frequency array (hint: each byte represents one of 256 discrete states): towardsdatascience.com/…\n",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "The channel capacity of a single byte samples has a maximum of 8 bits.\nAnother way of thinking about it: If a single byte has the same value for every sample, you need 0 additional bits of information to describe the values.\nIf a single byte takes on 256 different values, [0 to 255], then for every sample you will need 8 additional bits of information to uniquely describe the values.\nFor example, if you were measuring the Shannon Entropy of a collection of Short values (2 bytes / 16 bits) it would range from 0 (constant) to 16 (completely random).\n",
            "votes": "2",
            "user": "pythonpython",
            "time": "Dec 21, 2020 at 15:44",
            "is_accepted": true,
            "comments": []
        }
    ]
}