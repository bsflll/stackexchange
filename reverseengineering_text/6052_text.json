{
    "title": "What methodology can be used to change code flow atomically during program execution?",
    "link": "https://reverseengineering.stackexchange.com/questions/6052/what-methodology-can-be-used-to-change-code-flow-atomically-during-program-execu",
    "content": "I have been reading a lot about the different techniques for Windows API hooking  (a technique I'm particularly fascinated by and fond of), and it seems a major problem in implementing a realiable hook function is ensuring that the hook is written in a way that is thread-safe. Of course, there are some techniques where this problem has been solved or can be solved trivially, such as hotpatching the Windows API, but hot patching is not guaranteed to work on all win32 or third party API functions and the techniques that do support hooking them are not normally thread-safe.\nA very common technique that is has problems caused by multithreading is a inline hook that replaces the normal function prologue code with a jump instruction to the hook procedure, and then calls the original function as needed through a trampoline.\nThere are several inherent issues to the inline hook technique, which makes it a very complicated method to use and debug. A primary issue is as I mentioned, that it is not safe in a orthodox multithreaded environment in the real world. This is due to that when changing the bytes of the function, you can not guarantee that the instruction pointer will not be in the middle of your newly injected code, which may then cause the target application to crash from executing an invalid mix of the old opcodes mixed with the opcodes you inserted.\nThere are some solutions to this problem, with one being suspending all the threads in the process and then checking the instruction pointer in each thread to ensure that no thread is currently executing the target instructions you wish to replace. Then if there happens to be a thread or two executing that particular function, then you can respond accordingly by doing something such as performing a stack trace to place a breakpoint at the return address, resuming the thread, and then handling the exception when the thread has returned from the target function.\nOf course, this method is still unsafe, because there is nothing stopping one sneaky thread from using <pre><code>CreateThread()</code></pre> before you can suspend all of the running threads in the process (some applications on my computer run with 40+ threads at once). There could even be a related process that uses <pre><code>CreateRemoteThread()</code></pre> in your target application and then calls the function you are hooking before it's safe.\nA solution to that problem could be trying to debug the process and receive notifications of when a process creates a new thread, and then respond by suspending that thread. Of course, many event notification systems provided by the Windows    API or a third party API will not be sent in real time, which may allow that thread to perform an unsafe operation before it is suspended.\nAnother solution could be to statically patch the executable with the hook function before the process is launched, presumably by hooking the EAT/IAT. This is not an option for me because I need to have an implementation that will work process wide, regardless of how a function is resolved or in the event of a new unhooked module calling the function.\nThere are many other issues to overcome with the inline hook technique that I did not mention.  Which brings me back again to my question:\n\nWhat methodology can be used to change code flow atomically during program execution ?\n\nI was curious to see if there was a more robust solution out there that overcomes some of the shortcomings of the methods I covered in this post.\nPlease no third party library suggestions for hooking functions. I want to implement my own for the educational benefits.\nI prefer hooking technique documentation and examples that use the C programming language.\nMy processor is an AMD Athlon II X2 250 that is x86-x64 compatible, and my operating system is Windows 7.\n",
    "votes": "11",
    "answers": 3,
    "views": "1k",
    "tags": [
        "windows",
        "x86",
        "c",
        "function-hooking",
        "x86-64"
    ],
    "user": "CaptainObvious",
    "time": "Jul 4, 2022 at 19:17",
    "comments": [
        {
            "user": "0xec",
            "text": "Check out this paper; particularly in the section <pre><code>5.2 Capturing the CPUs to update safely</code></pre>\n",
            "time": null
        },
        {
            "user": "CaptainObvious",
            "text": "Interesting, but I do not know of an equivalent operation to use on Windows for the linux function <pre><code>stop_machine</code></pre>.\n",
            "time": null
        },
        {
            "user": "Ta Thanh Dinh",
            "text": "I think a dynamic code instrumentation framework (e.g. PIN, DynInst) may help, because the instrumentation will be realized \"transparently\" from the program's codes. For example, the paper about DynInst An API for Runtime Code Patching says: \"...The API is designed so that a single instrumentation process can insert snippets into multiple processes executing on a single machine...\". Here, snippets are injected codes.\n",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "A sketch of how to implement your own patching system, where the length of the replacement instruction is less than or equal to the length of the instruction that you want to patch:\n\nMake sure that none of your code depends on any of the code that you will want to patch. This is an issue of re-entrancy. If you patch code that your patching system will use, then you might deadlock / block / raise an infinite number of signals. A common solution is to do things like re-implement the subset of <pre><code>libc</code></pre> that you need, or statically link against some other implementation of <pre><code>libc</code></pre>. Symbol versioning can help ensure that no other libraries link against your version of <pre><code>libc</code></pre> (or <pre><code>libc</code></pre>-like functions) at runtime.\nHave a dedicated patching \"master\" thread. If you're on linux, then this patching thread can be an external process that controls the program via <pre><code>ptrace</code></pre>. An alternative is to dynamically elect a master thread from one of the threads that gets signalled (mentioned in the next point).\nInstall a signal handler such that your patching thread can signal all other threads to stop and block on a condition variable. Obviously, make sure that your patcher thread does not signal itself. You might need to double check that in the time it took you to signal all threads (that you knew about), that no more new threads have been created.\nNow you can patch code. Change the memory protection of the pages of code containing what you want to patch so that they are readable, writeable, but not executable. Make sure the code you're using doesn't appear on the same page(s)! Change the code. Change the memory protection of that code back to readable, executable, but not writeable.\nSignal your condition variable / threads to wake up.\nWhen your threads wake up from being blocked on the condition variable in their signal handlers, they need to execute a synchronizing instruction, e.g. <pre><code>CPUID</code></pre>, before executing the patched code. This is so that the old versions of the code do not remain in any instruction prefetch caches/buffers/whatever. Intel's software optimization manual goes into a few details here. By the way, watch out about patching the concurrency/signal mechanisms that you use to implement signal/wait/etc!\nThen the threads will return from the signal handler to resume execution where they were signalled.\n\nNow, what to do if you want to patch an <pre><code>N</code></pre> byte instruction with an <pre><code>M</code></pre> byte instruction such that <pre><code>M > N</code></pre>? We'll apply roughly the same technique, but we'll modify the return addresses of the signalled threads to point into a copy of the original instructions that include your patch <pre><code>P</code></pre>.\nFor example, lets say you have instructions <pre><code>I1; I2; I3; I4; ...</code></pre>, and your patch <pre><code>P</code></pre>, if placed, would end up as: <pre><code>P; I3_tail_garbage; I4; ...</code></pre>.\nThen you could create a patch entrypoint <pre><code>P; I1_copy; I2_copy; I3_copy; jmp &I4;</code></pre> at address <pre><code>patch</code></pre>. You will modify some of the the return addresses in the signal handlers as follows:\n\nIf <pre><code>RA == &I1</code></pre>, then make it point to: <pre><code>P; I1_copy; I2_copy; I3_copy; jmp &I4;</code></pre>.\nIf <pre><code>RA == &I2</code></pre>, then make it point to: <pre><code>I2_copy; I3_copy; jmp &I4;</code></pre>\nIf <pre><code>RA == &I3</code></pre>, then make it point to: <pre><code>I3_copy; jmp &I4;</code></pre>\n\nPatch <pre><code>I1; I2; I3; I4; ...</code></pre> to do the following: <pre><code>jmp patch; int3; ...; int3; I4; ...</code></pre>.\nNote: When copying code, you need to re-relativize it if your instructions somehow read from the instruction pointer. For example, if <pre><code>I1</code></pre>, <pre><code>I2</code></pre>, or <pre><code>I3</code></pre> are branch instructions, or compute a <pre><code>RIP</code></pre>-relative address, then they will potentially need to be widened/modified/replaced with equivalent instructions.\nAnother approach is to patch each of <pre><code>I1</code></pre>, <pre><code>I2</code></pre>, and <pre><code>I3</code></pre>. If you do this, then you must start by patching only the first byte of each of these instructions, and only with an <pre><code>int3</code></pre>. This can be done safely, even while other threads are executing the code being patched. However, you cannot safely modify the other bytes of these instructions if other threads are concurrently executing those instructions. This is because those instructions might have been prefetched, and once that has happened, they are no longer a cohesive unit.\nFiguring out the right protocol to handle the cases where threads concurrently execute the <pre><code>int3</code></pre>s is tricky, but I think it can be handled by following a similar methodology to above approach of duplicating the first few instructions so that you guarantee that those instructions aren't lost, but you also capture threads executing code that falls within your patch region.\nI am not familiar with the Windows environment, so the <pre><code>CreateRemoteThread</code></pre> issue sounds tricky, but I think installing <pre><code>int3</code></pre> instructions into the code as well as protecting the code from execution while you search for threads to signal might be sufficient. You might also consider having your master patching thread go to sleep for a short period of time. \nFinally, some good references to look at are Kprobes and RCU stuff as well, as the problem faced by some \"extra\" thread seeing the old or the new version (or something in-between) is a major concern with RCU. As a concluding remark, watch out about the language of the Intel manual w.r.t. cache coherency and the icache. A lot of text can be interpreted as if atomic writes to the data caches will be represented in the icache, but in practice, this isn't guaranteed to be true (especially where prefetching is concerned), and there are some important CPU errata on the issue that make the problem harder than it first appears.\n",
            "votes": "4",
            "user": "Peter Goodman",
            "time": "Aug 15, 2014 at 18:19",
            "is_accepted": false,
            "comments": []
        },
        {
            "content": "This is a good question, and I would argue there is no 100% safe method to patch a running windows process, unless you actively debug it, and even then there are probably edge cases.  You could eliminate many potential problems, but I feel that potential threading problems couldn't be entirely eliminated for generic purposes.\nThis leaves a couple practical options in my opinion:\n1.)  Suspend the process, patch your code, and resume execution.  Either all threads are suspended or they aren't, this is easily detectable if you have the rights to patch the process to begin with. This is my preferred method, though anti-debug measures based on timers as well as defensive hooks can detect this.  Overall though I'd say it's quite dependable.\n2.)  Know your target well and don't depend upon \"generic\" one-size-fits-all patching techniques.  You should know beforehand whether or not multi-threading is going to hamper a particular patch at a particular address for a specific target, and how feasible it will be to perform reliable realtime patching.\nIf you know or suspect that your target code is threaded, find the synchronization method used (locks, mutexes, interlocked operations, etc.) and begin your patch from thread-safe code, ideally after forcing temporary thread contention/deadlock to prevent execution while patching.  Reliably doing this will likely be very target specific and therefore require at least a tiny bit of fairly intimate knowledge of your target.\nMost important of all:  Know which instructions on your current hardware are atomic.  Without this knowledge to start with you can't possibly create an atomic patch.\nYou then have the problem of making a series of atomic writes (of atomic instructions) such that execution mid-patch doesn't crash/hang/alter execution in unintended ways.  This is not a trivial problem to solve.  Suspend the process and play it safe.\nEDIT:  I just realized that I took the bait and answered in a way that only considered hooking, i.e patching, even though your question specifically asks how to change code flow atomically during execution.  Proper DLL injection should allow you to do this pretty reliably in most cases, though like always it's never a sure thing when you are modifying a running process.\n",
            "votes": "2",
            "user": "Matthew Geyer",
            "time": "Jan 7, 2016 at 12:34",
            "is_accepted": false,
            "comments": [
                {
                    "user": "0xC0000022L",
                    "text": "<span class=\"comment-copy\">From kernel mode there is ... or does that qualify as cheating? ;)</span>",
                    "time": null
                }
            ]
        },
        {
            "content": "Here's an older article on how hotpatching was implemented in Windows. If you want it done absolutely atomically, it has to be done from the kernel mode. There's no way around it. Here's the walkthrough:\n\nSet your thread's IRQL to <pre><code>CLOCK1_LEVEL</code></pre> (heck, you can even try <pre><code>HIGH_LEVEL</code></pre>), which is way above 2, that will pretty much stop all task switching in that system for the time your patching code is running. It is also high enough to preempt most interrupts. Or, you can try to disable them with a <pre><code>CLI</code></pre> instruction.\nAlso schedule CPU-specific DPCs on all CPUs but your thread to keep those DPCs busy. (This is needed in case of a multi-core CPU.)\n\nThis basically turns your patching thread into a single threaded environment for a short while.\n\nTo ensure that no other running thread was stopped on that short span of executable memory where you're applying your 5-byte JMP, walk through the context of each thread and check its RIP value. In an unlikely event that it overlaps, either cancel the patch and retry after a short while, or raise the thread's IRQL for a very short while and then lower it back. Then check again. Repeat N times until its RIP doesn't overlap with the patch.\nFinally apply the patch. Make sure to do it as quickly as possible. Try not to call any outside functions. Just do a quick <pre><code>REP MOVS</code></pre> on a prepared memory blob.\nYou'll probably need to clear the processor's instruction cache. (In case the old code before the patch was in there.)\nThen undo all the steps above to restore the system back into the working state.\n\nPS. Should work in theory. In practice, debugging this will be a living hell. Obviously do it in a VM and be ready to reboot (a lot.)\n\nEdit: Here's an actual example, taken from the DebugView tool. If you know what it does, it tries to capture a program's debugger output. If you enable kernel debugger output on an older OS, that tool has no other option but to install a trampoline on a DbgPrint function on a live system when the DebugView starts up. \nHere's how it does it (it uses somewhat old kernel functions, but it still delivers the idea):\n1. Get number of CPU cores (it uses an older <pre><code>KeNumberProcessors</code></pre> global variable as such):\n\n(For modern code I would probably use <pre><code>KeQueryActiveProcessors()</code></pre> with its bitmask, and <pre><code>KeQueryGroupAffinity()</code></pre> to account for number of CPUs greater than 32/64.)\n2. Make sure that the current thread is running on the CPU core 0 by calling <pre><code>KeSetAffinityThread</code></pre>:\n\n(Then check global variable <pre><code>bDontSet_FuncTrampoline</code></pre> in case we don't need to set this trampoline & restore thread affinity by jumping to step 6. But that case is not interesting.)\n3. Then check if we just have one CPU core, and if so jump to step 5. (Not very interesting either.) Otherwise set global variable <pre><code>nCountCpuCores</code></pre> to the count of CPU cores, and reset global <pre><code>bAllowToContinue_CoreNon0_DeferredRoutine</code></pre> flag to 0:\n\n4. Set each CPU core (other than 0, i.e. <pre><code>rsi</code></pre> pointer starts from index 1, or 0x8 offset in bytes) for <pre><code>high importance</code></pre> DPCs (deferred procedure calls) for our <pre><code>DeferredRoutine</code></pre> with the <pre><code>context</code></pre> set to CPU core number:\n\nThis will basically preempt whatever those other cores were doing and direct them to our DPC.\n5. Then for our thread running in core 0, execute DPC routine <pre><code>DeferredRoutine</code></pre>:\n\n6. After which restore this thread's affinity to what it used to be before:\n\n\nNow the interesting thing is what happens in <pre><code>DeferredRoutine</code></pre>:\n(Note that this routine will be executed on each CPU core.)\nA. The first step, set IRQL for the thread to <pre><code>CLOCK_LEVEL</code></pre> (or <pre><code>13</code></pre> for x64 code.) This is done by using the <pre><code>cr8</code></pre> CPU register. Doing this will block processing of the most interrupts:\n\nB. Then decrement the counter in <pre><code>nCountCpuCores</code></pre> global variable, but do it using a <pre><code>lock</code></pre> CPU prefix to ensure synchronization among all CPU cores:\n\nC. Check what CPU core this thread runs on and enter a spin-loop accordingly:\n\nC.1. (Right side block in the code flow above.) For non-0 cores continue spinning in a loop while global variable <pre><code>bAllowToContinue_CoreNon0_DeferredRoutine</code></pre> is 0.\nC.2. (Left side block in the code flow above.) For core 0, continue spinning in a loop while the count of processed cores in the <pre><code>nCountCpuCores</code></pre> global variable doesn't reach 0.\n(I would personally add to each of those loops a <pre><code>pause</code></pre> instruction to ensure that CPU doesn't waste too much power while \"spinning\".)\nC.3. Once the condition C.2. has been met, it means that we have our core 0 all to ourselves and all other cores are busy spinning in the loop in C.1. and we can proceed by calling our <pre><code>install_func_Trampoline</code></pre> function to install required trampoline.\nC.4. When we're done with the trampoline, remember to release all cores from the spin-loop in C.1. by setting <pre><code>bAllowToContinue_CoreNon0_DeferredRoutine</code></pre> to 1.\nD. Lastly, very important, restore IRQL back to what it used to be:\n\nReturn error <pre><code>nt_status</code></pre> code, if so. Otherwise, we're done!\n",
            "votes": "2",
            "user": "c00000fd",
            "time": "Jun 25, 2018 at 6:26",
            "is_accepted": false,
            "comments": [
                {
                    "user": "RbMm",
                    "text": "<span class=\"comment-copy\">really all this is sesnseless and nothing give. assume thread execute instructions in place where we apply patch . say <code>push rbp; /** interrupt **/ sub rsp,10</code> let thread X executed <code>push rbp</code> and then clock interrupt , from where already we return on another thread in another place. then you apply patch (say set jmp here ) and then thread X continue execution from place where it was interrupted. already inside jmp instruction. and even without thread swap - you interrupt thread by DPC - but to where thread returned after DPC ? without change thread context - all this senseless</span>",
                    "time": null
                }
            ]
        }
    ]
}