{
    "title": "Why are special tools required to ascertain the differences between two related binary code files?",
    "link": "https://reverseengineering.stackexchange.com/questions/1902/why-are-special-tools-required-to-ascertain-the-differences-between-two-related",
    "content": "How comes that text diffing tools like <pre><code>diff</code></pre>, <pre><code>kdiff3</code></pre> or even more complex ones usually fail at highlighting the differences between two disassemblies in textual form - in particular two related binary executable files such as different versions of the same program?\nThis is the question Gilles asked over here in a comment:\n\nWhy is diff/meld/kdiff/... on the disassembly not satisfactory?\n\nI thought this question deserves an answer, so I'm giving an answer Q&A style, because it wouldn't fit into a 600 character comment for some strange reason ;)\nPlease don't miss out on Rolf's answer, though!\n",
    "votes": "27",
    "answers": 3,
    "views": "4k",
    "tags": [
        "tools",
        "disassembly",
        "assembly",
        "bin-diffing"
    ],
    "user": "0xC0000022L",
    "time": "Apr 13, 2017 at 12:49",
    "comments": [],
    "answers_data": [
        {
            "content": "Index (shortened)\n\nGentle Intro - binary executable code, how does it look?\nWhy it is a hard task to compare binary executable code?\nConclusion\nSolutions\nTL;DR\n\nTL;DWTR (too long, don't want to read): skip ahead to the section Why it is a hard task to compare binary executable code? if you feel comfortable with the basics around assembly and disassembly. Alternatively skip to the bottom of this answer (TL;DR).\nGentle Intro - binary executable code, how does it look?\nBinary executable code is made for computers to read, this is why it is commonly referred to as machine code. This means it is binary \"data\" that is usually represented as hexadecimal numbers to the naked eye. A category of tools named \"hex editors\" exists for this task.\nHere's how this commonly looks, using HTE for the screenshot:\n\nThe reason this is so convenient is because each hex digit represents exactly one nibble, that is 4 bits. So two hex digits can be used to represent a single 8-bit byte (the most common type of byte). Then showing them in multiples of 16 bytes per line has the additional advantage of making it easier to read the hexadecimal offset (given as 8-digit hexadecimal number in front of the hex bytes in the screenshot above), because decimal <pre><code>16</code></pre> is <pre><code>0x10</code></pre>. The most common notations for hexadecimal numbers are:\n\nprefix <pre><code>0x</code></pre>: e.g. <pre><code>0x10</code></pre> (C and related languages)\nprefix <pre><code>$</code></pre>: e.g. <pre><code>$10</code></pre> (Pascal, Delphi)\nsuffix <pre><code>h</code></pre>: e.g. <pre><code>10h</code></pre> (assembly language)\n\nSide-note: the line between code and data is a thin one and disassemblers sometimes struggle to identify the bytes in a binary file as one or the other, although heuristics can be applied to help in the process of identification.\nAssembly\nAside from the \"raw\" form of hexadecimal numbers there is also the human-readable representation known as assembly language. This is a mnemonic form of the binary instructions (or opcodes) and usually represents them 1:1 with very minor abstractions. The notable exception to this are macro assemblers such as Microsoft's MASM which provide a higher levels of abstraction as a convenience.\nSide-note: the program that digests assembly language code (also \"assembly code\" or \"assembler code\") is called an assembler.\nDepending on the type of processor and the exact architecture, various flavors of assembly language exist. For the scope of this question we'll stick with the IA-32 architecture - also known as x86 (32bit, x86), because its origins lie with the 8088 and 8086 processors, with subsequent processor (CPU) models being numbered <pre><code>80x86</code></pre>, where <pre><code>x</code></pre> was a one-digit number. Starting with the 80586 Intel departed from that naming scheme as they introduced the Pentium.\nNevertheless, it is good to know that two main processor architectures exist: CISC (68k, x86, x86-64) and RISC (SPARC, MIPS, PPC), whereas the aficionados of one or the other have claimed victory for their preferred architecture at one time or another, both still exist to this very day, although at the microcode level one could even argue CISC architectures to be RISC \"internally\". That said, x86 is a CISC architecture.\nJust to give you glimpse of what RISC and CISC look like in comparison, let's look at a few basic x86 and MIPS instructions:\n<pre><code> x86          |    MIPS              | Meaning\n-----------------------------------------------\n mov          | lb, lw, sb, move     | copy/\"move\" value from/to register/memory location\n jmp, jz, jnz | j/b, beq, beqz, bgez | jump unconditionally or on condition\n call         | jal                  | call other routine / jump and link\n</code></pre>\nWhat hopefully becomes clear at first glance (line with <pre><code>mov</code></pre>) is the fact that in MIPS you heave a much larger number of very basic instructions than x86, which is the gist of the CISC versus RISC paradigm. Another thing is that we see how MIPS uses <pre><code>j</code></pre> and <pre><code>b</code></pre> as the mnemonic prefix for jump and branch (the difference being generally the distance these \"jumps\" can cover), whereas x86 uses also <pre><code>j</code></pre> as in <pre><code>jmp</code></pre> (unconditional jump), <pre><code>jnz</code></pre> (jump if not zero[-flag set]) but also has a dedicated <pre><code>call</code></pre> opcode which MIPS to my knowledge doesn't have - the closest approximation probably being <pre><code>jal</code></pre> (jump and link) which also stores the program counter in a register as opposed to x86's <pre><code>call</code></pre>, though, which stores it on the stack.\nIn CISC you can do a relatively complex operation with a single instruction, where in RISC you often need several instructions to express the same thing. In fact assemblers for RISC architectures tend to have so-called pseudo-instructions which combine oft-used combinations of instructions, but which get translated to individual RISC instructions during the translation phase.\nAn example would be the <pre><code>ror</code></pre> (bit-rotate right) instruction. On an x86 (CISC) this is an opcode in its own right with the <pre><code>ror</code></pre> mnemonic. On MIPS (RISC) this is a pseudo-instruction if and when the assembler offers it and it gets translated as follows (bit-rotate the value in register <pre><code>$t2</code></pre> by one bit and store result in <pre><code>$t2</code></pre> again):\n<pre><code>ror $t2, $t2, 1    -->   sll $1 , $10, 31  (bit-shift $10 left by 31, store in $1)\n                         srl $10, $10, 1   (bit-shift $10 right by 1, store in $10)\n                         or  $10, $10, $1  (bit-wise or $1 and $10)\n</code></pre>\nThis example is taken from the book referenced a bit further down from here (MIPS resources), page 370.\nHowever, we won't dig further into assembly language basics and instead focus on answering the question. I think it is not necessary to understand much more than the most fundamental facts to understand why simple and even complex diff tools fail at showing the differences of binary executable files.\nCompilers and assembly language\nCompilers (compilers) convert code constructs usually written by humans or machines into machine code [*]. The usual translation is to translate the human-readable source code into an intermediate form which gets then optimized and after optimization translated to assembly language which in turn gets translated to machine code. This is shown beautifully in the Wikipedia article above, with the diagram I am reproducing here below:\n\nThe gist is, that compilers usually have an assembler somewhere in their back end, even though you may never get to see the actual assembly language instructions yourself. If you wanted to get it, you would use:\n\nWith GCC: <pre><code>gcc -S ...</code></pre> (AT&T syntax) or <pre><code>gcc -masm=intel -S ...</code></pre> (Intel syntax)\nWith Microsoft Visual C++: <pre><code>cl.exe /Fa ...</code></pre>\n\n[*] this is not the entire truth, as there are compilers which will create an intermediate byte code which then later gets translated further into machine code native to the CPU it is running on or interpreted on-the-fly. But for the scope of this answer we'll consider compilers to be the entities that convert human-readable high-level language source code into machine code through a number of processing stages, one of which involves assembly code.\nNB: some compilers, such as Embarcadero Delphi will hide the different stages from you and present the process from compiling to linking as one opaque step. This can cause some confusion in Delphians attempting to learn C/C++ which expose the different steps.\nIntel versus AT&T syntax\nFor x86 there exist two competing syntax variants. The AT&T syntax is favored in the *nix world and by GASM, Intel in the Windows world and most disassemblers and assemblers. Consider this simple C program:\n<pre><code>#include <stdio.h>\n\nint main()\n{\n    printf(\"Hello world!\n\");\n    return 0;\n}\n</code></pre>\n... and the translations with the AT&T (<pre><code>gcc -S hello.c</code></pre> or explicitly <pre><code>gcc -masm=att -S hello.c</code></pre>) and Intel (<pre><code>gcc -masm=intel -S hello.c</code></pre>) syntax respectively:\n<pre><code> AT&T                        |  Intel\n------------------------------------------------------------------------\n.LC0:                        | .LC0:\n    .string \"Hello world!\"   |     .string \"Hello world!\"\n    .text                    |     .text\n.globl main                  | .globl main\n    .type   main, @function  |     .type   main, @function\nmain:                        | main:\n    pushl   %ebp             |     push    ebp\n    movl    %esp, %ebp       |     mov ebp, esp\n    andl    $-16, %esp       |     and esp, -16\n    subl    $16, %esp        |     sub esp, 16\n    movl    $.LC0, (%esp)    |     mov DWORD PTR [esp], OFFSET FLAT:.LC0\n    call    puts             |     call    puts\n    movl    $0, %eax         |     mov eax, 0\n    leave                    |     leave\n    ret                      |     ret\n</code></pre>\nYou'll notice how the syntax differs. Registers in AT&T syntax are denoted with the <pre><code>%</code></pre>, literal values with <pre><code>$</code></pre> and the position of source and destination register is the inverse of the Intel syntax. Furthermore some of the mnemonics differ (<pre><code>movl</code></pre> instead of <pre><code>mov</code></pre>). In Intel syntax the size of the operands helps to infer the intended operation - in case of registers this is made explicit by using EAX, AX and AL/AH respectively to denote the <pre><code>DWORD</code></pre> (32bit), <pre><code>WORD</code></pre> (16bit) and <pre><code>BYTE</code></pre> (8bit) sizes. However, the line:\n<pre><code>mov DWORD PTR [esp], OFFSET FLAT:.LC0\n</code></pre>\nshows neatly how you have to be explicit about the size of memory locations to get it right. The AT&T <pre><code>movl</code></pre> mnemonic implies this because of its inherent meaning of \"move long\" (32bit here), so no need to mention that we are accessing a <pre><code>DWORD</code></pre> other than in the <pre><code>l</code></pre> in <pre><code>movl</code></pre>.\nPlease note: I trimmed some irrelevant parts at the top and the bottom of the generated assembly code for brevity.\nMIPS resources\nFor the inclined reader I would recommend getting a copy of the excellent, albeit pricey:\n\n\"Introduction to Assembly Language Programming\", 2nd ed., by Sivarama P. Dandamudi, Springer 2004/2005 (ISBN 978-0-387-20636-3)\n\nIf you want to experiment with MIPS, you can get SPIM, refer to its documentation or simply use a search engine to find useful information such as this Quick Tutorial.\nx86 resources\n\nThe book mentioned above in the MIPS resources also discusses x86 assembly\nRandall Hyde's \"Art of Assembly\" book\nIczelion's old website\n\nAgain, use a search engine to find more information or consult the documentation of your favorite assembler, such as NASM.\nDisassembly\nThe process of translating the binary machine language back to a mnemonic representation, usually 1:1, is called disassembling or disassembly. The result of the process is commonly referred to as disassembly as well.\nThe tool used for the process is called a disassembler.\nSince this is mostly a 1:1 process just like the reverse (assembly to machine code) there is no need to go into much more detail. There is one big difference between hand-written or compiler-generated assembly versus disassembly of the resulting binary code, and we'll see that a bit better by comparing the output of a disassembler and a compiler.\nSo without much further ado let's go to a practical example that shows why diffing is hard.\nWhy it is a hard task to compare binary executable code?\nNote: For the remainder of this answer we'll use the Intel syntax for the assembly code. We'll also have some redundant parts of GCCs output removed for brevity.\nSample program - first iteration\nC version\nIn our first iteration we have the following C code (I named it <pre><code>ptest1.c</code></pre>):\n<pre><code>#include <stdio.h>\n\nint syntax_help(int argc)\n{\n        return 20 + argc;\n}\n\nint main(int argc, char **argv)\n{\n        if (argc < 3)\n                return syntax_help(argc);\n        else if (argc == 3)\n                return 42;\n        // else ...\n        return 0;\n}\n</code></pre>\nAssembly language version (with GCC, Intel syntax)\n... compiling this into assembly with <pre><code>gcc -O0 -masm=intel -S -o ptest1.asm ptest1.c</code></pre> gives us:\n<pre><code>.globl syntax_help\n        .type   syntax_help, @function\nsyntax_help:\n        push    ebp\n        mov     ebp, esp\n        mov     eax, DWORD PTR [ebp+8]\n        add     eax, 20\n        pop     ebp\n        ret\n        .size   syntax_help, .-syntax_help\n.globl main\n        .type   main, @function\nmain:\n        push    ebp\n        mov     ebp, esp\n        sub     esp, 4\n        cmp     DWORD PTR [ebp+8], 2\n        jg      .L4\n        mov     eax, DWORD PTR [ebp+8]\n        mov     DWORD PTR [esp], eax\n        call    syntax_help\n        jmp     .L5\n.L4:\n        cmp     DWORD PTR [ebp+8], 3\n        jne     .L6\n        mov     eax, 42\n        jmp     .L5\n.L6:\n        mov     eax, 0\n.L5:\n        leave\n        ret\n</code></pre>\nSample program - second iteration\nNow let us modify the program a little and then assemble it again, just to see how it looks.\nC version\n<pre><code>#include <stdio.h>\n\nint syntax_help(int argc)\n{\n        switch (argc)\n        {\n        case 0:\n                return -1;\n        case 1:\n                return 23;\n        default:\n                return 20 + argc;\n        }\n}\n\nint main(int argc, char **argv)\n{\n        if (argc < 5)\n                return syntax_help(argc);\n        else if (argc == 5)\n                return 42;\n        // else ...\n        return 0;\n}\n</code></pre>\nAs you can see the two instances of <pre><code>3</code></pre> in <pre><code>main</code></pre> changed to <pre><code>5</code></pre> and we tinkered a bit with the \"logic\" in <pre><code>syntax_help</code></pre>. Clearly this is a contrived example, but then that's the exact point.\nAssembly language version (same options as above)\n<pre><code>.globl syntax_help\n        .type   syntax_help, @function\nsyntax_help:\n        push    ebp\n        mov     ebp, esp\n        mov     eax, DWORD PTR [ebp+8]\n        test    eax, eax\n        je      .L3\n        cmp     eax, 1\n        je      .L4\n        jmp     .L7\n.L3:\n        mov     eax, -1\n        jmp     .L5\n.L4:\n        mov     eax, 23\n        jmp     .L5\n.L7:\n        mov     eax, DWORD PTR [ebp+8]\n        add     eax, 20\n.L5:\n        pop     ebp\n        ret\n        .size   syntax_help, .-syntax_help\n.globl main\n        .type   main, @function\nmain:\n        push    ebp\n        mov     ebp, esp\n        sub     esp, 4\n        cmp     DWORD PTR [ebp+8], 4\n        jg      .L9\n        mov     eax, DWORD PTR [ebp+8]\n        mov     DWORD PTR [esp], eax\n        call    syntax_help\n        jmp     .L10\n.L9:\n        cmp     DWORD PTR [ebp+8], 5\n        jne     .L11\n        mov     eax, 42\n        jmp     .L10\n.L11:\n        mov     eax, 0\n.L10:\n        leave\n        ret\n</code></pre>\nThat's a mouthful. Now let's dig into one difference - aside from the \"optimization\" aspect - between this and a potential human-written piece of assembly that does the same. Here's what a human-written version might look like:\n<pre><code>.globl syntax_help\n    .type   syntax_help, @function\nsyntax_help:\n    push    ebp\n    mov ebp, esp\n    mov eax, DWORD PTR [ebp+8]\n    test    eax, eax\n    je  .zero_args\n    cmp eax, 1\n    je  .one_arg\n    jmp .return_20plus\n.zero_args:\n    mov eax, -1\n    jmp .exit_help\n.one_arg:\n    mov eax, 23\n    jmp .exit_help\n.return_20plus:\n    mov eax, DWORD PTR [ebp+8]\n    add eax, 20\n.exit_help:\n    pop ebp\n    ret\n    .size   syntax_help, .-syntax_help\n.globl main\n    .type   main, @function\nmain:\n    push    ebp\n    mov ebp, esp\n    sub esp, 4\n    cmp DWORD PTR [ebp+8], 4\n    jg  .return_42\n    mov eax, DWORD PTR [ebp+8]\n    mov DWORD PTR [esp], eax\n    call    syntax_help\n    jmp .exit\n.return_42:\n    cmp DWORD PTR [ebp+8], 5\n    jne .return_0\n    mov eax, 42\n    jmp .exit\n.return_0:\n    mov eax, 0\n.exit:\n    leave\n    ret\n</code></pre>\nAnyone who has ever written assembly code will inevitably notice how I am not declaring variables (<pre><code>db</code></pre>, <pre><code>dw</code></pre>, <pre><code>dd</code></pre>) here. This would be the normal course of action, but of course here I was merely showing that we humans tend to give symbolic names to code locations (and variables). If you hand write assembly, it would look still different, I merely adjusted the code to look a bit more like what a human might write (i.e. it's not perfect and certainly not \"hand-optimized\"). The compiler will stubbornly and efficiently tack a number on some kind of lettered prefix and be done with it. Let's also create a possible human-written version of the first iteration, using the same names:\n<pre><code>.globl syntax_help\n    .type   syntax_help, @function\nsyntax_help:\n    push    ebp\n    mov ebp, esp\n    mov eax, DWORD PTR [ebp+8]\n    add eax, 20\n    pop ebp\n    ret\n    .size   syntax_help, .-syntax_help\n.globl main\n    .type   main, @function\nmain:\n    push    ebp\n    mov ebp, esp\n    sub esp, 4\n    cmp DWORD PTR [ebp+8], 2\n    jg  .return_42\n    mov eax, DWORD PTR [ebp+8]\n    mov DWORD PTR [esp], eax\n    call    syntax_help\n    jmp .exit\n.return_42:\n    cmp DWORD PTR [ebp+8], 3\n    jne .return_0\n    mov eax, 42\n    jmp .exit\n.return_0:\n    mov eax, 0\n.exit:\n    leave\n    ret\n</code></pre>\nComparing compiler-generated assembly code\nHere's the output of <pre><code>diff ptest1.asm ptest2.asm</code></pre> (the compiler-generated form):\n<pre><code>1c1\n<       .file   \"ptest1.c\"\n---\n>       .file   \"ptest2.c\"\n9a10,22\n>       test    eax, eax\n>       je      .L3\n>       cmp     eax, 1\n>       je      .L4\n>       jmp     .L7\n> .L3:\n>       mov     eax, -1\n>       jmp     .L5\n> .L4:\n>       mov     eax, 23\n>       jmp     .L5\n> .L7:\n>       mov     eax, DWORD PTR [ebp+8]\n10a24\n> .L5:\n20,21c34,35\n<       cmp     DWORD PTR [ebp+8], 2\n<       jg      .L4\n---\n>       cmp     DWORD PTR [ebp+8], 4\n>       jg      .L9\n25,28c39,42\n<       jmp     .L5\n< .L4:\n<       cmp     DWORD PTR [ebp+8], 3\n<       jne     .L6\n---\n>       jmp     .L10\n> .L9:\n>       cmp     DWORD PTR [ebp+8], 5\n>       jne     .L11\n30,31c44,45\n<       jmp     .L5\n< .L6:\n---\n>       jmp     .L10\n> .L11:\n33c47\n< .L5:\n---\n> .L10:\n</code></pre>\nNot exactly helpful to understanding the differences, is it?\nWinMerge provides a more visual result. Chaos ensues ...\n\nNB: I decided to not doctor a full height screenshot, instead pay attention to the left pane which highlights the differences (yellow) and missing blocks (gray) and moved blocks (brown...ish).\nComparing \"human-written\" assembly code\nHere's the output of <pre><code>diff ptest1.asm-human ptest2.asm-human</code></pre> (\"human-written\" form):\n<pre><code>6a7,19\n>       test    eax, eax\n>       je      .zero_args\n>       cmp     eax, 1\n>       je      .one_arg\n>       jmp     .return_20plus\n> .zero_args:\n>       mov     eax, -1\n>       jmp     .exit_help\n> .one_arg:\n>       mov     eax, 23\n>       jmp     .exit_help\n> .return_20plus:\n>       mov     eax, DWORD PTR [ebp+8]\n7a21\n> .exit_help:\n17c31\n<       cmp     DWORD PTR [ebp+8], 2\n---\n>       cmp     DWORD PTR [ebp+8], 4\n24c38\n<       cmp     DWORD PTR [ebp+8], 3\n---\n>       cmp     DWORD PTR [ebp+8], 5\n</code></pre>\nWhoa, that's actually almost readable. Use <pre><code>colordiff</code></pre> and it's useful.\nThe respective visual comparison in WinMerge looks downright readable:\n\nInterlude - basic blocks\nA disassembler can only be smart to a certain extent, because it's a program. Even IDA Pro, hands down the most advanced disassembler as of this writing, will not be able to guess everything right - e.g. when distinguishing code or data. But the more sophisticated tools do a pretty good job at it. And IDA adds the I as interactive.\nOne thing disassemblers encounter are what assembly programmers is known as labels and (sub)routines.\nLabels, although they exist in C and are (rightly) frowned upon together with <pre><code>goto</code></pre>, also exist in higher level language, but tend to cover a somewhat different concept. Perhaps the closest to the assembly language concept were the labels in the good old days of BASIC. When you compile C into assembly code, however, every condition gets translated into a conditional or unconditional jump (<pre><code>jmp</code></pre>, <pre><code>je</code></pre>, <pre><code>jg</code></pre>, <pre><code>jne</code></pre> in the above compiler-generated code). The jump targets are referred to as labels. The jumps are the places where the code branches conditionally or unconditionally.\nThe closest corresponding concept to a routine would be a function in C or the <pre><code>procedure</code></pre>/<pre><code>function</code></pre> in Pascal or the <pre><code>sub</code></pre> in BASIC.\nMore or less each of the chunks of code between two branching instructions, other than <pre><code>call</code></pre>, are called basic blocks. In IDA Pro this is neatly visualized in the graph view (can be toggled with flat view via default Space):\n\nEach of the blocks linked by the arrows in the main IDA-view would be a basic block.\nAgain, why it is a hard task to compare binary executable code?\nBy now you should have a faint idea what makes the comparison hard, but let's go the extra mile. Let's switch from comparing the compiler-generated and \"human-written\" assembly code to actual disassembly.\nAs before we will stick to the gist of it.\nCompiler-generated versus disassembly\nBut just to mention it, in the disassembly you have the result after the linker mangled it. The compiler-generated assembly from before contained merely the code we had written in the sample program.\nJust to give you an idea, I generated an <pre><code>.asm</code></pre> file using IDA, stripped it down to everything without comments and empty lines and still ended up with 362 lines, as opposed to 52 lines in the original compiler-generated assembly which included meta-data used by the linker. This whopping difference can of course be attributed to the linker adding all kinds of code required to initialize the executable. In fewer words: it's boiler plate code the compiler (or more precisely its linker) adds.\nFor this comparison I am going to leave out this boiler plate code entirely, although obviously this only adds to the complexity a <pre><code>diff</code></pre> tool will encounter when comparing binary executable code.\nUnlike in the IDA screenshot above, which shows <pre><code>ptest2.c</code></pre> disassembled, in reality you will mostly have to work without debug symbols. This means the names such as <pre><code>main</code></pre> and <pre><code>syntax_help</code></pre> will no longer exist. Instead disassemblers such as IDA Pro mostly resort to naming the routines after their offset (e.g. <pre><code>sub_80483DB</code></pre>). It applies the same for labels (i.e. naming those <pre><code>loc_80483F4</code></pre> or <pre><code>locret_something</code></pre>). Of course the reverse engineer is free to change these names to something more readable/recognizable for herself. But the default names still depend on the offset.\nIn fact the disassembler will have a hard time to identify the <pre><code>main</code></pre> function, because the aforementioned boiler plate code tends to come before it when looking at it starting from the entry point of the executable. Here's what IDA shows you if there are no symbols available to the compiled <pre><code>ptest2.c</code></pre> from before (i.e. ran <pre><code>strip -s ...</code></pre>):\n\nNow let's look at the entry point for the compiled (and stripped) <pre><code>ptest1.c</code></pre> as well:\n\nDo you notice the difference? It's subtle, but let me put them side to side for you:\n\nYes, the highlighted lines ... ooh the offsets differ. What does that mean?\nWell, it means that the symbolic names IDA Pro assigns to routines and also to labels (i.e. basic blocks) will differ based on the offset of these entities within the file. \nThis is very similar indeed to what we encountered before with the compiler-generated assembly code and the numbered label names.\nUsing a simpler disassembler\nLet's compare the relevant pieces of code created by a simpler disassembler in a text differ.\nUsing <pre><code>objdump -M intel -d ...</code></pre> and then getting rid of the leading offsets and spaces we get this for the relevant parts in WinMerge:\n\nFull commands were:\n<pre><code>objdump -M intel -d ptest1.stripped|grep '^ 80'|cut -f 2- -d ':'|sed 's/^\\s*//g'\nobjdump -M intel -d ptest2.stripped|grep '^ 80'|cut -f 2- -d ':'|sed 's/^\\s*//g'\n</code></pre>\nConclusion\nThis means text diffing tools such as <pre><code>diff</code></pre>, <pre><code>kdiff3</code></pre>, <pre><code>WinMerge</code></pre> and many others will have a hard time comparing disassemblies unless the reverse engineer took the time to rename all routines and labels to something not based on the offset.\nIn fact this becomes an almost insurmountable task when facing a disassembly in textual form. The internal form IDA Pro keeps of the disassembly is much more suitable.\nIn text form every single changed offset - and there will be loads of those - will draw your attention because it is a difference to a text differ.\nSolutions\nNot that we know the problem, what can we do about it?\nBasic blocks are the answer to the problem at hand. Tools like DarunGrim (FLOSS), patchdiff2 (FLOSS) and Bindiff (commercial) use IDA's knowledge about basic blocks to build graphs. These graphs can then be used to identify similar and different blocks. With the abstraction in the form of a graph the visualization can be superimposed on the respective view inside IDA or a specialized view can be offered.\nAs you see, when you export your disassembly to a text file, you are stripping a whole lot of contextual information from it which IDA keeps for you in its database. Instead draw from the information IDA already has and use it. Plugins and scripts allow you to reach into the guts of the IDA database and extract what treasures are in there to make sense of basic blocks in a way a text differ will never be able to.\nTools\nFor a listing of tools able to tackle the task, refer to the answers to the question which sparked this one:\n\nhow can I diff two x86 binaries at assembly code level?\n\nFurther reading\n\nMake sure to read Rolf's answer below!\nHow BinDiff works, answer by newgre\nhttp://www.darungrim.org/Presentations\nhttp://www.darungrim.org/Researches\n\nTL;DR\nThe reason text differs are insufficient for handling textual disassembly is because the textual representation discards valuable information the disassembler collects during the process of disassembling. Also disassemblers name the code locations and variables after their offsets - changes to a program with subsequent recompilation will change virtually all offsets and therefore create a lot of noise in the textual representation. Text differs will point out every single one, making it impossible to find the relevant changes from the reverse engineer's point of view.\n",
            "votes": "44",
            "user": "Community",
            "time": "Apr 13, 2017 at 12:49",
            "is_accepted": true,
            "comments": [
                {
                    "user": "amccormack",
                    "text": "<span class=\"comment-copy\">I think stack exchange needs to make a <code>novelist</code> badge just for you. Good work.</span>",
                    "time": null
                },
                {
                    "user": "dyasta",
                    "text": "<span class=\"comment-copy\">Now THAT is an answer!</span>",
                    "time": null
                },
                {
                    "user": "jyz",
                    "text": "<span class=\"comment-copy\">Bookmarked. And probably gonna print it.</span>",
                    "time": null
                }
            ]
        },
        {
            "content": "Most of the problems come into play due to the fact that small changes to the source code can result in large changes to the compiled binary.  In fact, no changes to the source code can still result in different binaries.\nCompiler optimizations will wreck your day if you want to compare binaries.  The worst-case scenario is if you have two binaries compiled with different compilers, or different revisions of a compiler, or the same revision of a compiler at different optimization settings.\nA few examples that come to mind:  \n\nInlining.  This optimization can actually remove functions entirely, and can change the control flow graph of the optimized function.\nInstruction scheduling re-orders the instructions within a given basic block in order to minimize pipeline stalls.  This wreaks havoc on UNIX diff-style tools.\nLoop-invariant code motion.  This optimization can actually change the number of basic blocks within a function!  The same function compiled at different optimization levels can have a different control-flow signature.\nIntraprocedural register allocation.  Suppose that a function is changed by adding an if-statement somewhere that references some variable that was already defined within the function.  The act of using the variable again modifies the definition-use chains for the function's variables.  Now, when the compiler generates low-level code for a given function, it uses the use-def information to decide at each point which variables should be on the stack, and which ones should be placed in registers.  This is intraprocedural register allocation.  Therefore, it could turn out that simply adding one line of code results in the variables being held in different registers, and/or held on the stack instead of in registers (or vice versa) which obviously will affect what the compiled code looks like.\nInterprocedural optimizations such as \"interprocedural register allocation\" (IRA), interprocedural common subexpression elimination (ICSE), etc. drastically affect the layout of the compiled binary, and they are also sensitive to minute changes in the source code.  For example, IRA will manufacture novel calling conventions for functions that are not required to conform to standard calling conventions, e.g. because they are not exported from their containing module or library, and are never referenced via function pointer.  ICSE can remove portions of code from a given function.\nProfile-guided optimization (PGO).  Under this optimization, the compiler first produces a binary with extra code that computes statistics about the program's runtime behavior.  The programmer then subjects the instrumented code to \"a typical workload\" and computes statistics.  Then, the programmer recompiles the program, supplying those statistics to the compiler and telling it to generate code via PGO.  The compiler then dramatically changes the layout of the binary by ordering the code by how frequently each function executed, which paths through the function were the most common, etc.  Different training sets will produce different statistical profiles, and hence vastly different executables.\n\nThis is not an exhaustive list.  Many other optimizations will plague you.  It's mostly because of compiler optimizations that UNIX diff-style tools have little utility in the binary comparison space.\n",
            "votes": "10",
            "user": "Rolf Rolles",
            "time": "Apr 23, 2013 at 5:15",
            "is_accepted": false,
            "comments": []
        },
        {
            "content": "One of things I do is to read the machine code and translate it back into IR pseudo opcodes sans any addressing address values, and then perform differences between those two pseudo-IR binaries after using this reduction method on each.\n",
            "votes": "1",
            "user": "John Greene",
            "time": "May 11, 2020 at 18:31",
            "is_accepted": false,
            "comments": [
                {
                    "user": "0xC0000022L",
                    "text": "<span class=\"comment-copy\">this would amount (roughly) to what tools like retdec are trying. And yes, this feasible nowadays (now look at the timestamp of my Q&amp;A, though). But the question was actually where this stems from. Still +1 from me, because it's a fair point. Btw, your answer could gain a lot by providing some more details ;)</span>",
                    "time": null
                },
                {
                    "user": "John Greene",
                    "text": "<span class=\"comment-copy\">Yep.  But often times we are in a hurry to see if an executable has been tampered with against our baseline set of executables and this aforementioned method helps us to zero into the afflicted blocks and/or function that had been repurposed, especially in the case that the executable maintained the same executable header checksum value.</span>",
                    "time": null
                }
            ]
        }
    ]
}