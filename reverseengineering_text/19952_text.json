{
    "title": "Any ideas on how to decode Photoshop Liquify .msh files?",
    "link": "https://reverseengineering.stackexchange.com/questions/19952/any-ideas-on-how-to-decode-photoshop-liquify-msh-files",
    "content": "Photoshop's Liquify filter allows you to distort images interactively in many different ways. When you have distorted an image to your liking, you can save the mesh that represents the transformation in a .msh file. This transformation can then be loaded and applied on other images. I need to reverse engineer .msh files even though I never never decoded a file format before. Below is everything I've figured out so far.\nPreviously, .msh files just contained a header and an uncompressed array of pixel displacement values. I know this because the format was reverse engineered in open source projects such as Paint.NET and graphics32 (see TVectorMap.LoadFromFile and SaveToFile). This resulted in very large file sizes, so Adobe eventually updated the format to include some kind of compression. The compression is very efficient (an 11.5 MB file was reduced to 430 kB when resaved in the new format), but I don't know if it is lossy or lossless. To my knowledge, these newer compressed .msh files have not been decoded, but this is what I need to do.\nThe new headers are very similar to the old headers, but I can't figure out what kind of compression has been used so I can't read the actual data. I googled some common compression formats and their signatures but didn't detect anything useful.\nIs there a trick or utility that can help me figure out the type of compression? Any other thoughts that can lead me in the right direction?\nIf anyone wants to take a look, I created a few sample .msh files in vastly different sizes along with .png images that demonstrate the transformation being applied. I uploaded them to MEGA here (1.3 MB download):\nhttps://mega.nz/#!We5QkARI!2-qD_qK2e8ADnYJcT578x9RxXo4uvBH0rXeDPeR-pRU\n",
    "votes": "7",
    "answers": 1,
    "views": "612",
    "tags": [
        "decompress",
        "graphics"
    ],
    "user": "Nick Evans",
    "time": "Nov 23, 2018 at 21:44",
    "comments": [
        {
            "user": "Jongware",
            "text": "It looks like these are groups of floating point values; 2x (long value before them). Nothing compressed, as far as I can see.\n",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "Here's a description of the .msh format on Adobe Photoshop CC 2019, at least of what I've been able to glean.\nThe format uses run-length encoding to encode the offset coordinates of the mesh cells and compress empty cells along the way.\n\nThe format is little endian. The header is 64 bytes. At 0x10 and 0x14 are the mesh width and height, 32-bit integers. At 0x28 and 0x2c are the image height and width, 32-bit integers. The same image height and width are also found at 0x38 and 0x3c. The mesh size seems to always be 1/4th of the image size, so you get 4 pixels mesh cell.\nThe encoded grid starts at 0x40. Every row of mesh cells is encoded separately from the other rows.\nEvery row starts with the number of contiguous zero-offset cells, left-to-right, 32-bit integer. If the leftmost cell is non-zero then this number is zero. Then, if the row is incomplete, the number N of contiguous non-zero cells comes. Then come N pairs of 32-bit floats. If the row is incomplete, comes the number of contiguous zero-offset cells and so on until the row has been completely encoded. Then comes the next row with the number of zero-offset cells and so on until all rows have been encoded.\nIn the example above we have a 32x32 image with an 8x8 mesh. Starting at 0x40 we have:\n\n(row 1 starts here) 4 zero-offset cells\n1 non-zero cell, 2 floats\n3 zero-offset cells (the row is now complete)\n(the pattern repeats for two more rows until 0x7c)\n(row 4 starts here) 0 zero-offset cells\n1 non-zero cell, 2 floats\n3 zero-offset cells\n1 non-zero cell, 2 floats\n3 zero-offset cells (the row is now complete)\n\n...and so on.\nThe encoded float pairs seem to be the X and Y offsets from the current pixel to the pixel from which to sample the value. Not sure if the magnitude is a distance between pixels or distance between cells, though.\n",
            "votes": "6",
            "user": "Stefan Dragnev",
            "time": "Sep 20, 2019 at 13:16",
            "is_accepted": false,
            "comments": [
                {
                    "user": "Johan Tid√©n",
                    "text": "<span class=\"comment-copy\">I used your answer to create a simple java implementation, showcasing it. <a href=\"https://gist.github.com/johantiden/a9ec7bc4dfeb9ebc23260d6c0a159317\" rel=\"nofollow noreferrer\">gist.github.com/johantiden/a9ec7bc4dfeb9ebc23260d6c0a159317</a></span>",
                    "time": null
                }
            ]
        }
    ]
}