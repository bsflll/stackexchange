{
    "title": "Need help unraveling the format (time, string, float/decimal, integer/float/decimal) in .dat file",
    "link": "https://reverseengineering.stackexchange.com/questions/14941/need-help-unraveling-the-format-time-string-float-decimal-integer-float-deci",
    "content": "The files (idx, dat) are from a plant/facility operational historian. The .dat file is supposed to have entries, each with identifier (tag name/id/key), value (decimal/float) for different times (timestamp) along with their confidence rating (int/percentage).\nThe application is windows-based. Each .dat file would represent entries of few days.\nI've managed to identify timestamps at specific byte offsets. It also looks like the \"records\" are of 2049 byte chunks. The timestamp (and additional timestamps) repeat within each 2049 chunk (which is a bit strange), but perhaps it's also keeping a reference to the last recorded time, or maybe there's a nesting (parent/child) of records.\nI'm a stuck as to how I should proceed.\nSample dat file (truncated):\nhttps://drive.google.com/open?id=0B8ACIyH1qALnLUY2cEdzVWp6T1U\nFull dat file:\nhttps://drive.google.com/open?id=0B8ACIyH1qALnNU5wYkotMktVWVk\nOne of the first time values: 80CAFEBB168DD201 at offset 2061 decimal []  (131322467930000000 -> 2017-02-27 7:19:53 AM)\nSample idx file:\nhttps://drive.google.com/open?id=0B8ACIyH1qALnQzVueEJuRWNfUk0\nAppreciate the help.\nUPDATE\nAs requested, some further information:\n\nThe files are generated by Honeywell PHD Uniformance Server. I don't\nhave access to the software itself - but working on it. I don't know\nwhat language it was written in. \nSome online guide for the server suggest the\npresence of MAX_ARCRECSIZE configuration parameter <quote>\"which defaults to 2048.\nThis controls the record size within the archive files\" </endquote>. The dat files are of 2049 byte chunks (2048 bytes + 1 byte \"0A\")\nThe historian, as far as I know, doesn't provide SQL-like interface. The\nonly protocols understood are OPC variants (OPC-DA, OPC-HDA and\npossibly OPC-UA), however those are slow when it comes to extracting\nhistorical records.\nThe offset given for one of the dates (but not the first one), is at 2061 decimal\n<pre><code>=>hexdump -C -s 2061 -n 64 SCAN00356-sample.dat\n0000080d  80 ca fe bb 16 8d d2 01  02 00 00 00 12 00 00 00  |................|\n0000081d  96 07 46 04 00 00 00 00  20 5f a0 02 c2 00 00 80  |..F..... _......|\n0000082d  bf 00 3c 00 00 00 00 00  00 00 04 00 00 00 96 07  |..<.............|\n0000083d  8e 07 80 ca fe bb 16 8d  d2 01 0a 00 00 86 07 00  |................|\n0000084d\n</code></pre>\nI've found 4 different timestamps (ftime) in each 2049 'chunks' so far. They are at consistent offsets (at bytes 12, 62, 75, 94 from the beginning of each 2049 byte chunk). Possible sequence value at byte 8. Possible 'color' value at byte 38.\nOne more thing; OPC Servers leverage COM and DCOM architectures. I came across the Compound Binary File Format, but the corresponding readers aren't able to read the files.\n",
    "votes": "2",
    "answers": 2,
    "views": "615",
    "tags": [
        "binary-analysis",
        "struct"
    ],
    "user": "tamersalama",
    "time": "Mar 21, 2017 at 8:54",
    "comments": [
        {
            "user": "julian",
            "text": "Can any additional information about the program(s) reading/writing these files be provided?\n",
            "time": null
        },
        {
            "user": "Nordwald",
            "text": "Please know that there is hardly a chance to reverse the file format without having a look at the loading or creation process. In any other case, the Honeywell support may provide better help\n",
            "time": null
        },
        {
            "user": "tamersalama",
            "text": "Fair enough Nodwald. I know it might be a shot in the dark.\n",
            "time": null
        },
        {
            "user": "julian",
            "text": "@tamersalama do you have access to client software designed to interface with the Uniformance server?\n",
            "time": null
        },
        {
            "user": "tamersalama",
            "text": "@SYS_V Sorry - not at the moment. First, there's the server interface (or UI). Then there are client libraries that uses OPC-DA, OPC-HDA and OPC-UA protocols. I don't have access any of those but working on it.\n",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "This post consists of the results of preliminary analysis. Hopefully it saves other interested parties a little work.\nSimilar questions on SO\npossible type of database that uses dat, idx files\nHow do I open .bin/.idx database files?\nWhat database uses these specific type of .dat and .idx files?\nAnd most interestingly: \nHow can I extract data from DAT and IDX files of SCADA CIMPLICITY software?\nPreliminary Analysis\n<pre><code>SCAN00356-sample.dat</code></pre> and <pre><code>SCAN00356.idx</code></pre> were examined. The full <pre><code>.dat</code></pre> file, <pre><code>SCAN00356.dat</code></pre>, is 4.0GB in size and too large load into memory on the VM being used and so has not been examined.\nsample <pre><code>.dat</code></pre> file <pre><code>SCAN00356-sample.dat</code></pre>\nThe structure of <pre><code>SCAN00356-sample.dat</code></pre> is non-uniform:\n\nAdditional visualization allows us to further appreciate the heterogeneous distribution of data within the file:\n\n\n\n\nThere is a very brief header in which the the string \"SCAN\" appears, composed of 16-bit characters.\n<pre><code>$ hexdump -C -n 100 SCAN00356-sample.dat\n00000000  00 00 00 00 00 00 00 00  00 00 00 00 00 01 00 00  |................|\n00000010  00 00 00 00 00 01 00 00  80 fa 6d 1c a5 8b d2 01  |..........m.....|\n00000020  00 f1 d7 49 75 8f d2 01  e8 07 00 00 53 00 43 00  |...Iu.......S.C.|\n00000030  41 00 4e 00 00 00 00 00  00 00 00 00 00 00 00 00  |A.N.............|\n00000040  00 00 01 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n00000050  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n*\n</code></pre>\nsample <pre><code>.idx</code></pre> file <pre><code>SCAN00356.idx</code></pre>\nUnlike <pre><code>SCAN00356-sample.dat</code></pre>, the structure of <pre><code>SCAN00356.idx</code></pre> is fairly uniform:\n\nVisualization:\n\n\n<pre><code>SCAN00356.idx</code></pre> also has a very small header. The ASCII string \"dism\" appears here afterward, prior to the bulk of the encoded data.\n<pre><code> $ hexdump -C -n 2208 SCAN00356.idx\n00000000  fe 53 02 02 04 04 03 ff  00 01 07 04 00 08 00 00  |.S..............|\n00000010  00 00 02 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n00000020  00 00 1f ac 54 00 00 f9  3d 03 8a f0 33 00 00 00  |....T...=...3...|\n00000030  01 00 00 00 00 00 08 00  00 00 00 00 00 00 00 00  |................|\n00000040  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n*\n000003f0  00 00 00 00 00 00 00 00  00 00 00 00 64 69 73 6d  |............dism|\n00000400  00 1c 00 00 00 00 00 16  00 00 00 03 00 00 04 00  |................|\n00000410  08 06 00 08 00 00 0d 00  02 00 16 05 00 00 00 00  |................|\n00000420  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n*\n000007f0  00 00 00 00 00 00 00 00  00 00 00 00 00 ff 7e 00  |..............~.|\n00000800  02 9c 88 0a 00 00 ff f9  71 9f ce 72 2d 7e 00 00  |........q..r-~..|\n00000810  00 00 a3 1e 0d 16 00 00  ff 77 18 28 86 72 2d 7e  |.........w.(.r-~|\n00000820  00 00 00 00 4c d2 99 18  00 00 ff 03 71 b9 f1 72  |....L.......q..r|\n00000830  2d 7e 00 00 00 00 a0 06  1e 28 00 00 ff 63 c4 ff  |-~.......(...c..|\n00000840  ed 72 2d 7e 00 00 00 00  28 c3 94 35 00 00 7f c9  |.r-~....(..5....|\n00000850  28 94 e2 72 2d 7e 00 00  00 00 a1 42 21 41 00 00  |(..r-~.....B!A..|\n00000860  7f dd 10 f2 f1 72 2d 7e  00 00 00 00 4e 5e 24 51  |.....r-~....N^$Q|\n00000870  00 00 ff 1c 82 c0 c5 72  2d 7e 00 00 00 00 95 50  |.......r-~.....P|\n00000880  58 5b 00 00 7f 5c f5 c5  f1 72 2d 7e 00 00 00 00  |X[...\\...r-~....|\n00000890  16 34 02 69 00 00 ff 6f  79 56 e5 72 2d 7e 00 00  |.4.i...oyV.r-~..|\n</code></pre>\nThe images were created using <pre><code>binwalk</code></pre> and binvis.io.\n",
            "votes": "1",
            "user": "Community",
            "time": "May 23, 2017 at 12:37",
            "is_accepted": false,
            "comments": []
        },
        {
            "content": "The SCAN00356.idx file has easily identifiable structures.  The data region begins starting at offset 0x800 and continues to the end of the file.  Each 0x400 page contains 18-byte records.  When a page fills up (or data ends), it ends the current set of records with a 1-word index value after the last record. \nFYI - Just change the view width of your hex editor to 18 bytes.  The structures will pop right out at you.  Here is an excerpt from your file:\n<pre><code>EF 73 05 50 01 00 FF 72 7F 46 88 72 2D 7E 00 00 00 05 \nC7 14 05 50 01 00 7F E4 1C 09 8C 72 2D 7E 00 00 00 05 \nA0 20 05 50 01 00 FF 55 BA CB 8F 72 2D 7E 00 00 00 05 \n67 18 05 50 01 00 7F C7 57 8E 93 72 2D 7E 00 00 00 05 \n44 D6 05 50 01 00 FF 38 F5 50 97 72 2D 7E 00 00 00 05 \n0F 84 05 50 01 00 7F AA 92 13 9B 72 2D 7E 00 00 00 04 \nCA A0 05 50 01 00 FF 1B 30 D6 9E 72 2D 7E 00 00 00 04 \nA9 49 05 50 01 00 7F 8D CD 98 A2 72 2D 7E 00 00 00 04 \n76 89 05 50 01 00 FF FE 6A 5B A6 72 2D 7E 00 00 00 04 \n4D 6F 05 50 01 00 7F 70 08 1E AA 72 2D 7E 00 00 00 04 \n2C BF 05 50 01 00 FF E1 A5 E0 AD 72 2D 7E 00 00 00 03 \nFD 5B 05 50 01 00 7F 53 43 A3 B1 72 2D 7E 00 00 00 03\n</code></pre>\nSome of the columns never seem to change, such as the byte string 0x72 7D 7E 00 00 00.  \nOthers appear as flags, such as the column that alternates between 0xFF and 0x7F.\nThere seem to be a few different types of records stored, although they all conform to this format.  Some will use more of the data bytes than others.\nThis has the feel of some type of logging record, though I don't know what the values of the data fields mean.  I hope this helps.\n",
            "votes": "1",
            "user": "Dwiggit",
            "time": "Mar 23, 2017 at 17:28",
            "is_accepted": false,
            "comments": []
        }
    ]
}