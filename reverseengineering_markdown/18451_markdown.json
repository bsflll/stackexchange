{
  "title": "What are the popular machine learning unsupervised approaches to learning binary data representations?",
  "link": "https://reverseengineering.stackexchange.com/questions/18451/what-are-the-popular-machine-learning-unsupervised-approaches-to-learning-binary",
  "content": "This is somewhat open-ended question, so bear with me please.\n\nBe it a binary payload that you pull from network packet, firmware blob you pull of some EPROM or data intercepted straight from physical bus - does anybody here use machine learning models to learn data representation?\n\nThe problem here is that we have a large sequence(s) of binary data of known length which has some kind of a structure (think stream of IP packets) which is yet to be understood.\n\nAssuming we have enough of this data, we can deduce data representations in unsupervised manner, e.g. if we have pcap capture of a network packet flow on ethernet network, we can deduce what ethernet header is, that it is typically followed by something like IP header, then UDP/TCP header and some paylond in the end.\n\n\n\nYou could replace \"classifier\" with whatever else we use those ML models (in this case probably RNN-GRU/LSTM) for nowadays (apart from classification it could generate fake traffic etc). But the point is that unlike with common ML domains such as natural language processing, I'm not aware of any model that can be used to replace manual parsing. Most popular NLP model to learn what words mean in context of a sequence nowadays is word2vec, but is there anything like that for representing binary sequences?\n\nPS: I used example in the image just to demonstrate the problem, that could very well be binary code of unknown architecture, USB request block or anything else, point being that it is typically highly structured, opaque and sequential binary input.\n\nI guess the real question is, does anybody use ML for reverse engineering?\nIf so, do you mind sharing your experiences?\n\n",
  "votes": "4",
  "answers": 2,
  "views": "343",
  "tags": [
    "binary-analysis",
    "binary"
  ],
  "user": "Tomas Pruzina",
  "time": "Jun 4, 2018 at 13:33",
  "comments": [
    {
      "user": "Tomas Pruzina",
      "text": "At the moment I'm thinking byte level VAEs/LSTMs for upper part.",
      "time": null
    }
  ],
  "answers_data": [
    {
      "content": "Inferring the structure of an unknown binary stream is a really difficult task, that I'm aware of only a few attempts at tackling:\n\nI do not believe existing \"machine learning\" models and approaches are currently capable of statistically inferring structural information about binary data.  You'll have to resort to more basic statistical inference, and that process should probably be designed from beginning to end with the end goal in mind (seems to be \"malicious classification\").\n\nMost approaches nowadays do not tackle the task of protocol inference in the process of malware classification (one could also make a few arguments against any advantage of doing so).\n\nIn comparison to malware classification, I would say the task of protocol structure inference is more difficult to achieve and I would advise reevaluating if this is indeed a requirement you want to attempt meeting.\n\nFull disclosure: I'm employed by a \"next gen AV\" that makes use of ML for malware classification and have been tinkering with protocol inference in the past.\n\n",
      "votes": "5",
      "user": "NirIzr",
      "time": "Jun 6, 2018 at 17:55",
      "is_accepted": true,
      "comments": [
        {
          "user": "Tomas Pruzina",
          "text": "That's pretty much what I was looking for, I was just hoping that somebody came up with something better than HMMs. At the moment I have written simple fuzzer that generates random http packets and gonna test few models trying to learn underlying structure. Thanks for the link.",
          "time": null
        },
        {
          "user": "joxeankoret",
          "text": "You should take a look to 'radamsa'. It tries to infer the grammar from the data you give to it and then generate outputs according to the inferred grammar.",
          "time": null
        }
      ]
    },
    {
      "content": "First, the more samples of discrete messages you have the better.\n\nSecond, a one algorithm fits all approach isn't going to work. Use an ensemble of small simple recognizers. \n\nThird, it's coming from memory, so start by learning the memory representations for a specific thing, for example unint32.\n\nFourth, the most difficult part of this task is having pure data. You can be comparing string bytes to int bytes and get nowhere. If you have pure string bytes or pure float bytes, you'll make progress.\n\n",
      "votes": "0",
      "user": "pythonpython",
      "time": "Dec 11, 2019 at 3:43",
      "is_accepted": false,
      "comments": []
    }
  ]
}