{
  "title": "What methodology can be used to change code flow atomically during program execution?",
  "link": "https://reverseengineering.stackexchange.com/questions/6052/what-methodology-can-be-used-to-change-code-flow-atomically-during-program-execu",
  "content": "I have been reading a lot about the different techniques for Windows API hooking  (a technique I'm particularly fascinated by and fond of), and it seems a major problem in implementing a realiable hook function is ensuring that the hook is written in a way that is thread-safe. Of course, there are some techniques where this problem has been solved or can be solved trivially, such as hotpatching the Windows API, but hot patching is not guaranteed to work on all win32 or third party API functions and the techniques that do support hooking them are not normally thread-safe.\n\nA very common technique that is has problems caused by multithreading is a inline hook that replaces the normal function prologue code with a jump instruction to the hook procedure, and then calls the original function as needed through a trampoline.\n\nThere are several inherent issues to the inline hook technique, which makes it a very complicated method to use and debug. A primary issue is as I mentioned, that it is not safe in a orthodox multithreaded environment in the real world. This is due to that when changing the bytes of the function, you can not guarantee that the instruction pointer will not be in the middle of your newly injected code, which may then cause the target application to crash from executing an invalid mix of the old opcodes mixed with the opcodes you inserted.\n\nThere are some solutions to this problem, with one being suspending all the threads in the process and then checking the instruction pointer in each thread to ensure that no thread is currently executing the target instructions you wish to replace. Then if there happens to be a thread or two executing that particular function, then you can respond accordingly by doing something such as performing a stack trace to place a breakpoint at the return address, resuming the thread, and then handling the exception when the thread has returned from the target function.\n\nOf course, this method is still unsafe, because there is nothing stopping one sneaky thread from using CreateThread() before you can suspend all of the running threads in the process (some applications on my computer run with 40+ threads at once). There could even be a related process that uses CreateRemoteThread() in your target application and then calls the function you are hooking before it's safe.\n\nA solution to that problem could be trying to debug the process and receive notifications of when a process creates a new thread, and then respond by suspending that thread. Of course, many event notification systems provided by the Windows    API or a third party API will not be sent in real time, which may allow that thread to perform an unsafe operation before it is suspended.\n\nAnother solution could be to statically patch the executable with the hook function before the process is launched, presumably by hooking the EAT/IAT. This is not an option for me because I need to have an implementation that will work process wide, regardless of how a function is resolved or in the event of a new unhooked module calling the function.\n\nThere are many other issues to overcome with the inline hook technique that I did not mention.  Which brings me back again to my question:\n\nI was curious to see if there was a more robust solution out there that overcomes some of the shortcomings of the methods I covered in this post.\n\nPlease no third party library suggestions for hooking functions. I want to implement my own for the educational benefits.\n\nI prefer hooking technique documentation and examples that use the C programming language.\n\nMy processor is an AMD Athlon II X2 250 that is x86-x64 compatible, and my operating system is Windows 7.\n\n",
  "votes": "11",
  "answers": 3,
  "views": "1k",
  "tags": [
    "windows",
    "x86",
    "c",
    "function-hooking",
    "x86-64"
  ],
  "user": "CaptainObvious",
  "time": "Jul 4, 2022 at 19:17",
  "comments": [
    {
      "user": "0xec",
      "text": "Check out this paper; particularly in the section 5.2 Capturing the CPUs to update safely",
      "time": null
    },
    {
      "user": "CaptainObvious",
      "text": "Interesting, but I do not know of an equivalent operation to use on Windows for the linux function stop_machine.",
      "time": null
    },
    {
      "user": "Ta Thanh Dinh",
      "text": "I think a dynamic code instrumentation framework (e.g. PIN, DynInst) may help, because the instrumentation will be realized \"transparently\" from the program's codes. For example, the paper about DynInst An API for Runtime Code Patching says: \"...The API is designed so that a single instrumentation process can insert snippets into multiple processes executing on a single machine...\". Here, snippets are injected codes.",
      "time": null
    }
  ],
  "answers_data": [
    {
      "content": "A sketch of how to implement your own patching system, where the length of the replacement instruction is less than or equal to the length of the instruction that you want to patch:\n\nNow, what to do if you want to patch an N byte instruction with an M byte instruction such that M > N? We'll apply roughly the same technique, but we'll modify the return addresses of the signalled threads to point into a copy of the original instructions that include your patch P.\n\nFor example, lets say you have instructions I1; I2; I3; I4; ..., and your patch P, if placed, would end up as: P; I3_tail_garbage; I4; ....\n\nThen you could create a patch entrypoint P; I1_copy; I2_copy; I3_copy; jmp &I4; at address patch. You will modify some of the the return addresses in the signal handlers as follows:\n\nPatch I1; I2; I3; I4; ... to do the following: jmp patch; int3; ...; int3; I4; ....\n\nNote: When copying code, you need to re-relativize it if your instructions somehow read from the instruction pointer. For example, if I1, I2, or I3 are branch instructions, or compute a RIP-relative address, then they will potentially need to be widened/modified/replaced with equivalent instructions.\n\nAnother approach is to patch each of I1, I2, and I3. If you do this, then you must start by patching only the first byte of each of these instructions, and only with an int3. This can be done safely, even while other threads are executing the code being patched. However, you cannot safely modify the other bytes of these instructions if other threads are concurrently executing those instructions. This is because those instructions might have been prefetched, and once that has happened, they are no longer a cohesive unit.\n\nFiguring out the right protocol to handle the cases where threads concurrently execute the int3s is tricky, but I think it can be handled by following a similar methodology to above approach of duplicating the first few instructions so that you guarantee that those instructions aren't lost, but you also capture threads executing code that falls within your patch region.\n\nI am not familiar with the Windows environment, so the CreateRemoteThread issue sounds tricky, but I think installing int3 instructions into the code as well as protecting the code from execution while you search for threads to signal might be sufficient. You might also consider having your master patching thread go to sleep for a short period of time. \n\nFinally, some good references to look at are Kprobes and RCU stuff as well, as the problem faced by some \"extra\" thread seeing the old or the new version (or something in-between) is a major concern with RCU. As a concluding remark, watch out about the language of the Intel manual w.r.t. cache coherency and the icache. A lot of text can be interpreted as if atomic writes to the data caches will be represented in the icache, but in practice, this isn't guaranteed to be true (especially where prefetching is concerned), and there are some important CPU errata on the issue that make the problem harder than it first appears.\n\n",
      "votes": "4",
      "user": "Peter Goodman",
      "time": "Aug 15, 2014 at 18:19",
      "is_accepted": false,
      "comments": []
    },
    {
      "content": "This is a good question, and I would argue there is no 100% safe method to patch a running windows process, unless you actively debug it, and even then there are probably edge cases.  You could eliminate many potential problems, but I feel that potential threading problems couldn't be entirely eliminated for generic purposes.\n\nThis leaves a couple practical options in my opinion:\n\n1.)  Suspend the process, patch your code, and resume execution.  Either all threads are suspended or they aren't, this is easily detectable if you have the rights to patch the process to begin with. This is my preferred method, though anti-debug measures based on timers as well as defensive hooks can detect this.  Overall though I'd say it's quite dependable.\n\n2.)  Know your target well and don't depend upon \"generic\" one-size-fits-all patching techniques.  You should know beforehand whether or not multi-threading is going to hamper a particular patch at a particular address for a specific target, and how feasible it will be to perform reliable realtime patching.\n\nIf you know or suspect that your target code is threaded, find the synchronization method used (locks, mutexes, interlocked operations, etc.) and begin your patch from thread-safe code, ideally after forcing temporary thread contention/deadlock to prevent execution while patching.  Reliably doing this will likely be very target specific and therefore require at least a tiny bit of fairly intimate knowledge of your target.\n\nMost important of all:  Know which instructions on your current hardware are atomic.  Without this knowledge to start with you can't possibly create an atomic patch.\n\nYou then have the problem of making a series of atomic writes (of atomic instructions) such that execution mid-patch doesn't crash/hang/alter execution in unintended ways.  This is not a trivial problem to solve.  Suspend the process and play it safe.\n\nEDIT:  I just realized that I took the bait and answered in a way that only considered hooking, i.e patching, even though your question specifically asks how to change code flow atomically during execution.  Proper DLL injection should allow you to do this pretty reliably in most cases, though like always it's never a sure thing when you are modifying a running process.\n\n",
      "votes": "2",
      "user": "Matthew Geyer",
      "time": "Jan 7, 2016 at 12:34",
      "is_accepted": false,
      "comments": [
        {
          "user": "0xC0000022L",
          "text": "From kernel mode there is ... or does that qualify as cheating? ;)",
          "time": null
        }
      ]
    },
    {
      "content": "Here's an older article on how hotpatching was implemented in Windows. If you want it done absolutely atomically, it has to be done from the kernel mode. There's no way around it. Here's the walkthrough:\n\nThis basically turns your patching thread into a single threaded environment for a short while.\n\nPS. Should work in theory. In practice, debugging this will be a living hell. Obviously do it in a VM and be ready to reboot (a lot.)\n\nEdit: Here's an actual example, taken from the DebugView tool. If you know what it does, it tries to capture a program's debugger output. If you enable kernel debugger output on an older OS, that tool has no other option but to install a trampoline on a DbgPrint function on a live system when the DebugView starts up. \n\nHere's how it does it (it uses somewhat old kernel functions, but it still delivers the idea):\n\n1. Get number of CPU cores (it uses an older KeNumberProcessors global variable as such):\n\n\n\n(For modern code I would probably use KeQueryActiveProcessors() with its bitmask, and KeQueryGroupAffinity() to account for number of CPUs greater than 32/64.)\n\n2. Make sure that the current thread is running on the CPU core 0 by calling KeSetAffinityThread:\n\n\n\n(Then check global variable bDontSet_FuncTrampoline in case we don't need to set this trampoline & restore thread affinity by jumping to step 6. But that case is not interesting.)\n\n3. Then check if we just have one CPU core, and if so jump to step 5. (Not very interesting either.) Otherwise set global variable nCountCpuCores to the count of CPU cores, and reset global bAllowToContinue_CoreNon0_DeferredRoutine flag to 0:\n\n\n\n4. Set each CPU core (other than 0, i.e. rsi pointer starts from index 1, or 0x8 offset in bytes) for high importance DPCs (deferred procedure calls) for our DeferredRoutine with the context set to CPU core number:\n\n\n\nThis will basically preempt whatever those other cores were doing and direct them to our DPC.\n\n5. Then for our thread running in core 0, execute DPC routine DeferredRoutine:\n\n\n\n6. After which restore this thread's affinity to what it used to be before:\n\n\n\nNow the interesting thing is what happens in DeferredRoutine:\n\n(Note that this routine will be executed on each CPU core.)\n\nA. The first step, set IRQL for the thread to CLOCK_LEVEL (or 13 for x64 code.) This is done by using the cr8 CPU register. Doing this will block processing of the most interrupts:\n\n\n\nB. Then decrement the counter in nCountCpuCores global variable, but do it using a lock CPU prefix to ensure synchronization among all CPU cores:\n\n\n\nC. Check what CPU core this thread runs on and enter a spin-loop accordingly:\n\n\n\nC.1. (Right side block in the code flow above.) For non-0 cores continue spinning in a loop while global variable bAllowToContinue_CoreNon0_DeferredRoutine is 0.\n\nC.2. (Left side block in the code flow above.) For core 0, continue spinning in a loop while the count of processed cores in the nCountCpuCores global variable doesn't reach 0.\n\n(I would personally add to each of those loops a pause instruction to ensure that CPU doesn't waste too much power while \"spinning\".)\n\nC.3. Once the condition C.2. has been met, it means that we have our core 0 all to ourselves and all other cores are busy spinning in the loop in C.1. and we can proceed by calling our install_func_Trampoline function to install required trampoline.\n\nC.4. When we're done with the trampoline, remember to release all cores from the spin-loop in C.1. by setting bAllowToContinue_CoreNon0_DeferredRoutine to 1.\n\nD. Lastly, very important, restore IRQL back to what it used to be:\n\n\n\nReturn error nt_status code, if so. Otherwise, we're done!\n\n",
      "votes": "2",
      "user": "c00000fd",
      "time": "Jun 25, 2018 at 6:26",
      "is_accepted": false,
      "comments": [
        {
          "user": "RbMm",
          "text": "really all this is sesnseless and nothing give. assume thread execute instructions in place where we apply patch . say push rbp; /** interrupt **/ sub rsp,10 let thread X executed push rbp and then clock interrupt , from where already we return on another thread in another place. then you apply patch (say set jmp here ) and then thread X continue execution from place where it was interrupted. already inside jmp instruction. and even without thread swap - you interrupt thread by DPC - but to where thread returned after DPC ? without change thread context - all this senseless",
          "time": null
        }
      ]
    }
  ]
}