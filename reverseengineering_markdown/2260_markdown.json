{
  "title": "Reverse engineering compressed file, where to start?",
  "link": "https://reverseengineering.stackexchange.com/questions/2260/reverse-engineering-compressed-file-where-to-start",
  "content": "I want to open finnish sports league \"data file\" used for bookkeeping. It includes all statistics for few decade, so it's interesting data file.\n\nThe file is here: http://www.bittilahde.fi/Tietokanta.dat (Database.dat in english)\n\nThe book keeping program is here: http://www.pesistulokset.fi/Kirjaus504.exe\n\nWhat I've found out:\n\nWhat could be the next step? \n\n",
  "votes": "15",
  "answers": 4,
  "views": "6k",
  "tags": [
    "file-format"
  ],
  "user": "Harriv",
  "time": "Mar 6, 2017 at 8:18",
  "comments": [
    {
      "user": "EfForEffort",
      "text": "Did you try binwalk?",
      "time": null
    },
    {
      "user": "Harriv",
      "text": "@bueno No, I'm new at this so I've never heard of it.Do you mena this: code.google.com/p/binwalk",
      "time": null
    },
    {
      "user": "EfForEffort",
      "text": "yup, it crawls the file looking for all kinds of different file types. It requires python and libmagic, I think. it's good stuff.",
      "time": null
    },
    {
      "user": "Harriv",
      "text": "@bueno Looks like great program, but in this case it doesn't tell me anything useful. Entropy graph gives out flat 1.0 for whole file.",
      "time": null
    },
    {
      "user": "samuirai",
      "text": "I added binwalk as an answer, because it may help other people having a similar question. Some additional information about entropy graph and compression can be found here: devttys0.com/2013/06/…",
      "time": null
    }
  ],
  "answers_data": [
    {
      "content": "Looking at it in OllyDbg it looks like a heavy task. Looks like a custom database with encrypted and (custom?) compressed data. This or the like would usually be the case in such applications. A flat file with structured data is not part of this one.\n\nAnyhow. As a starter:\n\nA quick check after trying out some general compression tools like 7z or binwalk, (have not tested it), can be to use ProcMon from Sysinternals. Start ProcMon, then your application and set filter on the application in ProcMon. You quickly find that:\n\nIn short it reads in chunks of varying size, but for main data processing it reads chunks of 16384 bytes. The process in steps:\n\nThe application also reads same chunks multiple times.\n\nExample:\n\n```\n013D0010  D4 9E BE BF 1C 1C 0B D4 C5 E7 11 B5 09 48 87 FA  Ôž¾¿ÔÅçµ.H‡ú\n013D0020  29 4C 03 C9 DE 4A 2B 71 74 7F D2 48 E7 13 94 4E  )LÉÞJ+qtÒHç”N\n...\n013D3FF0  6A D1 55 92 E2 16 60 53 69 89 86 7D D9 D8 10 BC  jÑU’â`Si‰†}ÙØ¼\n013D4000  90 F3 D1 48 28 47 34 EC 39 36 EC 4D 69 2A 7D E5  óÑH(G4ì96ìMi*}å\n                                             |_____._____|\n                                                   | \n                         Last DWORD aka checksum --+\n\n```\nSteps and details in order of discovery:\n\nSplit the .dat file in chunks of 16384 bytes and also generate a hex-dump of each file for easy search and comparison. To be honest I use Linux for this part with dd, xxd -ps, grep, diff etc.\n\nStart OllyDbg, open the application, locate CreateFile and set breakpoint:\n\n```\n00401220   $-FF25 18825000  JMP DWORD PTR DS:[<&kernel32.CreateFileA>;  kernel32.CreateFileA\n\n```\nPress F9 until filename (in EAX) is .dat file. Set/enable breakpoint on ReadFile. F9 and when read is done start stepping and looking at what is done.\n\nLooking at it:\n\nAfter read it first modify the buffer by using offset as \"magic\" starting at:\n\n```\n0045F5EC  /$ 53   PUSH EBX     ;  ALGO 2: XOR algorithm - post file read.\n...\n0045F6B6  \\. C3   RETN         ;  ALGO 2: RETN\n\n```\nAt least two of the actions taken seems to be libj_randl1() and libj_randl2(). (This would be step 2.2 in list above.)\n\nSimplified:\n\n```\nedx = memory address of buffer\necx = offset / 0x4000\nedi = edx\nebx = ecx * 0x9b9\nesi = last dword of buffer & 0x7fffffff\necx = 0\n\ni = 0;\nwhile (i < 0x3ffc) { /* size of buffer - 4 */\n    manipulate buffer\n}\n\n```\nThe whole routine translated to C code:\n\n```\nint xor_buf(uint8_t *buf, long offset, long buf_size)\n{\n    int32_t eax;\n    int32_t ebx;\n    int32_t esi;\n    long i;\n\n    buf_size -= 4;\n\n    ebx = (offset / 0x4000) * 0x9b9;\n    /* Intel int 32 */\n    esi = (\n        (buf[buf_size + 3] << 24) |\n        (buf[buf_size + 2] << 16) |\n        (buf[buf_size + 1] <<  8) |\n         buf[buf_size + 0]\n        ) & 0x7fffffff;\n\n    for (i = 0; i < buf_size /*0x3ffc*/; ++i) {\n        /* libj_randl2(sn) Ref. link above. */\n        ebx = ((ebx % 0x0d1a4) * 0x9c4e) - ((ebx / 0x0d1a4) * 0x2fb3);\n\n        if (ebx < 0) {\n            ebx += 0x7fffffab;\n        }\n\n        /* libj_randl1(sn) Ref. link above. */\n        esi = ((esi % 0x0ce26) * 0x9ef4) - ((esi / 0x0ce26) * 0x0ecf);\n\n        if (esi < 0) {\n            esi += 0x7fffff07;\n        }\n\n        eax = ebx - 0x7fffffab + esi;\n\n        if (eax < 1) {\n            eax += 0x7fffffaa;\n        }\n\n        /* Modify three next bytes. */    \n        buf[i] ^= (eax >> 0x03) & 0xff;\n\n        if (++i <= buf_size) {\n            buf[i] ^= (eax >> 0x0d) & 0xff;\n        }\n        if (++i <= buf_size) {\n            buf[i] ^= (eax >> 0x17) & 0xff;\n        }\n    }\n\n    return 0;\n}\n\n```\nThen a checksum is generated of the resulting buffer, (minus last dword), and checked against last dword. Here it uses a buffer from BSS segment that is generated upon startup, step 1. from list above. (Offset 0x00505000 + 0x894 and using a region of 4 * 0x100 as it is 256 32 bit integers). This seed map seems to be constant (never re-generated / changed) and can be skipped if one do not want to validate the buffer.\n\nCode point in disassembly (Comments mine.):\n\n```\n0045E614 . 53   PUSH EBX           ;  ALGO 1: GENERATE CHECKSUM MAGICK BSS\n...\n0045E672 . C3   RETN               ;  ALGO 1: RETN\n\n```\nThe code for the BSS numbers can simplified be written in C as e.g.:\n\n```\nint eax;    /* INT NR 1, next generated number to save */\nint i, j;\n\nunsigned int bss[0x100] = {0};  /* offset 00505894 */\n\nfor (i = 0; i < 0x100; ++i) {\n    eax = i << 0x18;\n    for (j = 0; j < 8; ++j) {\n        if (eax & 0x80000000) {\n            eax = (eax + eax) ^ 0x4c11db7;\n        } else {\n            eax <<= 1;\n        }\n    }\n    bss[i] = eax;\n}\n\n```\nThat bss int array is used on the manipulated buffer to generate a checksum that should be equal to the last integer in the 16384 bytes read from file. (Last dword, the one skipped in checksum routine and XOR'ing.). This would be step 2.3 in list above.\n\n```\nunsigned char *buf = manipulated file buffer;\nunsigned char *bss = memory dump 0x00505894 - 0x00505C90, or from code above\n\neax = 0x13d0010;  /* Memory location for buffer. */\nedx = 0x3ffc;     /* Size of buffer - 4 bytes (checksum). */\n\n...\n\n```\nAt exit ecx is equal to checksum.\n\nCode point in disassembly (Comments mine.):\n\n```\n0045E5A8  /$ 53  PUSH EBX    ;  ALGO 3: CALCULATE CHECKSUM AFTER ALGORITHM 2\n...\n0045E5E0  \\. C3  RETN        ;  ALGO 3: RETN (EAX=CHECKSUM == BUFFER LAST 4 BYTES)\n\n```\nShortened to a C routine it could be something like:\n\n```\nint32_t checksum(int32_t map[0x100], uint8_t *buf, long len)\n{\n    int i;\n    int32_t k, cs = 0;\n\n    for (i = 0; i < len; ++i) {\n        k = (cs >> 0x18) & 0xff;\n        cs = map[buf[i] ^ k] ^ (cs << 0x08);\n    }\n\n    return cs;\n}\n\n```\nIt is checked to be OK and then checksum in buffer is set as: two least significant bytes = 0, two most significant bytes are set to some number (chunk number in file or read number, (starting from 0)).\n\n```\n0045F9BF   . C680 FC3F0000 >MOV BYTE PTR DS:[EAX+3FFC],0     ;  Set two lower bytes of checksum in dat buf to 0\n0045F9C6   . C680 FD3F0000 >MOV BYTE PTR DS:[EAX+3FFD],0     ;  follows previous\n0045F9CD   . 66:8B4D F8     MOV CX,WORD PTR SS:[EBP-8]       ;  Set CX to stack pointer value of addr EBP - 8 (counter of sorts)\n0045F9D1   . 66:8988 FE3F00>MOV WORD PTR DS:[EAX+3FFE],CX    ;  Set .dat buffer higher bytes like CX.\n\n```\nNow after all this is done the actual copying of data starts with even more algorithms. Here the real work starts. Identifying data types, structures, where and what etc. Found some routines that extracted names etc. But everything being Finnish didn't help on making it easier to grasp ;).\n\nThe data above could be a start.\n\nSome breakpoints that might be of interest to begin with:\n\n```\nBreakpoints\nAddress    Module     Active    Disassembly  Comment\n0045E5A8   Kirjaus5   Disabled  PUSH EBX     ALGO 3: CALCULATE CHECKSUM AFTER ALGORITHM 2\n0045E5E0   Kirjaus5   Disabled  RETN         ALGO 3: RETN (EAX=CHECKSUM == BUFFER LAST 4 BYTES)\n0045E614   Kirjaus5   Disabled  PUSH EBX     ALGO 1: GENERATE CHECKSUM MAGIC BSS\n0045E672   Kirjaus5   Disabled  RETN         ALGO 1: RETN\n0045F5EC   Kirjaus5   Disabled  PUSH EBX     ALGO 2: FILE POST XOR READ ALGORITHM\n0045F6B6   Kirjaus5   Disabled  RETN         ALGO 2: RETN\n\n```\nSome notes:\n\nKeep a backup of the .dat file you are working with. If you abort the application the file often gets corrupted as it, as noted by @blabb, write data back to file. The .dat file also seem to be live so a new download of it would result in different data.\n\n",
      "votes": "16",
      "user": "Community",
      "time": "Jun 17, 2020 at 9:54",
      "is_accepted": true,
      "comments": [
        {
          "user": "Harriv",
          "text": "One question: how did you create those C code snippets? By hand or using some tools?",
          "time": null
        },
        {
          "user": "Runium",
          "text": "@Harriv: By hand. One way, when routines are not to long, could be to create a variable for each register (in use) etc. and almost make a blueprint in C, then you see what is what and can make functions and loops from it. After a while, and with exercise, it becomes easier to recognize what is what and how to write it more compact first time around …",
          "time": null
        }
      ]
    },
    {
      "content": "the .dat file you posted is written back every time it is accessed by your app constant size of 9.6 MB  (0x267 * 0x4000 ) = 0x99c0000 bytes\n\n4000 bytes are accessed on each successive reads\n267 times ReadFile is Done\neach of the 4000 bytes is xorred using a routine (custom ??)\nand then check summed \nfor (int i = 0; i< 0x267 ;i++)\n{\nchecksum = *(DWORD *) (FilePointer)(0x3ffc + i)\n}\nso on a dead dat file opened via hexeditor the dwords 0x3ffc,0x7ffc ...... contains the latest checksum \n\nyou might have to reverse engineer the xorring routine and checksum routine \n\nanalyse all the callstacks in the log file generated by windbg with this break point\n\nC:\\>cdb  -c \".logopen kir.txt;bu ntdll!NtReadFile \\\".if ( poi(esp+0x1c) != 0x400\n0) {gc} .else {kb;g }\\\"\" Kirjaus504.exe\n\n",
      "votes": "5",
      "user": "blabb",
      "time": "Jun 16, 2013 at 7:33",
      "is_accepted": false,
      "comments": [
        {
          "user": "Harriv",
          "text": "Great, thanks. I just assumed it was compressed..",
          "time": null
        }
      ]
    },
    {
      "content": "binwalk is a firmware analysis tool. It comes with some default file signatures called magic. There is a magic file called compressed, which scans for common compression signatures. It shows a lot of false positives, but it may find some common compression types and it should also be capable of unpacking them.\n\n",
      "votes": "5",
      "user": "samuirai",
      "time": "Jun 19, 2013 at 13:36",
      "is_accepted": false,
      "comments": []
    },
    {
      "content": "Well from this point on, your best bet would be to reverse the program's database loading functions since the database might be a custom one. Place a break point on CreateFile/OpenFile APIs when it loads the database and then look for the database manipulation functions to see how it extracts the contents. Couldn't try this on the program you posted since the user interface is in Finnish.\n\n",
      "votes": "4",
      "user": "shebaw",
      "time": "Jun 16, 2013 at 5:18",
      "is_accepted": false,
      "comments": []
    }
  ]
}