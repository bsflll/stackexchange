{
  "title": "Could a decompiler give better results if provided with part of the original code?",
  "link": "https://reverseengineering.stackexchange.com/questions/33207/could-a-decompiler-give-better-results-if-provided-with-part-of-the-original-cod",
  "content": "I know it's generally impractical to decompile programs written in C/C++ and the like because most non-essential information is lost during the translation to machine code. Any decompiled code would have none of the original structure, no meaningful method and variable names, and definitely no comments.\n\nHowever, if a compiler \"knows\" what part of the original code looked like, then could it produce more understandable code?\n\nSuppose I have a program called HelloWorld that is built from the following three files:\n\nI want to decompile HelloWorld after having lost the source code. However, let's say I find an intact copy of foo.c backed up somewhere. If I could somehow \"feed\" that file to a decompiler, then could it reproduce the contents of bar.c and baz.c more accurately? If so, are there any decompilers that do this?\n\n",
  "votes": "3",
  "answers": 1,
  "views": "113",
  "tags": [
    "decompilation"
  ],
  "user": "Danny",
  "time": "Sep 6, 2024 at 16:30",
  "comments": [
    {
      "user": "Rup",
      "text": "IDA can import C header files, yes - realistically it’s the function signatures and type / structure information that are going to be most useful for the other files - and Ghidra has Parse C source. How well they work in practice I don’t know though.",
      "time": null
    }
  ],
  "answers_data": [
    {
      "content": "IMHO, the best you can do in the scenario you mention to improve the output of any of the major decompilers I know (Hex-Rays and Ghidra) is to import function names, prototypes, structs, enums, unions, defines, etc... to your binary project from the source files you have, so the output of the decompilers will be closer to the original sources. The process, however, won't be automatic almost 99% sure: I doubt you would be able to just tell IDA/Ghidra \"here are these source files, just parse them and import the definitions\". In my experience, almost always I have had to modify the header files, or generate one myself with the definitions I want, in order to be able to use the definitions in IDA/Ghidra.\n\nEven if what I mentioned in the previous paragraph was possible to be done in an automated way, you will have the problem of how to match functions in the binary with functions in the source codes when there is no debugging information (in order to rename functions and apply function prototypes, etc). And even if debugging information is available, how to do so for non trivial C++ projects is... yet another whole project by its own. I have done some research (Pigaios) on this area and all I can tell you is that it isn't any easy.\n\nOther than that, I have seen some research projects trying to modify the output of working decompilers using LLMs telling them how to modify the output of the tool by feeding them multiple outputs of different decompilers and/or original source codes (like r2ai). However, they are usually toy projects and, also, they have the inherent problem of using LLMs: decompilers must be as correct, accurate and exact as possible, and LLMs aren't, as they hallucinate stuff and there is no way to control this.\n\nAnother example, while not exactly the scenario you mention but it is however yet another method aiming to improve the readability of generated pseudo-code by training on real source codes: I have seen some papers, and a few tools, that trained models using Open Source software, to try to infer variable and function names in binaries using the trained model (like, for example, Debin). The amount of false positives generated by such tools is astonishing.\n\nSo, in summary: the only realistic way of improving the output of decompilers as of today that I know of is to import, almost always manually, as much information as possible from source codes to your binary projects.\n\nPS: Last but not least, you are partially wrong when you say \"Any decompiled code would have none of the original structure\" as there are some basic things preserved, like functions order in compilation units.\n\n",
      "votes": "2",
      "user": "joxeankoret",
      "time": "Sep 8, 2024 at 10:51",
      "is_accepted": true,
      "comments": [
        {
          "user": "Danny",
          "text": "Thanks for the detailed response. I've also wondered whether AI could be used in this manner. I've heard it's also possible to ask ChatGPT to explain what a block of code does, but my understanding is AI is still a long way from being able to make decompiled code more readable.",
          "time": null
        }
      ]
    }
  ]
}