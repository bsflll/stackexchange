{
    "title": "How to display only the IR for your program code",
    "link": "https://reverseengineering.stackexchange.com/questions/11637/how-to-display-only-the-ir-for-your-program-code",
    "content": "<div class=\"s-prose js-post-body\" itemprop=\"text\">\n<p>I have a simple C program that is literally</p>\n<pre><code>int main(void) {\n    return 0;\n}\n</code></pre>\n<p>When I convert this to assembly, <code>gcc -S</code>, it grows to around 10 lines. As expected.</p>\n<p>Then when I convert it into binary, and then from that to VEX IR it grows to * a lot * of instructions. You can see this with <code>valgrind --tool=lackey --trace-mem=yes &lt;FILE&gt;</code></p>\n<p>My question is two-folded:</p>\n<ol>\n<li><p>Why does the program grow so much when you are looking at the IR even though the Assembly was tiny.</p>\n<p>I think its because you now have all the overhead calls / instructions that are needed to run the binary and not just your program code. But a more detailed explanation would be helpful</p>\n</li>\n<li><p>How can I isolate the IR that represents instructions in the code I wrote?</p>\n<p>I'm not sure if this is 100% possible, so if not are there any ways to help me narrow down what I want to look at?</p>\n</li>\n</ol>\n</div>",
    "votes": "2",
    "answers": 1,
    "views": "1k",
    "tags": [
        "decompilation"
    ],
    "user": "soupman",
    "time": "Jun 17, 2020 at 9:54",
    "comments": [],
    "answers_data": [
        {
            "content": "<div class=\"s-prose js-post-body\" itemprop=\"text\">\n<p>What follows is based primarily on information found in <a href=\"http://valgrind.org/docs/valgrind2007.pdf\" rel=\"nofollow noreferrer\"> Valgrind: A Framework for Heavyweight Dynamic Binary Instrumentation</a>.</p>\n<hr/>\n<h2>part 1</h2>\n<blockquote>\n<p>Why does the program grow so much when you are looking at the IR even though the Assembly was tiny.</p>\n</blockquote>\n<p>There are at least 2 reasons for this:</p>\n<ol>\n<li><p>While the machine code produced by GCC for the <code>main()</code> routine may by small, all of the code in the binary is transformed by Valgrind, including code in dynamically linked libraries. </p>\n<p>Valgrind is a dynamic binary intrumentation (DBI) framework, similar in some ways to <a href=\"http://www.dynamorio.org/\" rel=\"nofollow noreferrer\">DynamoRIO</a> and <a href=\"https://software.intel.com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool\" rel=\"nofollow noreferrer\">PIN</a>. It is implemented as a <a href=\"https://pdfs.semanticscholar.org/bb6c/4460b37a54530269dbdec19892c3e0836fc0.pdf\" rel=\"nofollow noreferrer\"> process virtual machine</a> (PVM) that loads a binary into its own virtual memory space and executes a transformed and intrumented version of its code:</p>\n<blockquote>\n<p>Valgrind uses <em>dynamic binary re-compilation</em>, similar to many other\n  DBI frameworks. A Valgrind tool is invoked by adding <code>valgrind --tool=&lt;toolname&gt;</code> (plus any Valgrind or tool options) before a\n  command. The named tool starts up, loads the client program into\n  the same process, and then (re)compiles the client’s machine code,\n  one small code block at a time, in a just-in-time, execution-driven\n  fashion. The core disassembles the code block into an intermediate\n  representation (IR) which is instrumented with analysis code by\n  the tool plug-in, and then converted by the core back into machine\n  code. The resulting translation is stored in a code cache to be\n  rerun as necessary. Valgrind’s core spends most of its time making,\n  finding, and running translations. None of the client’s original code\n  is run.</p>\n<p>Code handled correctly includes: normal executable code, dynamically\n  linked libraries, shared libraries, and dynamically generated\n  code.<sup>[1]</sup></p>\n</blockquote></li>\n<li><p>In the intermediate representation (IR) used by Valgrind, every effect a machine code instruction in a binary has is explicitly represented by an IR operation. This means that CISC instructions with side-effects will be represented by multiple IR operations.</p>\n<ul>\n<li><blockquote>\n<p>Valgrind uses disassemble-and-resynthesise (D&amp;R): machine\n  code is converted to an IR in which each instruction becomes\n  one or more IR operations. This IR is instrumented (by adding\n  more IR) and then converted back to machine code. All of the\n  original code’s effects on guest state (e.g. condition code setting)\n  must be explicitly represented in the IR because the original client\n  instructions are discarded and the final code is generated purely\n  from the IR.</p>\n</blockquote></li>\n<li><blockquote>\n<p>The IR has some RISC-like features: it is load/store, each primitive\n  operation only does one thing (many CISC instructions are broken\n  up into multiple operations), and when flattened, all operations\n  operate only on temporaries and literals. Nonetheless, supporting\n  all the standard integer, FP and SIMD operations of different sizes\n  requires more than 200 primitive arithmetic/logical operations.</p>\n</blockquote></li>\n</ul>\n<p>The instruction set architecture of the test binary is not explicitly stated in the original post and is assumed to be x86. x86 is an example of a <a href=\"https://www.cs.duke.edu/courses/fall06/cps220/lectures/2-isa.pdf\" rel=\"nofollow noreferrer\">CISC ISA</a>, which means that the number of IR operations &gt;&gt; number of original machine code instructions. This due to the complexity of x86 instructions in terms of side effects and operations performed as the result of executing a single instruction.</p></li>\n</ol>\n<p>When I executed <code>valgrind --tool=lackey --trace-mem=yes test</code>, where <code>test</code> was an ELF32 binary created from the example C code in the original post using GCC, these were the results (truncated, plus arrows pointing to lines that will be discussed subsequently):</p>\n<pre><code>.\n.\n.\nI  04cec101,3\nI  04cec104,3\nI  04cec107,2\n==11736== \n==11736== Counted 0 calls to main()                &lt;---------- (1)\n==11736== \n==11736== Jccs:\n==11736==   total:         44,420\n==11736==   taken:         21,288 ( 47%)\n==11736== \n==11736== Executed:\n==11736==   SBs entered:   44,083\n==11736==   SBs completed: 30,750\n==11736==   guest instrs:  211,953                 \n==11736==   IRStmts:       1,304,900               \n==11736== \n==11736== Ratios:\n==11736==   guest instrs : SB entered  = 48 : 10\n==11736==        IRStmts : SB entered  = 296 : 10\n==11736==        IRStmts : guest instr = 61 : 10   &lt;---------- (2)\n==11736== \n==11736== Exit code:       0\n</code></pre>\n<p>As we can see at (2), there are significantly more IR statements than machine code instructions, which is in line with what is expected of translation of CISC instructions into Valgrind's IR.</p>\n<p>(1) has to do with the second part of the question </p>\n<p>Here is an example of a single x86 instruction producing multiple IR statements:</p>\n<pre><code>0x24F27C: addl %ebx,%eax                 &lt;---------- x86 instruction + operands\n4: ------ IMark(0x24F27C, 2) ------\n5: PUT(60) = 0x24F27C:I32       # put %eip\n6: t3 = GET:I32(0)              # get %eax\n7: t2 = GET:I32(12)             # get %ebx\n8: t1 = Add32(t3,t2)            # addl\n9: PUT(32) = 0x3:I32            # put eflags val1\n10: PUT(36) = t3                # put eflags val2\n11: PUT(40) = t2                # put eflags val3\n12: PUT(44) = 0x0:I32           # put eflags val4\n13: PUT(0) = t1                 # put %eax\n</code></pre>\n<h2>part 2</h2>\n<blockquote>\n<p>How can I isolate the IR that represents instructions in the code I wrote?</p>\n</blockquote>\n<p>This does not seem possible due to how Valgrind transforms machine code (disassembly + resynthesis). </p>\n<p>We observe in (1) that 0 calls to <code>main()</code> were made when Valgrind instrumented the test binary. Since <code>main()</code> does nothing, it is possible that it is optimized out during the machine code -&gt; IL -&gt; instrumented IR -&gt; machine code translation process.</p>\n<p>The translation process actually consists of 8 phases, where</p>\n<blockquote>\n<p>All phases are performed by the core, except\n  instrumentation, which is performed by the tool. Phases marked\n  with a ‘*’ are architecture-specific.</p>\n</blockquote>\n<ol>\n<li><blockquote>\n<p><strong>Phase 1. Disassembly*: machine code → tree IR</strong>. The disassembler\n  converts machine code into (unoptimised) tree IR. Each\n  instruction is disassembled independently into one or more statements.\n  These statements fully update the affected guest registers in\n  memory: guest registers are pulled from the ThreadState into temporaries,\n  operated on, and then written back.</p>\n</blockquote></li>\n<li><blockquote>\n<p><strong>Phase 2. Optimisation 1: tree IR → flat IR</strong>. The first optimisation phase flattens the IR and does several optimisations: redundant get and put elimination (to remove unnecessary copying of guest\n  registers to/from the ThreadState), copy and constant propagation,\n  constant folding, dead code removal, common sub-expression elimination,\n  and even simple loop unrolling for intra-block loops.</p>\n</blockquote></li>\n<li><blockquote>\n<p><strong>Phase 3. Instrumentation: flat IR → flat IR</strong>. The code block is\n  then passed to the tool, which can transform it arbitrarily. It is important that the IR is flattened at this point as it makes instrumentation easier, particularly for shadow value tools.</p>\n</blockquote></li>\n<li><blockquote>\n<p><strong>Phase 4. Optimisation 2: flat IR → flat IR.</strong> A second, simpler optimisation pass performs constant folding and dead code removal.</p>\n</blockquote></li>\n<li><blockquote>\n<p><strong>Phase 5. Tree building: flat IR → tree IR</strong>. The tree builder converts flat IR back to tree IR in preparation for instruction selection.\n  Expressions assigned to temporaries which are used only once are\n  usually substituted into the temporary’s use point, and the assignment\n  is deleted. The resulting code may perform loads in a different\n  order to the original code, but loads are never moved past stores</p>\n</blockquote></li>\n<li><blockquote>\n<p><strong>Phase 6. Instruction selection*: tree IR → instruction list</strong>. The\n  instruction selector converts the tree IR into a list of instructions\n  which use virtual registers (except for those instructions that are\n  hard-wired to use particular registers; these are common on x86\n  and AMD64). The instruction selector uses a simple, greedy, topdown\n  tree-matching algorithm.</p>\n</blockquote></li>\n<li><blockquote>\n<p><strong>Phase 7. Register allocation: instruction list → instruction list</strong>. The linear-scan register allocator [26] replaces virtual registers with host registers, inserting spills as necessary. One general-purpose\n  host register is always reserved to point to the ThreadState.</p>\n</blockquote></li>\n<li><blockquote>\n<p><strong>Phase 8. Assembly*: instruction list → machine code</strong>. The final\n  assembly phase simply encodes the selected instructions appropriately\n  and writes them to a block of memory.</p>\n</blockquote></li>\n</ol>\n<p>After optimization and potentially arbitrary transformation, it is an open question as to whether any of the IR code output by <code>lackey</code> bears any discernible resemblance to the machine code generated by GCC for <code>main()</code>.</p>\n<hr/>\n<p>Supplementary resources:</p>\n<p><a href=\"https://fosdem.org/2017/schedule/event/valgrind_vex_future/\" rel=\"nofollow noreferrer\">https://fosdem.org/2017/schedule/event/valgrind_vex_future/</a></p>\n<p><a href=\"https://fosdem.org/2017/schedule/event/valgrind_vex_future/attachments/slides/1842/export/events/attachments/valgrind_vex_future/slides/1842/valgrind_vex_future.pdf\" rel=\"nofollow noreferrer\">https://fosdem.org/2017/schedule/event/valgrind_vex_future/attachments/slides/1842/export/events/attachments/valgrind_vex_future/slides/1842/valgrind_vex_future.pdf</a></p>\n<p><a href=\"https://github.com/trailofbits/libvex/blob/master/VEX/pub/libvex_ir.h\" rel=\"nofollow noreferrer\">https://github.com/trailofbits/libvex/blob/master/VEX/pub/libvex_ir.h</a></p>\n<p><a href=\"https://arxiv.org/pdf/0810.0372.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/0810.0372.pdf</a></p>\n<p><a href=\"http://www.ittc.ku.edu/~kulkarni/teaching/EECS768/slides/chapter3.pdf\" rel=\"nofollow noreferrer\">http://www.ittc.ku.edu/~kulkarni/teaching/EECS768/slides/chapter3.pdf</a></p>\n<p><a href=\"https://docs.angr.io/docs/ir.html\" rel=\"nofollow noreferrer\">https://docs.angr.io/docs/ir.html</a></p>\n<p><hr/>\n<sub>1. Nicholas Nethercote and Julian Seward. Valgrind: A Framework for Heavyweight Dynamic Binary Instrumentation. In Proc. of the ACM SIGPLAN 2007 Conference on Programming Language Design and Implementation (PLDI), June 2007.\n</sub></p>\n</div>",
            "votes": "4",
            "user": "julian",
            "time": "Aug 12, 2017 at 4:20",
            "is_accepted": false,
            "comments": []
        }
    ]
}