{
    "title": "Trying to figure what kind of compression was used",
    "link": "https://reverseengineering.stackexchange.com/questions/15326/trying-to-figure-what-kind-of-compression-was-used",
    "content": "<div class=\"s-prose js-post-body\" itemprop=\"text\">\n<p>I got the following raw data, which are the first 35 bytes of a compressed png image:</p>\n<pre><code>00 89 50 4e 47 0d 0a 1a 0a 00 00 00 00 0d 49 48\n44 52 08 00 00 02 58 00 83 5a 08 06 80 00 83 64\n31 28 fe\n</code></pre>\n<p>I also happened to have the 33 bytes the above 35 bytes were before they were compressed</p>\n<pre><code>89 50 4e 47 0d 0a 1a 0a 00 00 00 0d 49 48 44 52\n00 00 02 58 00 00 00 5a 08 06 00 00 00 64 31 28\nfe\n</code></pre>\n<p>I'm staring on those bytes for days now and can't figure our the compression algorithm... it looks like some kind of lz77 or Sliding Window Compression.</p>\n<p>Any help would be much appreciated with this problem</p>\n</div>",
    "votes": "2",
    "answers": 2,
    "views": "996",
    "tags": [
        "decompress"
    ],
    "user": null,
    "time": "May 12, 2017 at 13:42",
    "comments": [
        {
            "user": "julian",
            "text": "<span class=\"comment-copy\">can you share all of the data, not just the first <i>n</i> bytes of file <i>x</i></span>",
            "time": null
        },
        {
            "user": "rertiyulte",
            "text": "<span class=\"comment-copy\">hey i have something pretty similar just with 16 bits and not 8. can you tell us how did solve it? ian cock can you give me your skype or something to chat?</span>",
            "time": null
        },
        {
            "user": "perror",
            "text": "<span class=\"comment-copy\">If you have a new question, please ask it by clicking the <a href=\"https://reverseengineering.stackexchange.com/questions/ask\">Ask Question</a> button. Include a link to this question if it helps provide context. - <a href=\"/review/low-quality-posts/8841\">From Review</a></span>",
            "time": null
        }
    ],
    "answers_data": [
        {
            "content": "<div class=\"s-prose js-post-body\" itemprop=\"text\">\n<p>It does indeed appear to be an LZ77 variant where 8 encoded/not-encoded flags are combined into a single flag byte.</p>\n<p>The compressed data is then grouped into 8 data 'units' where each unit is represented either by a single uncompressed byte or by a 2 byte dictionary entry.</p>\n<p>The data for a batch of 8 units is preceded by the flag byte where each of its 8 bits indicates whether each unit is an uncompressed byte or a dictionary entry.</p>\n<p>There's not enough data here to be 100% sure about the encoding of the dictionary entries or what any window is because there are only 2 (identical) dictionary entries in your example data.  However, it appears likely that the 2 byte entry is made up of a 12 bit offset and a 4 bit length referring back to previously decompressed data.</p>\n<p>In the case of your compressed data, the decompression proceeds as follows -</p>\n<pre><code>compressed                  decompressed\nflags         data          offset  data            \n00                                                  \n    0=&gt;raw    89      -&gt;    0000:   89              \n    0=&gt;raw    50      -&gt;    0001:   50              \n    0=&gt;raw    4e      -&gt;    0002:   4e              \n    0=&gt;raw    47      -&gt;    0003:   47              \n    0=&gt;raw    0d      -&gt;    0004:   0d              \n    0=&gt;raw    0a      -&gt;    0005:   0a              \n    0=&gt;raw    1a      -&gt;    0006:   1a              \n    0=&gt;raw    0a      -&gt;    0007:   0a              \n00                                                  \n    0=&gt;raw    00      -&gt;    0008:   00              \n    0=&gt;raw    00      -&gt;    0009:   00              \n    0=&gt;raw    00      -&gt;    000A:   00              \n    0=&gt;raw    0d      -&gt;    000B:   0d              \n    0=&gt;raw    49      -&gt;    000C:   49              \n    0=&gt;raw    48      -&gt;    000D:   48              \n    0=&gt;raw    44      -&gt;    000E:   44              \n    0=&gt;raw    52      -&gt;    000F:   52              \n08                                                  \n    0=&gt;raw    00      -&gt;    0010:   00              \n    0=&gt;raw    00      -&gt;    0011:   00              \n    0=&gt;raw    02      -&gt;    0012:   02              \n    0=&gt;raw    58      -&gt;    0013:   58              \n    1=&gt;dict   00 83   -&gt;    0014:   00 00 00    // copy of 3 bytes from offset 8    \n    0=&gt;raw    5A      -&gt;    0017:   5A              \n    0=&gt;raw    08      -&gt;    0018:   08              \n    0=&gt;raw    06      -&gt;    0019:   06              \n80                                                  \n    1=&gt;dict   00 83   -&gt;    001A:   00 00 00    // copy of 3 bytes from offset 8        \n    0=&gt;raw    64      -&gt;    001D:   64              \n    0=&gt;raw    31      -&gt;    001E:   31              \n    0=&gt;raw    28      -&gt;    001F:   28              \n    0=&gt;raw    fe      -&gt;    0020:   fe              \n    0=&gt;raw    ...     -&gt;    0021:   ...\n    0=&gt;raw    ...     -&gt;    0022:   ...                 \n    0=&gt;raw    ...     -&gt;    0023:   ...          \n</code></pre>\n</div>",
            "votes": "3",
            "user": "Ian Cook",
            "time": "May 11, 2017 at 19:52",
            "is_accepted": false,
            "comments": [
                {
                    "user": "user20145",
                    "text": "<span class=\"comment-copy\">I was so sure it is the right solution, but sadly after decompressing it - the image isnt readable :( this is my decompression script: <a href=\"https://pastebin.com/N94jrkpu\" rel=\"nofollow noreferrer\">pastebin.com/N94jrkpu</a>   I'm so hoping you will find an error in my decompression script...</span>",
                    "time": null
                },
                {
                    "user": "Ian Cook",
                    "text": "<span class=\"comment-copy\">The problem is that there are various ways of encoding the dictionary entities and it's not possible to tell how it's done from the exceedingly small data sample you've provided. Having more of the compressed image would help.</span>",
                    "time": null
                },
                {
                    "user": "user20145",
                    "text": "<span class=\"comment-copy\">the 4 bits definitely represent the amount, because the size of the decompressed file is right (I know that by the IDAT length) but the content isnt, any other ideas?</span>",
                    "time": null
                }
            ]
        },
        {
            "content": "<div class=\"s-prose js-post-body\" itemprop=\"text\">\n<p>This looks like an format produced by a <a href=\"http://www.ross.net/compression/lzrw1.html\" rel=\"nofollow noreferrer\">LZRW</a> family algorithm.</p>\n<p>The code referred there contains</p>\n<pre><code>#define FLAG_COMPRESS 0     /* Signals that compression occurred. */\n#define FLAG_COPY     1     /* Signals that a copyover occurred.  */\n</code></pre>\n<p>(your variant may have those two swapped) and</p>\n<pre><code>#define ITEMMAX 16     /* Maximum number of bytes in an expanded item.  */\n</code></pre>\n</div>",
            "votes": "0",
            "user": "Leo B.",
            "time": "May 12, 2017 at 1:52",
            "is_accepted": false,
            "comments": [
                {
                    "user": "user20145",
                    "text": "<span class=\"comment-copy\">Can you please give an example on the data I provided</span>",
                    "time": null
                },
                {
                    "user": "Leo B.",
                    "text": "<span class=\"comment-copy\">@Matan The algorithm refuses to compress because of no savings (as you said, the original is 33 bytes, the \"compressed\" form is 35). The LZRW1 format is similar but not exact; for example, it uses 2 bytes of flags at a time, but otherwise the idea is the same. You may want to consult the decompression part of the LZRW code by my link to see if your decompression script has a bug (sorry, I cannot access pastebin now from behind a corporate firewall).</span>",
                    "time": null
                },
                {
                    "user": "Leo B.",
                    "text": "<span class=\"comment-copy\">One thing to notice is that the compressed references use the absolute buffer position of the string to copy (offset 8) rather than the relative (how many bytes to step back to find the copy source). This is different from most LZ77 implementations.</span>",
                    "time": null
                },
                {
                    "user": "user20145",
                    "text": "<span class=\"comment-copy\">I implemented a decompressor and it outputed a file in right side - but the CRC32 of the IDAT chunk doesnt fit the data itself, the CRC is right, the data isnt.</span>",
                    "time": null
                },
                {
                    "user": "user20145",
                    "text": "<span class=\"comment-copy\">What it means is that the 4 LSB bits are definitely the <code>amount</code> but the 12 MSB bits aren't just the offset, there is something more over there.</span>",
                    "time": null
                }
            ]
        }
    ]
}